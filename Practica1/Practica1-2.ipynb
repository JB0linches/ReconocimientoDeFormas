{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 1 Reconocimiento de Formas: Clasificador de la distancia euclídea \n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cercadillo Muñoz, Daniel\n",
    "* **Alumno 3**: Cerezo Pomykol, Jan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "class ClassifEuclid(Classifier):\n",
    "    \n",
    "    def __init__(self,labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n = np.zeros(len(self.labels)) # Contador de ocurrencias de cada clase\n",
    "        self.Z = np.zeros((len(self.labels), X.shape[1]))\n",
    "        # Calcular la media: \n",
    "        # Sumar las ocurrencias de cada clase en self.Z\n",
    "        for yi, Xi in zip(y, X):\n",
    "            n[yi] = n[yi] + 1\n",
    "            self.Z[yi] = self.Z[yi] + Xi\n",
    "        # Dividir cada sumatorio entre el númeo de ocurrencias\n",
    "        self.Z = self.Z / n[:,np.newaxis]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "        #return np.sqrt(np.sum(np.power(X[:,np.newaxis] - self.Z, 2), axis=2))\n",
    "\n",
    "    def pred_label(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.predict(X), axis=1)\n",
    "\n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.pred_label(X)==y)\n",
    "\n",
    "class ClassifEstadistico(Classifier):\n",
    "    \n",
    "    def __init__(self,labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.cov = None # Array de medias\n",
    "        self.mu = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            self.cov[c] = np.cov(X[y==c], rowvar=False)\n",
    "            self.mu[c] = np.mean(X[y==c], axis=0)\n",
    "            self.cov_inv[c] = np.linalg.inv(self.cov[c])\n",
    "            self.det[c] = np.linalg.det(self.cov[c])\n",
    "            self.a[c] = -.5 * self.cov_inv[c]\n",
    "            self.b[c] = self.mu[c].T @ self.cov_inv[c]\n",
    "            self.c[c] = -.5 * (self.mu[c].T @ self.cov_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(np.sum(y==c)/X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        #return (np.einsum('ab,cdb->acd', X, self.a)@X.T + self.b@X.T + self.c[:,np.newaxis]).T\n",
    "        #return (np.einsum('abc,ac->ab', np.einsum('ab,cdb->acd', X, self.a), X) + (self.b@X.T).T + self.c[np.newaxis,:]).T\n",
    "        #return np.einsum('ab,cdb,ad->ac', X, self.a, X) + (self.b@X.T).T + self.c[None,:]\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "        #return (np.diagonal(X@self.a@X.T, axis1=1, axis2=2) + self.b@X.T + self.c[:,np.newaxis]).T\n",
    "\n",
    "    def pred_label(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmax(self.predict(X), axis=1)\n",
    "\n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.pred_label(X)==y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmu = np.empty((3, 4))\\ncov = np.empty((3, 4, 4))\\ncovi = np.empty((3, 4, 4))\\ndet = np.empty(3)\\na = np.empty((3, 4, 4))\\nb = np.empty((3, 4))\\nc = np.empty(3)\\nfor ci in range(3):\\n    mu[ci] = np.mean(X[y==ci], axis=0)\\n    cov[ci] = np.cov(X[y==ci], rowvar=False)\\n    covi[ci] = np.linalg.inv(cov[ci])\\n    det[ci] = np.linalg.det(cov[ci])\\n    a[ci] = -.5 * covi[ci]\\n    b[ci] = mu[ci].T @ covi[ci]\\n    c[ci] = -.5 * (mu[ci] @ covi[ci] @ mu[ci].T) -.5 * np.log(det[ci]) + np.log(np.sum(y==ci)/X.shape[0])\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PRUEBAS\"\"\"\n",
    "\"\"\"\n",
    "mu = np.empty((3, 4))\n",
    "cov = np.empty((3, 4, 4))\n",
    "covi = np.empty((3, 4, 4))\n",
    "det = np.empty(3)\n",
    "a = np.empty((3, 4, 4))\n",
    "b = np.empty((3, 4))\n",
    "c = np.empty(3)\n",
    "for ci in range(3):\n",
    "    mu[ci] = np.mean(X[y==ci], axis=0)\n",
    "    cov[ci] = np.cov(X[y==ci], rowvar=False)\n",
    "    covi[ci] = np.linalg.inv(cov[ci])\n",
    "    det[ci] = np.linalg.det(cov[ci])\n",
    "    a[ci] = -.5 * covi[ci]\n",
    "    b[ci] = mu[ci].T @ covi[ci]\n",
    "    c[ci] = -.5 * (mu[ci] @ covi[ci] @ mu[ci].T) -.5 * np.log(det[ci]) + np.log(np.sum(y==ci)/X.shape[0])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VRuI00dW2cU"
   },
   "source": [
    "## Código para cargar la base de datos desde un fichero en drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXE9uaPR63vh"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# from sklearn.datasets import load_iris\n",
    "\n",
    "# drive.mount('/content/gdrive')\n",
    "# drive_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
    "\n",
    "# import pandas as pd\n",
    "# # Cargar las características de la BD\n",
    "# X = np.genfromtxt(drive_dir + 'irisData.txt', delimiter='\\t')[:, :-1]\n",
    "# print(\"X: \\n\" + str(X))\n",
    "\n",
    "# # Leer las etiquetas y convertirlas a enteros\n",
    "# y = np.genfromtxt(drive_dir + 'irisData.txt', dtype=str, delimiter='\\t')[:, -1]\n",
    "# y = pd.factorize(y)[0]\n",
    "# print(\"y: \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jry9Y_njWsg6"
   },
   "source": [
    "## Código para cargar la base de datos Iris directamente desde sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 906,
     "status": "ok",
     "timestamp": 1568323676443,
     "user": {
      "displayName": "Iago Suárez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCIoiLrUWgbOZ6jr3DHdz3G66zRmqqPBdVeoM8yEA=s64",
      "userId": "13725843249013938636"
     },
     "user_tz": -120
    },
    "id": "LmA70vaCWgzI",
    "outputId": "0eba7d4e-2b19-4ccf-eb44-549a1f745948",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "#print(\"X: \\n\" + str(X))\n",
    "y = dataset.target\n",
    "#print(\"y: \\n\" + str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "Entrenamiento, predicción y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################################\n",
      "\tClasificador distancia euclídea\n",
      "############################################################################\n",
      "----------------------------------------------------------------------------\n",
      "iris:   Aciertos: 139/150 (92.67%)\n",
      "          Clasificador sklearn: 139 aciertos\n",
      "----------------------------------------------------------------------------\n",
      "wine:   Aciertos: 129/178 (72.47%)\n",
      "          Clasificador sklearn: 129 aciertos\n",
      "----------------------------------------------------------------------------\n",
      "cancer:   Aciertos: 507/569 (89.10%)\n",
      "          Clasificador sklearn: 507 aciertos\n",
      "\n",
      "############################################################################\n",
      "\tClasificador estadístico\n",
      "############################################################################\n",
      "----------------------------------------------------------------------------\n",
      "iris:   Aciertos: 147/150 (98.00%)\n",
      "          Clasificador sklearn: 147 aciertos\n",
      "----------------------------------------------------------------------------\n",
      "wine:   Aciertos: 177/178 (99.44%)\n",
      "          Clasificador sklearn: 177 aciertos\n",
      "----------------------------------------------------------------------------\n",
      "cancer:   Aciertos: 554/569 (97.36%)\n",
      "          Clasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\"\"\"\n",
    "Clasificador distancia euclídea\n",
    "\"\"\"\n",
    "\n",
    "print(\"\", \"#\"*76, \"\\tClasificador distancia euclídea\", \"#\"*76, sep=\"\\n\")\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "a = ClassifEuclid(dataset.target_names)\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "train = a.fit(np.array(X), y)\n",
    "#print(\"-\"*32, \"centroides\", \"-\"*32, \"\\n\", train.Z, \"\\n\")\n",
    "\n",
    "# 3. Predecir empleando la base de datos de entrenamiento (X)\n",
    "pred = a.predict(X)\n",
    "#print(\"-\"*32, \"distancias\", \"-\"*32, \"\\n\", pred, \"\\n\")\n",
    "result = a.pred_label(X)\n",
    "#print(\"-\"*32, \"etiquetas\", \"-\"*33, \"\\n\", result, \"\\n\")\n",
    "\n",
    "# 4. Evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "n_aciertos = a.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\niris:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "# wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEuclid(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "#print(\"-\"*32, \"centroides\", \"-\"*32, \"\\n\", train.Z, \"\\n\")\n",
    "pred = b.predict(X)\n",
    "#print(\"-\"*32, \"distancias\", \"-\"*32, \"\\n\", pred, \"\\n\")\n",
    "result = b.pred_label(X)\n",
    "#print(\"-\"*32, \"etiquetas\", \"-\"*33, \"\\n\", result, \"\\n\")\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\nwine:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "# cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "c = ClassifEuclid(dataset.target_names)\n",
    "train = c.fit(np.array(X), y)\n",
    "#print(\"-\"*32, \"centroides\", \"-\"*32, \"\\n\", train.Z, \"\\n\")\n",
    "pred = c.predict(X)\n",
    "#print(\"-\"*32, \"distancias\", \"-\"*32, \"\\n\", pred, \"\\n\")\n",
    "result = c.pred_label(X)\n",
    "#print(\"-\"*32, \"etiquetas\", \"-\"*33, \"\\n\", result, \"\\n\")\n",
    "n_aciertos = c.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\ncancer:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Clasificador estadístico\n",
    "\"\"\"\n",
    "print(\"\", \"#\"*76, \"\\tClasificador estadístico\", \"#\"*76, sep=\"\\n\")\n",
    "# iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "pred = b.predict(X)\n",
    "result = b.pred_label(X)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\niris:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "# wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "pred = b.predict(X)\n",
    "result = b.pred_label(X)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\nwine:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "# cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "pred = b.predict(X)\n",
    "result = b.pred_label(X)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"-\"*76, \"\\ncancer:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\" \"*10, \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los tres experimentos (clasificador distancia euclídea):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 139| 92.67|\n",
    "| Wine   | 129| 72.47|\n",
    "| Cancer | 507| 89.10|\n",
    "\n",
    "Resultados de los tres experimentos (clasificador estadístico):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147| 98.00|\n",
    "| Wine   | 177| 99.44|\n",
    "| Cancer | 554| 97.37|\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
