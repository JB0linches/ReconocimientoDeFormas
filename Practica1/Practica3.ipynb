{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 1 Reconocimiento de Formas: Clasificador de la distancia euclídea \n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cercadillo Muñoz, Daniel\n",
    "* **Alumno 3**: Cerezo Pomykol, Jan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self,X):\n",
    "        pass\n",
    "\n",
    "class ClassifEuclid(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self,labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n = np.zeros(len(self.labels)) # Contador de ocurrencias de cada clase\n",
    "        self.Z = np.zeros((len(self.labels), X.shape[1]))\n",
    "        # Calcular la media: \n",
    "        # Sumar las ocurrencias de cada clase en self.Z\n",
    "        for yi, Xi in zip(y, X):\n",
    "            n[yi] = n[yi] + 1\n",
    "            self.Z[yi] = self.Z[yi] + Xi\n",
    "        # Dividir cada sumatorio entre el númeo de ocurrencias\n",
    "        self.Z = self.Z / n[:,np.newaxis]\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        #return np.sqrt(np.sum(np.power(X[:,np.newaxis] - self.Z, 2), axis=2))\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "\n",
    "    def pred_label(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.predict(X), axis=1)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y)/len(y)\n",
    "    \n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.pred_label(X)==y)\n",
    "\n",
    "class ClassifEstadistico(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self,labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            self.cov[c] = np.cov(X[y==c], rowvar=False)\n",
    "            self.mu[c] = np.mean(X[y==c], axis=0)\n",
    "            self.cov_inv[c] = np.linalg.inv(self.cov[c])\n",
    "            self.det[c] = np.linalg.det(self.cov[c])\n",
    "            self.a[c] = -.5 * self.cov_inv[c]\n",
    "            self.b[c] = self.mu[c].T @ self.cov_inv[c]\n",
    "            self.c[c] = -.5 * (self.mu[c].T @ self.cov_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(np.sum(y==c)/X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        #return (np.diagonal(X@self.a@X.T, axis1=1, axis2=2) + self.b@X.T + self.c[:,np.newaxis]).T\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def pred_label(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmax(self.predict(X), axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y)/len(y)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.pred_label(X)==y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "# Entrenamiento, predicción y evaluación de iris, wine y cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################\n",
      "\tClasificador distancia euclídea\n",
      "############################################################################\n",
      "\t--------------------------------------------------------------------\n",
      "\tiris:   Aciertos: 139/150 (92.67%)\n",
      "\t\tEvaluación por resustitución: 0.9267\n",
      "\t\tEvaluación por validación cruzada: 0.9133, std:0.0499\n",
      "\t\tClasificador sklearn: 139 aciertos\n",
      "\t--------------------------------------------------------------------\n",
      "\twine:   Aciertos: 129/178 (72.47%)\n",
      "\t\tEvaluación por resustitución: 0.7247\n",
      "\t\tEvaluación por validación cruzada: 0.7187, std:0.0804\n",
      "\t\tClasificador sklearn: 129 aciertos\n",
      "\t--------------------------------------------------------------------\n",
      "\tcancer: Aciertos: 507/569 (89.10%)\n",
      "\t\tEvaluación por resustitución: 0.8910\n",
      "\t\tEvaluación por validación cruzada: 0.8841, std:0.0840\n",
      "\t\tClasificador sklearn: 507 aciertos\n",
      "\n",
      "\n",
      "############################################################################\n",
      "\tClasificador estadístico\n",
      "############################################################################\n",
      "\t--------------------------------------------------------------------\n",
      "\tiris:   Aciertos: 147/150 (98.00%)\n",
      "\t\tEvaluación por resustitución: 0.9800\n",
      "\t\tEvaluación por validación cruzada: 0.9600, std:0.0646\n",
      "\t\tClasificador sklearn: 147 aciertos\n",
      "\t--------------------------------------------------------------------\n",
      "\twine:   Aciertos: 177/178 (99.44%)\n",
      "\t\tEvaluación por resustitución: 0.9944\n",
      "\t\tEvaluación por validación cruzada: 0.7108, std:0.3660\n",
      "\t\tClasificador sklearn: 177 aciertos\n",
      "\t--------------------------------------------------------------------\n",
      "\tcancer: Aciertos: 554/569 (97.36%)\n",
      "\t\tEvaluación por resustitución: 0.9736\n",
      "\t\tEvaluación por validación cruzada: 0.9613, std:0.0090\n",
      "\t\tClasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\"\"\"\n",
    "Clasificador distancia euclídea\n",
    "\"\"\"\n",
    "print(\"#\"*76, \"\\tClasificador distancia euclídea\", \"#\"*76, sep=\"\\n\")\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# 1. Cargar los datos de la base de datos de entrenamiento\n",
    "a = ClassifEuclid(dataset.target_names)\n",
    "\n",
    "# 2. Entrenar el clasificador\n",
    "train = a.fit(np.array(X), y)\n",
    "\n",
    "# 3. Predecir y evaluar el clasificador calculando el porcentaje de datos correctamente clasificados\n",
    "n_aciertos = a.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % a.score(X,y))\n",
    "scores = cross_val_score(a, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "# wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEuclid(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\twine:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % b.score(X,y))\n",
    "scores = cross_val_score(b, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "# cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "c = ClassifEuclid(dataset.target_names)\n",
    "train = c.fit(np.array(X), y)\n",
    "n_aciertos = c.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % c.score(X,y))\n",
    "scores = cross_val_score(c, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Clasificador estadístico\n",
    "\"\"\"\n",
    "print(\"\\n\", \"#\"*76, \"\\tClasificador estadístico\", \"#\"*76, sep=\"\\n\")\n",
    "# iris\n",
    "dataset = load_iris()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % b.score(X,y))\n",
    "scores = cross_val_score(b, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "# wine\n",
    "dataset = load_wine()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\twine:   Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % b.score(X,y))\n",
    "scores = cross_val_score(b, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n",
    "\n",
    "# cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "b = ClassifEstadistico(dataset.target_names)\n",
    "train = b.fit(np.array(X), y)\n",
    "n_aciertos = b.num_aciertos(X, y)\n",
    "print(\"\\t\", \"-\"*68, \"\\n\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y), \" (\", \"%.2f\" % ((n_aciertos / len(y))*100), \"%)\", sep='')\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % b.score(X,y))\n",
    "scores = cross_val_score(b, X, y, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std:\", \"%.4f\" % np.std(scores), sep='')\n",
    "c_est = QuadraticDiscriminantAnalysis()\n",
    "c_est.fit(X, y)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(c_est.predict(X)==y), \" aciertos\", sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resultados de los tres experimentos (clasificador distancia euclídea):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 139| 92.67|\n",
    "| Wine   | 129| 72.47|\n",
    "| Cancer | 507| 89.10|\n",
    "\n",
    "Resultados de los tres experimentos (clasificador estadístico):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147| 98.00|\n",
    "| Wine   | 177| 99.44|\n",
    "| Cancer | 554| 97.37|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de Isolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador distancia euclídea:\n",
      "\tEvaluación por resustitución: 0.8809\n",
      "\tEvaluación por exclusión: 0.8743\n",
      "Clasificador estadístico:\n",
      "\tEvaluación por resustitución: 1.0000\n",
      "\tEvaluación por exclusión: 0.0648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_train = np.array(X[:6238])\n",
    "y_train = pd.factorize(y)[0][:6238]\n",
    "X_test = np.array(X[6238:])\n",
    "y_test = pd.factorize(y)[0][6238:]\n",
    "\n",
    "X = np.array(X)\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Clasificador distancia euclidea\n",
    "clss_euc = ClassifEuclid(np.unique(y_train))\n",
    "clss_euc.fit(X_train, y_train)\n",
    "# Clasificador estadístico\n",
    "clss_est = QuadraticDiscriminantAnalysis()\n",
    "clss_est.fit(X_train, y_train)\n",
    "\n",
    "print(\"Clasificador distancia euclídea:\")\n",
    "print(\"\\tEvaluación por resustitución:\", \"%.4f\" % clss_euc.score(X_train, y_train))\n",
    "print(\"\\tEvaluación por exclusión:\", \"%.4f\" % clss_euc.score(X_test, y_test))\n",
    "print(\"Clasificador estadístico:\")\n",
    "print(\"\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador de la distancia euclídea:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9267 | 0.9133 | - |\n",
    "| Wine   | 0.7247 | 0.7187 | - |\n",
    "| Cancer | 0.8910 | 0.8841 | - |\n",
    "| Isolet |  0.8809 | - | 0.8743 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador estadístico bayesiano:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9800 | 0.9600 | - |\n",
    "| Wine   | 0.9944 | 0.7108 | - |\n",
    "| Cancer | 0.9736 | 0.9613 | - |\n",
    "| Isolet |  1.0000 | - | 0.0648 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios sobre los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijándonos en la columna de aciertos por sustitución, vemos que el estadístico comete menos errores en las 3 bases de datos,\n",
    "siendo mas destacable la diferencia en cuanto al porcentaje de aciertos en las de Wine y Cancer, puesto que pasa de un 72,47%\n",
    "a un 99,44% en Wine y de un 89,1% a un 97,36%. Sin embargo, este incremento de la tasa de aciertos no se corresponde con un\n",
    "aumento real de la precisión del clasificador, si no con un error en la forma de evaluar el rendimiento de los clasificadores.\n",
    "Al evaluar ambos por validación cruzada, comprobamos que el aumento no es tan grande como el obtenido evaluando solo por\n",
    "resusitución, siendo incluso menor la precisión del estadístico en Wine a pesar de que era donde a priori se producia el mayor\n",
    "aumento. A pesar del peor rendimiento obtenido por el bayesiano en Wine, no podemos obviar que ha desempeñado mejor su funcion\n",
    "en las otras dos bases de datos, mostrando incluso un aumento de la tasas de aciertos desde un 88,41% a un 96,13% en Cancer.\n",
    "\n",
    "En cuanto a los resultados obtenidos en Isolet, vemos que los resultados del euclideo concuerdan más con los resultados que se\n",
    "esperan de un clasificador que los del bayesiano. Como podemos ver, en el bayesiano se ha obtenido un 100% de precision por\n",
    "resustitución, sin embargo se ha obtenido un 6,48% por exclusion. Este fenómeno se debe a la existencia de variables linealmente\n",
    "dependientes en el conjunto de entrenamiento de isolet. Debido a las variables colineares, es imposible hallar la inversa de la\n",
    "matriz de covarianzas, por lo que estos datos no se tienen en cuenta afectando negativamente al rendimiento del bayesiano, sin\n",
    "embargo esto no sucede con el euclideo puesto que no tiene en cuenta el factor de la dispersion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
