{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dcae2d-a218-421c-87bd-f7da8443540b",
   "metadata": {},
   "source": [
    "# **Práctica 2**\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cerezo Pomykol, Jan\n",
    "***\n",
    "\n",
    "### **Índice**\n",
    "* [Carga de datasets](#1)\n",
    "* [Entrenamiento y evaluación del Perceptrón](#2)\n",
    "* [Ensemble del clasificador](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b50ba-27f0-4a31-b585-a49c4494ca60",
   "metadata": {},
   "source": [
    "### **Carga de datasets** <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c757e0c9-9393-4a6d-8c07-6e3bfe7aad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, fetch_openml\n",
    "\n",
    "# Iris\n",
    "dataset = load_iris()\n",
    "X_iris = dataset.data\n",
    "y_iris = dataset.target\n",
    "\n",
    "# Wine\n",
    "dataset = load_wine()\n",
    "X_wine = dataset.data\n",
    "y_wine = dataset.target\n",
    "\n",
    "# Cancer\n",
    "dataset = load_breast_cancer()\n",
    "X_cancer = dataset.data\n",
    "y_cancer = dataset.target\n",
    "\n",
    "# Isolet\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_isolet = np.array(X)\n",
    "y_isolet = pd.factorize(y)[0]\n",
    "\n",
    "# MNIST\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"mnist_X.pickle\"):\n",
    "    X = pd.read_pickle('mnist_X.pickle')\n",
    "    y = pd.read_pickle('mnist_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"mnist_X.pickle\")\n",
    "    y.to_pickle(\"mnist_y.pickle\")\n",
    "\n",
    "X_mnist = np.array(X)\n",
    "y_mnist = pd.factorize(y)[0]\n",
    "\n",
    "datasets = {\"iris\": (X_iris, y_iris),\n",
    "            \"wine\": (X_wine, y_wine),\n",
    "            \"cancer\": (X_cancer, y_cancer),\n",
    "            \"isolet\": (X_isolet, y_isolet),\n",
    "            \"mnist\": (X_mnist, y_mnist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03963aea-c2ca-429d-a858-3124ff783ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los datasets:\n",
      "iris:\t(150, 4)\n",
      "wine:\t(178, 13)\n",
      "cancer:\t(569, 30)\n",
      "isolet:\t(7797, 617)\n",
      "mnist:\t(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones de los datasets:\")\n",
    "for i in datasets:\n",
    "    print(i, \":\\t\", datasets[i][0].shape, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edec771-5ed1-4b50-a2ad-1c66ad2ff4b8",
   "metadata": {},
   "source": [
    "## **Entrenamiento y evaluación del Perceptrón** <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe6c4890-7c68-4649-a8d2-7c47b38951ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fa490-86c6-495b-bd05-8a768dbb7b1b",
   "metadata": {},
   "source": [
    "Para la evaluación del perceptrón vamos a emplear la siguiente función, que recibe como parámetros el dataset (X, y) y la lista de valores de fracción de validación. Devuelve como resultado una lista con las tasas de acierto para cada valor de esta lista, así como el índice del mejor valor. Por cada valor de la lista de valores de fracción de validación interna, entrena y evalúa un perceptrón para cada dataset proporcionado por `KFold`. El ratio de aprendizaje $\\delta$ toma el valor $\\frac{1}{k}$, donde $k$ es el orden de la iteración. Este parámetro se corresponde con el atributo `eta0` de la clase Perceptron. En la primera iteración se le asigna valor 1, dado que el número de la iteración es accesible sólo después de ejecutar la primera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265e9423-3e36-4157-baa0-45c45ec03351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_val(X, y, v):\n",
    "    nv = len(v)\n",
    "    scores = np.empty((nv, 10))\n",
    "    scores_mean = np.empty(nv)\n",
    "    best_v = 0\n",
    "    prev = 0\n",
    "    for vi in range(nv):\n",
    "        clf = Perceptron(early_stopping=True, random_state=0, n_jobs=-1, validation_fraction=v[vi])\n",
    "        kf = KFold(n_splits=10)\n",
    "        n_iter = 1\n",
    "        inicial = True\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            if inicial:\n",
    "                clf.set_params(eta0=1)\n",
    "                inicial = False\n",
    "            else:\n",
    "                clf.set_params(eta0=1/clf.n_iter_)\n",
    "            scores[vi][n_iter-1] = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "            n_iter = n_iter + 1\n",
    "        scores_mean[vi] = np.mean(scores[vi])\n",
    "        if scores_mean[vi] > prev:\n",
    "            best_v = vi\n",
    "            prev = scores_mean[vi]\n",
    "    return scores_mean, best_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1889c-045f-40fc-8a44-06d0f081ee3b",
   "metadata": {},
   "source": [
    "## Dataset iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4197c00d-05eb-4000-b2fa-0298776b1c91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: max_score: 0.6667, std: 0.0843, best_val: 0.0250, time: 6.2058s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "interval = 0.1\n",
    "val = np.arange(0.02, 0.4, 0.005)\n",
    "scores, best_v = find_val(X_iris, y_iris, val)\n",
    "print(\"iris: \", \"max_score: %.4f\" % np.max(scores), \", std: %.4f\" % np.std(scores), \", best_val: %.4f\" % val[best_v], \", time: %.4fs\" % (time()-t0), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94240bd2-0c06-4bb2-9465-bfd70c766039",
   "metadata": {},
   "source": [
    "## Dataset wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0294b90a-db08-4654-a9af-3825086044af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine: max_score: 0.8598, std: 0.1814, best_val: 0.4350, time: 14.2372s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "interval = 0.1\n",
    "val = np.arange(0.1, 0.9, 0.005)\n",
    "scores, best_v = find_val(X_wine, y_wine, val)\n",
    "print(\"wine: \", \"max_score: %.4f\" % np.max(scores), \", std: %.4f\" % np.std(scores), \", best_val: %.4f\" % val[best_v], \", time: %.4fs\" % (time()-t0), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad4f47-c27c-4fbd-90c5-c2a10dea8600",
   "metadata": {},
   "source": [
    "## Dataset cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cd7a18-5b40-4f9a-91f3-011ab31fd568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer: max_score: 0.8947, std: 0.0666, best_val: 0.7330, time: 21.0799s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "interval = 0.1\n",
    "val = np.arange(0.1, 0.9, 0.001)\n",
    "scores, best_v = find_val(X_cancer, y_cancer, val)\n",
    "print(\"cancer: \", \"max_score: %.4f\" % np.max(scores), \", std: %.4f\" % np.std(scores), \", best_val: %.4f\" % val[best_v], \", time: %.4fs\" % (time()-t0), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f4b2b-35cb-4b6a-b890-1f15c4511099",
   "metadata": {},
   "source": [
    "## Dataset isolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78d3d648-6f3d-44b0-a976-ea3c7eab33b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolet: max_score: 0.9277, std: 0.0217, best_val: 0.1300, time: 444.1929s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "interval = 0.1\n",
    "val = np.arange(0.1, 0.9, 0.01)\n",
    "scores, best_v = find_val(X_isolet, y_isolet, val)\n",
    "print(\"isolet: \", \"max_score: %.4f\" % np.max(scores), \", std: %.4f\" % np.std(scores), \", best_val: %.4f\" % val[best_v], \", time: %.4fs\" % (time()-t0), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7f117-a2cf-4f35-99e1-386215c22dba",
   "metadata": {},
   "source": [
    "## Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5039698-36e7-4b2e-ae4f-6333175bb49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist: max_score: 0.8688, std: 0.0081, best_val: 0.7000, time: 533.4743s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "val = np.arange(0.05, 1, 0.05)\n",
    "scores, best_v = find_val(X_mnist, y_mnist, val)\n",
    "print(\"mnist: \", \"max_score: %.4f\" % np.max(scores), \", std: %.4f\" % np.std(scores), \", best_val: %.4f\" % val[best_v], \", time: %.4fs\" % (time()-t0), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9bc27-01de-4d3b-961f-477860c14a0d",
   "metadata": {},
   "source": [
    "***\n",
    "#### **Resumen de resultados**\n",
    "\n",
    "**Nota**: no hemos buscado mejores valores, dado que tarda demasiado tiempo en ejecutar la función con datasets grandes.\n",
    "\n",
    "La siguiente tabla muestra la mejor tasa de aciertos que hemos conseguido con el perceptrón para cada dataset, así como el valor de la fracción de validación interna seleccionado.\n",
    "\n",
    "|dataset|fraccion de validación interna|tasa de aciertos|\n",
    "|---|---|---|\n",
    "|iris|0.0250|0.6667|\n",
    "|wine|0.4350|0.8598|\n",
    "|cancer|0.7330|0.8947|\n",
    "|isolet|0.1300|0.9277|\n",
    "|mnist|0.7000|0.8688|\n",
    "\n",
    "#### **Comentarios sobre los resultados**\n",
    "\n",
    "Por lo general, los resultados no han sido tan buenos comparados con los resultados obtenidos en la práctica de la primera parte de la asignatura. Esto se debe a que los clasificadores que vimos tienen la capacidad de clasificar elementos en grupos linealmente no separables. En cambio, la función discriminante del perceptrón es lineal, por tanto hay datasets en los que no proporciona tan buenos resultados. Un ejemplo claro de esto es el dataset iris. Este dataset cuenta con tres clases, de cuales una está separada de las otras dos, pero estas dos últimas se entremezclan. Esto trae como consecuencia el hecho de que no se puede dividir linealmente el conjunto de datos (además de que no son clases separables). El perceptrón asigna correctamente los datos a la primera clase, pero las asignaciones de las otras dos son erróneas en la mitad de las veces. El mejor valor de fracción de validación interna que hemos encontrado para este dataset es 0.025, que da una tasa de aciertos del 66.67% (33.33% de fallos). En cuanto a los resultados obtenidos en los demás datasets, no son tan malos comparados con los de iris. Los mejores resultados se han obtenido con el dataset isolet, con una tasa de aciertos del 92.77% (7.2% de fallos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f547663-16cc-4619-beed-981e7d5f3f3f",
   "metadata": {},
   "source": [
    "## **Ensemble del clasificador** <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fc1fc",
   "metadata": {},
   "source": [
    "A continuación se incluye nuestra implementación necesaria para crear un ensemble de perceptrones, el cual usaremos para evaluar los 5 datasets vistos anteriormente. Además, comentaremos los resultados y los compararemos con otra función de sklearn que permite realizar ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f40958",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### **Código de la función**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "748b20e9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "def ensembler(X, y, name):\n",
    "    X_aux = np.copy(X)\n",
    "    y_aux = np.copy(y)\n",
    "    estimators = []\n",
    "    i = 0\n",
    "    anterior = 0\n",
    "\n",
    "    #mientras haya fallos o sea la primera iteración\n",
    "    while(len(np.unique(y_aux))>1 or i==0):\n",
    "\n",
    "        #se crea un perceptron\n",
    "        clf = Perceptron(eta0=0.5, early_stopping=True, random_state=0)\n",
    "\n",
    "        #se entrena con el dataset de errores de la iteración anterior\n",
    "        clf = clf.fit(X_aux, y_aux)\n",
    "\n",
    "        #se añade a la lista de clasificadores\n",
    "        estimators.append((str(i), clf))\n",
    "\n",
    "        #se crea el ensemble con la lista de clasificadores\n",
    "        Vclf = VotingClassifier(estimators=estimators, voting = 'hard', n_jobs= -1)\n",
    "\n",
    "        #se entrena el ensemble\n",
    "        Vclf = Vclf.fit(X, y)\n",
    "\n",
    "        #se comprueba los aciertos del ensemble\n",
    "        predicts = Vclf.predict(X)\n",
    "        scores = cross_val_score(Vclf, X, y, scoring='accuracy', cv=10)\n",
    "        tasa = scores.mean()\n",
    "\n",
    "        #Se extraen los datos mal clasificados por el ensemble y sus correspondientes etiquetas\n",
    "        X_aux = X[y!=predicts]\n",
    "        y_aux = y[y!=predicts]\n",
    "\n",
    "        #Se comprueba que la tasa de acierto haya mejorado con respecto a la anterior iteración\n",
    "        # que la tasa de acierto sea mayor que el 95%\n",
    "        # y que el numero de clases en las que ha fallado sea mayor que 1 como condiciones de parada\n",
    "\n",
    "        v, c = np.unique(y_aux, return_counts=True)\n",
    "        if(tasa<=anterior or tasa>0.95 or np.sum(c<2)):\n",
    "            break\n",
    "\n",
    "        #se incrementa la iteración y se actualiza la tasa de acierto para la siguiente iteración\n",
    "        i+=+1\n",
    "        anterior = tasa\n",
    "    print(name + \":\\tscore: %0.4f (std: %0.4f)\" % (tasa, scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d69c2c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### **Evaluación de los datasets con la implementación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7b0109-e745-40e4-a898-a72e2e126e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris:\tscore: 0.6667 (std: 0.0000)\n",
      "\ttime: 3.3788s\n",
      "wine:\tscore: 0.5297 (std: 0.1177)\n",
      "\ttime: 0.4461s\n",
      "cancer:\tscore: 0.7823 (std: 0.2063)\n",
      "\ttime: 0.1140s\n",
      "isolet:\tscore: 0.9259 (std: 0.0147)\n",
      "\ttime: 23.7873s\n",
      "mnist:\tscore: 0.8687 (std: 0.0144)\n",
      "\ttime: 194.0456s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "ensembler(X_iris, y_iris, 'iris')\n",
    "print(\"\\ttime: %.4fs\" % (time()-t0))\n",
    "t0 = time()\n",
    "ensembler(X_wine,y_wine, 'wine')\n",
    "print(\"\\ttime: %.4fs\" % (time()-t0))\n",
    "t0 = time()\n",
    "ensembler(X_cancer, y_cancer, 'cancer')\n",
    "print(\"\\ttime: %.4fs\" % (time()-t0))\n",
    "t0 = time()\n",
    "ensembler(X_isolet, y_isolet, 'isolet')\n",
    "print(\"\\ttime: %.4fs\" % (time()-t0))\n",
    "t0 = time()\n",
    "ensembler(X_mnist, y_mnist, 'mnist')\n",
    "print(\"\\ttime: %.4fs\" % (time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95756bd3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***\n",
    "### **Resumen de resultados**\n",
    "\n",
    "\n",
    "|dataset|Tasa de aciertos con el perceptrón|Tasa de aciertos con el ensemble|\n",
    "|---|---|---|\n",
    "|iris|0.6667|0.6667|\n",
    "|wine|0.8598|0.5297|\n",
    "|cancer|0.8947|0.7823|\n",
    "|isolet|0.9277|0.9259|\n",
    "|mnist|0.8688|0.8687|\n",
    "\n",
    "Como podemos observar, los resultados son parecidos a los obtenidos con un sólo perceptrón, exceptuando el dataset wine.\n",
    "Para el dataset Iris, el resultado es exactamente el mismo debido a que los fallos que comete el primer perceptrón pertenecen a una única clase, asi que no es posible entrenar varios perceptrones y por tanto el ensemble consta de uno sólo e igual al perceptrón de la parte anterior. Los resultados de wine son mucho peores, probablemente porque el dataset wine es muy dependiente de la fracción de validación y del ratio de apredizaje y en esta función no se ha implementado la modificación de los parámetros de los perceptrones del ensemble. La misma lógica se puede aplicar al dataset cáncer. Los resultados de isolet y mnist son bastante más parecidos a lo esperado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eb4eab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### **Evaluación de los dataset usando el ensemble de sklearn**\n",
    "\n",
    "En esta parte, emplearemos el Adaptive Boosting de sklearn para crear ensembles con los que evaluar el dataset. Cabe destacar que una de las principales ventajas del Adaptive booster frente al nuestro es que este ensemble nos permite modificar el parámetro de la fracción de validación, por lo que se han usado los parámetros encontrados en la primera parte de la práctica y por tanto los más óptimos para cada dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baea01f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import necesario para usar el Adaptive booster de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44393c72",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d268504-8153-400b-95f1-db741dcbe63e",
   "metadata": {},
   "source": [
    "#### Dataset iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c80a687",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris:\tscore: 0.8133, std: 0.1293, time: 0.4341s\n"
     ]
    }
   ],
   "source": [
    "#Crear el perceptron\n",
    "clf = Perceptron(early_stopping=True, random_state=0, validation_fraction=0.0250, n_jobs=-1)\n",
    "t0 = time()\n",
    "\n",
    "#Crear el ensemble indicando que queremos hasta 5 perceptrones de los anteriores\n",
    "Ada = AdaBoostClassifier(base_estimator=clf, n_estimators=5, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "#Entrenar el ensemble\n",
    "Ada = Ada.fit(X_iris, y_iris)\n",
    "\n",
    "#evaluación con validación cruzada con k=10\n",
    "scores = cross_val_score(Ada, X_iris, y_iris, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"iris:\\tscore: %0.4f, std: %0.4f, time: %.4fs\" % (scores.mean(), scores.std(), time()-t0))\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Iris'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325776ba-12bd-4c58-9f20-14e34a5e5d8f",
   "metadata": {},
   "source": [
    "#### Dataset wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45e5faf3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine:\tscore: 0.6304, std: 0.0753, time: 0.4173s\n"
     ]
    }
   ],
   "source": [
    "#Crear el perceptron\n",
    "clf = Perceptron(early_stopping=True, random_state=0, validation_fraction=0.4350, n_jobs=-1)\n",
    "t0 = time()\n",
    "\n",
    "#Crear el ensemble indicando que queremos hasta 5 perceptrones de los anteriores\n",
    "Ada = AdaBoostClassifier(base_estimator=clf, n_estimators=5, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "#Entrenar el ensemble\n",
    "Ada = Ada.fit(X_wine, y_wine)\n",
    "\n",
    "#evaluación con validación cruzada con k=10\n",
    "scores = cross_val_score(Ada, X_wine, y_wine, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"wine:\\tscore: %0.4f, std: %0.4f, time: %.4fs\" % (scores.mean(), scores.std(), time()-t0))\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Wine'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72d5f8-16ce-4de9-bc8a-7ef8c59c83f3",
   "metadata": {},
   "source": [
    "#### Dataset cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7620021c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer:\tscore: 0.8823, std: 0.0422, time: 0.1029s\n"
     ]
    }
   ],
   "source": [
    "#Crear el perceptron\n",
    "clf = Perceptron(early_stopping=True, random_state=0, validation_fraction=0.7330, n_jobs=-1)\n",
    "t0 = time()\n",
    "\n",
    "#Crear el ensemble indicando que queremos hasta 5 perceptrones de los anteriores\n",
    "Ada = AdaBoostClassifier(base_estimator=clf, n_estimators=5, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "#Entrenar el ensemble\n",
    "Ada = Ada.fit(X_cancer, y_cancer)\n",
    "\n",
    "#evaluación con validación cruzada con k=10\n",
    "scores = cross_val_score(Ada, X_cancer, y_cancer, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"cancer:\\tscore: %0.4f, std: %0.4f, time: %.4fs\" % (scores.mean(), scores.std(), time()-t0))\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Cancer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f205dcb-b4ac-49c6-b969-d20e76c4bcc3",
   "metadata": {},
   "source": [
    "#### Dataset isolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b3a2d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolet:\tscore: 0.9256, std: 0.0153, time: 32.5279s\n"
     ]
    }
   ],
   "source": [
    "#Crear el perceptron\n",
    "clf = Perceptron(early_stopping=True, random_state=0, validation_fraction=0.1300, n_jobs=-1)\n",
    "t0 = time()\n",
    "\n",
    "#Crear el ensemble indicando que queremos hasta 5 perceptrones de los anteriores\n",
    "Ada = AdaBoostClassifier(base_estimator=clf, n_estimators=5, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "#Entrenar el ensemble\n",
    "Ada = Ada.fit(X_isolet, y_isolet)\n",
    "\n",
    "#evaluación con validación cruzada con k=10\n",
    "scores = cross_val_score(Ada, X_isolet, y_isolet, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"isolet:\\tscore: %0.4f, std: %0.4f, time: %.4fs\" % (scores.mean(), scores.std(), time()-t0))\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Isolet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce0894-3b94-4d1a-98e9-f6db174a177a",
   "metadata": {},
   "source": [
    "#### Dataset mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6f735c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist:\tscore: 0.8796, std: 0.0080, time: 147.6491s\n"
     ]
    }
   ],
   "source": [
    "#Crear el perceptron\n",
    "clf = Perceptron(early_stopping=True, random_state=0, validation_fraction=0.7000, n_jobs=-1)\n",
    "t0 = time()\n",
    "\n",
    "#Crear el ensemble indicando que queremos hasta 5 perceptrones de los anteriores\n",
    "Ada = AdaBoostClassifier(base_estimator=clf, n_estimators=5, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "#Entrenar el ensemble\n",
    "Ada = Ada.fit(X_mnist, y_mnist)\n",
    "\n",
    "#evaluación con validación cruzada con k=10\n",
    "scores = cross_val_score(Ada, X_mnist, y_mnist, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"mnist:\\tscore: %0.4f, std: %0.4f, time: %.4fs\" % (scores.mean(), scores.std(), time()-t0))\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Mnist'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855ee9e",
   "metadata": {},
   "source": [
    "***\n",
    "### **Comparativa de resultados**\n",
    "\n",
    "|dataset|Tasa de aciertos con el ensemble implementado|Tasa de aciertos con el ensemble de sklearn|\n",
    "|---|---|---|\n",
    "|iris|0.6667|0.8133|\n",
    "|wine|0.5297|0.6304|\n",
    "|cancer|0.7823|0.8823|\n",
    "|isolet|0.9259|0.9259|\n",
    "|mnist|0.8687|0.8796|\n",
    "\n",
    "En cuanto a los resultados de la comparativa, cabe destacar que la técnica de Adaptive boosting es distinta a la vista en clase e implementada por nosotros, lo que permite evaluar con 5 perceptrones el dataset Iris, por lo que la precisión del AdaBoost es mucho mayor a la nuestra. Para los datasets de wine y cancer, el AdaBoost permite modificar la fracción de validación, por lo que obtiene mayor precisión que nuestro ensemble. En cuanto a los datasets isolet y mnist, los parámetros de los perceptrones no son tan influyentes y el tamaño de los datasets no limita nuestro algoritmo a la hora de crear perceptrones, es por eso por lo que los resultados obtenidos por ambos ensembles son muy similares, siendo AdaBoost solo mejor en mnist en un 1%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
