{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8",
    "tags": []
   },
   "source": [
    "# **Práctica Final Reconocimiento de Formas**\n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cerezo Pomykol, Jan\n",
    "\n",
    "**Nota**: El alumno *Cercadillo Muñoz, Daniel*, que figura como autor en las anteriores entregas, sin haber participado en la elaboración de ninguna de ellas, nos ha confirmado oficialmente que ha abandonado la asignatura, por tanto no consta como autor en esta práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Este notebook de Jupyter contiene las soluciones propuestas a los apartados del enunciado de la práctica correspondiente a la primera parte de la asignatura. Incluye tanto la implementación de los clasificadores como las pruebas realizadas con estos. A continuación se explica brevemente el procedimiento seguido para implementar cada clasificador, así como los métodos de reducción de la dimensionalidad vistos en clase, y que se emplean más adelante:\n",
    "\n",
    "***\n",
    "\n",
    "#### **Clasificador distancia euclídea:**\n",
    "Este clasificador asigna datos según la distancia mínima a los centroides de cada clase.\n",
    "\n",
    "El entrenamiento de este clasificador consiste en calcular los centroides $z_{i}$ de cada clase. Esto es lo que hace la función `fit` del clasificador.\n",
    "\n",
    "$$z_{i} = \\frac{1}{card(\\alpha_{i})}\\sum\\limits _{\\forall x\\in\\alpha_{i}}x$$\n",
    "\n",
    "La predicción consiste en calcular la distancia euclídea de cada vector de entrada a los centroides de cada clase y elegir la clase que se corresponde con la menor distancia euclídea asociada. El cálculo de pertenencia se hace con `decision_function`. La función de pertenencia es la siguiente:\n",
    "\n",
    "$$ de_{i}(x) \\equiv D_{E}(x, z_{i}) = \\sqrt{\\sum\\limits_{j=0}^{n}(x_{j}-z_{i})^{2}}$$\n",
    "\n",
    "Donde $D_{E}(x, z_{i})$ es la distancia eculídea de $x$ al centroide $z_{i}$ y $n$ es la dimensión de cada dato. Dado que esta función proporciona la distancia a una clase, se selecciona el valor mínimo de las distancias a cada clase. Se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg\\min_{j}\\{de_{i}(x)\\} $$\n",
    "\n",
    "Esta operación se ejecuta en la función `predict`.\n",
    "\n",
    "***\n",
    "\n",
    "#### **Clasificador estadístico bayesiano:**\n",
    "\n",
    "Este clasificador parte de la hipótesis de distribución gaussiana. La función de pertenencia del clasificador es la siguiente:\n",
    "\n",
    "$$ db_{i}(x) = -\\frac{1}{2}ln|\\Sigma_{i}|-\\frac{1}{2}(x-\\mu_{i})^{T}\\Sigma_{i}^{-1}(x-\\mu_{i})+\\ln P(\\alpha_{i})$$\n",
    "\n",
    "Donde $\\Sigma_{i}$ es la matriz de covarianzas de la clase $\\alpha_{i}$, $P(\\alpha_{i})$ es la probabilidad a priori de la clase $\\alpha_{i}$, y $\\mu_{i}$ es la media de la clase $\\alpha_{i}$. Dado que esta función proporciona una probabilidad de pertenencia a una clase, se selecciona el valor máximo. Se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg\\max_{j}\\{db_{i}(x)\\} $$\n",
    "\n",
    "En la implementación se emplea $dbq_{i} = \\ln(db_{i}(x))$, que tiene forma cuadrática:\n",
    "\n",
    "$$ dbq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{-1}]x + [\\mu_{i}^{T}\\Sigma_{i}^{-1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "En la implementación (`ClassifEstadistico`), los términos $a$, $b$ y $c$ de la expresión cuadrática $ax^{2}+bx+c$ se corresponden con:\n",
    "\n",
    "$$a = -\\frac{1}{2}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$b = \\mu_{i}^{T}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$c = -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "Estos términos se calculan en el entrenamiento del clasificador `fit`, dado que son independientes del vector $x$ de entrada a la hora de clasificar. En la función clasificadora (`decision_function`), se calcula $dbq_{i}(x)$. De esta forma se reduce el tiempo de clasificación de nuevos datos, aumentando ligeramente el tiempo de entrenamiento (que sólo se hace una vez).\n",
    "\n",
    "El clasificador estadístico regularizado añade dos hiperparámetros en el cálculo de la matriz de covarianzas: $\\lambda$ y $\\gamma$. El primero indica una medida de similitud entre clases, mientras que el segundo sirve para regularizar la matriz de covarianzas. El hiperparámetro $\\lambda$ también indica lo parecida o distinta que es la matriz de covarianzas de la clase a la matriz de covarianzas de todos los datos. Primero se calcula la matriz $\\Sigma_{i}^{\\lambda}$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda} = \\frac{(1-\\lambda)n_{i}\\Sigma_{i} + \\lambda nS_{w}}{(1-\\lambda)n_{i} + \\lambda n}$$\n",
    "\n",
    "Donde $n_{i}$ es el número de representantes de la clase $i$, $n$ es el número total de representantes, y $S_{w}$ es la matriz\n",
    "\n",
    "$$S_{w} = \\sum\\limits_{i=0}^{c}\\frac{n_{i}}{n}\\Sigma_{i}$$\n",
    "\n",
    "donde $c$ es el número de clases. Esta matriz es una matriz de covarianzas de todas las clases, pero teniendo en cuenta la proporción de datos de cada clase.\n",
    "\n",
    "A continuación se calcula la matriz $\\Sigma_{i}^{\\lambda, \\gamma}$, que tiene en cuenta el parámetro $\\gamma$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda, \\gamma} = (1-\\gamma)\\Sigma_{i}^{\\lambda} + \\gamma c_{i} I_{d}$$\n",
    "\n",
    "Donde $I_{d}$ es la matriz identidad $d x d$, $d$ la dimensión de cada representante y $c_{i}$ es:\n",
    "\n",
    "$$c_{i} = \\frac{Tr\\{\\Sigma_{i}^{\\lambda}\\}}{d}$$\n",
    "\n",
    "Con la nueva matriz de covarianzas $\\Sigma_{i}^{\\lambda, \\gamma}$ se obtiene $dbrq_{i}(x)$: \n",
    "\n",
    "$$ dbrq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{\\lambda, \\gamma -1}]x + [\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}^{\\lambda, \\gamma}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "La función de pertenencia sigue siendo la misma: se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg\\max_{j}\\{dbrq_{i}(x)\\} $$\n",
    "\n",
    "***\n",
    "\n",
    "En la sección de implementaciones se incluyen las implemetanciones de los siguientes clasificadores:\n",
    "* **Clasificador de la distancia euclídea**: implementado con la función $de_{i}(x)$. Está disponible en la clase `ClassifEuclid`.\n",
    "* **Clasificador estadístico sin regularizar:** implementado con la función $dbq_{i}(x)$. Está disponible en la clase `ClassifEstadistico`.\n",
    "* **Clasificador estadístico regularizado:** implementado con la función $dbrq_{i}(x)$. Está disponible en la clase `ClassifEstadisticoRegularizado_metodo_clase`.\n",
    "* **Clasificador estadístico regularizado (método de sklearn):** implementado con regularización por autovectores. Está disponible en la clase `ClassifEstadisticoRegularizado_metodo_sklearn`. Este clasificador está basado en la solución por *singular value decomposition*. Esto supone que la matriz de covarianzas $\\Sigma_{i}$ es igual a $\\frac{1}{n-1}X^{T}X = \\frac{1}{n-1}VS^{2}V^{T}$. Donde $V$ proviene de la descomposición de valores singulares de $\\Sigma_{i} = USV^{T}$. Con esto es posible calcular los valores de pertenencia a cada clase sin tener que calcular explícitamente $\\Sigma_{i}^{-1}$, evitando así los errores al intentar invertir una matriz no inversible. Este procedimiento se explica [aquí](https://scikit-learn.org/stable/modules/lda_qda.html#estimation-algorithms). El motivo por el que hemos implementado esta versión es porque con el método de regularización que hemos visto en clase no es posible probar todos los valores de hiperparámetros. La teoría supone que los hiperparámetros $\\lambda$ y $\\gamma$ son lo suficientemente buenos como para que la matriz de covarianzas final no sea singular. Pero cuando se intenta probar un hiperparámetro que no elimina la singularidad, aparecen errores por intentar invertir una matriz no inversible. La solución que hemos tomado en nuestra implementación del clasificador estadístico regularizado (metodo_clase) para que no aparezcan errores es la siguiente. Cuando el determinante de la matriz de covarianzas sea 0, entonces no se asignarán datos a esa clase (se le asigna probabilidad 0). Claramente no es una solución buena, ni tampoco arregla el hecho de que la matriz de covarianzas sea singular, pero al menos podemos probar el clasificador con múltiples combinaciones de $\\lambda$ y $\\gamma$ sin que salten errores al intentar calcular la matriz inversa. De esta forma, si los hiperparámetros con los que se entrena son buenos, entonces la tasa de aciertos será la correcta porque no habrá matrices singulares. En el caso de que sea una combinación mala, la tasa será muy baja. Aún así, nuestro clasificador regularizado sólo lo empleamos para clasificar datos que se han filtrado mediante Análisis de Componentes Principales y/o Análisis Discriminante Lineal, por tanto no deberían aparecer matrices singulares si se estiman bien los parámetros $k$ y $c$ (se explican a continuación).\n",
    "\n",
    "***\n",
    "\n",
    "#### **Técnicas de reducción de la dimensionalidad empleadas:**\n",
    "\n",
    "##### **Análisis de Componentes Principales:**\n",
    "\n",
    "Este método tiene como objetivo eliminar características muy poco discriminantes de un conjunto de datos, de forma que se conserva la mayoría de la información eliminando un número considerable de datos poco relevantes. Esta técnica se puede emplear en múltiples campos, pero detallaremos el procedimiento para esta práctica.\n",
    "\n",
    "Partiendo de un conjunto de datos $X$ que contiene dimensiones que no aportan información dado que la varianza de esa dimensión es muy pequeña, el Análisis de Componentes Principales consiste en escoger las componentes asociadas a las varianzas más altas de cada una de las dimensiones. Dicho de otra forma, es un método de selección de componentes que maximiza la varianza del conjunto de datos.\n",
    "\n",
    "1. El primer paso consiste en calcular la media del vector $X$ de datos.\n",
    "\n",
    "$$\\bar X = \\frac{1}{m}\\sum\\limits_{i=1}^{m}X_{i}$$\n",
    "\n",
    "2. El segundo paso consiste en estandarizar el conjunto de datos. Para ello se resta al vector $X$ su media $\\bar X$.\n",
    "\n",
    "$$\\hat X = X - \\bar X$$\n",
    "\n",
    "3. Se calcula la matriz de covarianzas $\\Sigma_{\\hat X}$ de $\\hat X$.\n",
    "\n",
    "4. Se calcula la descomposición espectral de la matriz $\\Sigma_{\\hat X}$. Los autovalores ordenados de mayor a menor, proporcionan los autovectores correspondientes a las direcciones de máxima varianza del conjunto de datos (se maximiza $\\Sigma_{\\hat X}$). En este punto es posible entender por qué es importante estandarizar los datos (paso 2), veamos un ejemplo. Imaginemos que queremos clasificar personas según su salario anual y el número de días que trabajan al año. Supongamos que en una variable medimos el salario anual de las personas, y en otra el número de días que se trabaja al año. En este caso el salario estará en el rango de las decenas de miles, mientras que el número de días nunca será superior a 365. Si los sueldos de nuestro conjunto de datos varían entre 20.000€ hasta 45.000€ (por ejemplo), y los días varían entre 100 y 300 días, se ve claramente que el autovector asociado al autovalor mayor es el de los salarios. El objetivo del Análisis de Componentes Principales es reducir el conjunto de datos sin perder demasiada información. En este ejemplo, el salario es la variable que tiene mayor varianza. Pero podría darse el caso de que no es la variable más importante para el problema que queremos resolver, por tanto sería incorrecto seleccionar el autovector asociado. Es por esto por lo que es necesario estandarizar los datos.\n",
    "\n",
    "$$\\Sigma_{\\hat X} = P\\Lambda P^{T}$$\n",
    "\n",
    "5. Se construye la matriz de proyección $A$, compuesta por los $k$ autovectores de mayor autovalor asociado ($P_{1-k}$). El valor de $k$ es un hiperparámetro, indica el número de componentes que se conservarán.\n",
    "\n",
    "$$A = P_{1-k}$$\n",
    "\n",
    "6. Se proyectan los datos estandarizados sobre el nuevo espacio:\n",
    "\n",
    "$$X_{pr} = A^{T}\\hat X$$\n",
    "\n",
    "Con el conjunto de datos $X_{pr}$ se entrena el clasificador. Cuando se quiere evaluar, es necesario estandarizar los datos del test y proyectarlos sobre el mismo espacio:\n",
    "\n",
    "$$X_{pr} = A^{T}(X-\\bar X)$$\n",
    "\n",
    "##### **Análisis Discriminante Lineal:**\n",
    "\n",
    "Este método, al igual que el Análisis de Componentes Principales, consiste en reducir la dimensionalidad de un conjunto de datos. Tiene como objetivo maximizar la separación entre las clases, pero minimizando la varianza dentro de cada clase, es decir, maximiza el Ratio de Fisher. Esta técnica también se puede emplear en múltiples campos, pero detallaremos el procedimiento seguido en esta práctica.\n",
    "\n",
    "1. Primero hay que calcular la matrix $S_{w}$, que representa la suma de las covarianzas de cada clase ($\\Sigma_{i}$).\n",
    "\n",
    "$$S_{w} = \\sum\\limits_{i=0}^{c}\\Sigma_{i}$$\n",
    "\n",
    "2. Se calcula la matriz de dispersión entre clases $S_{b}$:\n",
    "\n",
    "$$S_{b} = \\sum\\limits_{i=0}^{c}N_{i}(x_{i}-\\bar x)(x_{i}-\\bar x)^{T}$$\n",
    "\n",
    "Donde $N_{i}$ representa el número de datos de la clase $i$ y $\\bar x$ la media total. Lo que pretende este método es minimizar $S_{w}$ y maximizar $S_{b}$.\n",
    "\n",
    "3. Calcular la descomposición espectral de $S_{w}^{-1}S_{b}$:\n",
    "\n",
    "$$S_{w}^{-1}S_{b} = P\\Lambda P^{T}$$\n",
    "\n",
    "Previamente a este paso, lo que se quería era minimizar $S_{w}$ y maximizar $S_{b}$, pero al invertir la matriz $S_{w}$, ahora lo que se quiere es maximizarla. Los autovectores asociados a los autovalores de mayor valor de esta descomposición espectral nos proporcionan las direcciones en las que hay maxima varianza de $S_{b}$ y máxima varianza de $S_{w}^{-1}$ (que es equivalente a buscar la mínima varianza de $S_{w}$.\n",
    "\n",
    "4. Se construye la matriz de proyección $A$, compuesta por los $c-1$ autovectores de mayor autovalor asociado ($P_{1-(c-1)}$). El valor de $c$ es un hiperparámetro, indica el número de componentes que se conservarán.\n",
    "\n",
    "$$A = P_{1-(c-1)}$$\n",
    "\n",
    "Este método asigna el dato $x$ a la clase que minimize la distancia de Mahalanobis, teniendo en cuenta además la probabilidad a priori de cada clase.\n",
    "Cuando se quiere evaluar, es necesario proyectar los datos del test sobre el mismo espacio:\n",
    "\n",
    "$$X_{pr} = A^{T}X$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementación de clasificadores y funciones auxiliares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y) / len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEuclid(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_clases = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.Z = np.empty((n_clases, n_caracteristicas))\n",
    "        for c in range(n_clases):\n",
    "            self.Z[c] = np.mean(X[y==c], axis=0)\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadistico(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            cov = np.cov(X_clase, rowvar=False)\n",
    "            mu = np.mean(X_clase, axis=0)\n",
    "            cov_inv = np.linalg.inv(cov)\n",
    "            det = np.linalg.det(cov)\n",
    "            self.a[c] = -.5 * cov_inv\n",
    "            self.b[c] = mu.T @ cov_inv\n",
    "            self.c[c] = -.5 * (mu.T @ cov_inv @ mu) -.5 * np.log(det) + np.log(X_clase.shape[0] / X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado (método visto en clase, explicado en la introducción)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_clase2(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = []\n",
    "        self.b = []\n",
    "        self.c = []\n",
    "        self.dont_ignore = None\n",
    "\n",
    "    def fit(self, X, y, l=0, g=0):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        l: (lambda) hiperparámetro de similitud entre matrices de covarianza (ver introduccion)\n",
    "        g: (gamma) hiperparámetro de regularización (ver introduccion)\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        tol = 1e-1\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.dont_ignore = np.var(X - np.mean(X, axis=0), axis=0) > tol\n",
    "\n",
    "        for c in range(n_labels):\n",
    "            X_clase = X[y==c][:, self.dont_ignore]\n",
    "            mu = np.mean(X_clase, axis=0)\n",
    "            cov = np.cov(X_clase, rowvar=False)\n",
    "            print(len(np.diagonal(cov) < tol))\n",
    "            det = np.linalg.det(cov)\n",
    "            cov_inv = np.linalg.inv(cov)\n",
    "            priori = X_clase.shape[0] / X.shape[0]\n",
    "            self.a.append(-.5 * self.cov_lg_inv[c])\n",
    "            self.b.append(self.mu[c].T @ cov_inv)\n",
    "            self.c.append(-.5 * (mu.T @ cov_inv @ mu) -.5 * np.log(det) + np.log(priori))\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        X_data = X[:, self.dont_ignore]\n",
    "        res = np.zeros((X.shape[0], len(self.labels)))\n",
    "        for c in self.dont_ignore:\n",
    "            #res[:,c] = -.5 * np.log(self.det[c]) - .5 * np.diagonal((X - self.mu[c]) @ self.cov_lg_inv[c] @ (X - self.mu[c]).T) + np.log(self.priori)\n",
    "            res[:,c] = np.einsum('ab,db,ad->a', X_data, self.a[c], X_data) + np.einsum('b,cb->c', self.b[c], X_data) + self.c[c]\n",
    "        return res\n",
    "        #return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n",
    "\n",
    "class ClassifEstadisticoRegularizado_metodo_clase(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.dont_ignore = []\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self, X, y, l=0, g=0):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        l: (lambda) hiperparámetro de similitud entre matrices de covarianza (ver introduccion)\n",
    "        g: (gamma) hiperparámetro de regularización (ver introduccion)\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        cov_pooled = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "        for c in range(n_labels):\n",
    "            X_clase = X[y==c]\n",
    "            cov[c] = np.cov(X_clase, rowvar=False)\n",
    "            cov_pooled = cov_pooled + ((X_clase.shape[0] / X.shape[0]) * cov[c])  # Matriz Sw en el libro de Webb (formula 2.15, pagina 42)\n",
    "        for c in range(n_labels):\n",
    "            X_clase = X[y==c]\n",
    "            mu = np.mean(X_clase, axis=0)\n",
    "            cov_l = (((1 - l) * X_clase.shape[0] * cov[c]) + (l * X.shape[0] * cov_pooled)) / ((1 - l) * X_clase.shape[0] + l * X.shape[0])\n",
    "            cov_lg = (1 - g) * cov_l + g * (np.trace(cov_l) / n_caracteristicas) * np.eye(n_caracteristicas)\n",
    "            det = np.linalg.det(cov_lg)\n",
    "            if det > 0:\n",
    "                cov_lg_inv = np.linalg.inv(cov_lg)\n",
    "                priori = X_clase.shape[0] / X.shape[0]\n",
    "                self.dont_ignore.append(c)\n",
    "                self.a[c] = -.5 * cov_lg_inv\n",
    "                self.b[c] = mu.T @ cov_lg_inv\n",
    "                self.c[c] = -.5 * (mu.T @ cov_lg_inv @ mu) -.5 * np.log(det) + np.log(priori)\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.zeros((X.shape[0], len(self.labels)))\n",
    "        for c in self.dont_ignore:\n",
    "            #res[:,c] = -.5 * np.log(self.det[c]) - .5 * np.diagonal((X - self.mu[c]) @ self.cov_lg_inv[c] @ (X - self.mu[c]).T) + np.log(self.priori[c])\n",
    "            res[:,c] = np.einsum('ab,db,ad->a', X, self.a[c], X) + np.einsum('b,cb->c', self.b[c], X) + self.c[c]\n",
    "        return res\n",
    "        #return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado por autovectores (método de sklearn)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_sklearn(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        self.labels = labels\n",
    "        self.reg_param = 0 # hiperparametro\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.prob_clases = None\n",
    "        self.ajustes = []\n",
    "        self.autovectores = []\n",
    "    \n",
    "    def fit(self, X, y, reg_param=0):\n",
    "        self.reg_param = reg_param\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.prob_clases = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c, :]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            X_new = X_clase - self.mu[c]\n",
    "            # descomposicion espectral\n",
    "            _, autovalores, autovectores = np.linalg.svd(X_new, full_matrices=False)\n",
    "            ajuste = (autovalores ** 2) / (X_new.shape[0] - 1)\n",
    "            ajuste = ((1 - self.reg_param) * ajuste) + self.reg_param\n",
    "            self.cov[c] = (ajuste * autovectores.T) @ autovectores # np.dot(ajuste * autovectores.T, autovectores)\n",
    "            self.ajustes.append(np.copy(ajuste))\n",
    "            self.autovectores.append(np.copy(autovectores))\n",
    "            self.prob_clases[c] = X_clase.shape[0] / X.shape[0]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.empty((X.shape[0], len(self.labels)))\n",
    "        for c in range(len(self.labels)):\n",
    "            res[:,c] = np.sum(((X - self.mu[c]) @ (self.autovectores[c] * (self.ajustes[c] ** -.5)[:, None]).T) ** 2, axis=1)\n",
    "        aux = np.asarray([np.sum(np.log(x)) for x in self.ajustes])\n",
    "        return (-.5 * (res.T + aux[:, None]) + np.log(self.prob_clases)[:, None]).T\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clase Splitter para GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusionSplitter:\n",
    "    \"\"\"Esta clase nos permite usar GridSearchCV con la valuación por exclusion.\"\"\"\n",
    "    def __init__(self, train_indices, test_indices):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return [(self.train_indices, self.test_indices)]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de Grid Search, pero sin Cross Validation**\n",
    "La base de datos Isolet NO la podemos evaluar con CrossValidation porque cuenta con unos 8000 datos, que son demasiados para computar en un tiempo razonable. Esta función evalua el clasificador estadístico regularizado implementado por nosotros por medio de exclusión para cada combinación de hiperparámetros $\\gamma = 0.0, 0.1, 0.2, \\dots, 1.0$ y $\\lambda = 0.0, 0.1, 0.2, \\dots, 1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def GridSearchExclusion(X_train, y_train, X_test, y_test):\n",
    "    g = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # hiperparametro gamma (ver clasificador estadistico regularizado en la introduccion)\n",
    "    l = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] # hiperparametro lambda (ver clasificador estadistico regularizado en la introduccion)\n",
    "    scores_exclusion = np.empty((len(g), len(l)))\n",
    "    t0 = time()\n",
    "    best_g = [0.0]\n",
    "    best_l = [0.0]\n",
    "    best_score = 0.0\n",
    "    for gi in range(len(g)):\n",
    "        for li in range(len(l)):\n",
    "            clss_est = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "            clss_est.fit(X_train, y_train, l=l[li], g=g[gi])\n",
    "            scores_exclusion[gi][li] = clss_est.score(X_test, y_test)\n",
    "            if scores_exclusion[gi][li] == best_score:\n",
    "                best_g.append(g[gi])\n",
    "                best_l.append(l[li])\n",
    "            if scores_exclusion[gi][li] > best_score:\n",
    "                best_g = [g[gi]]\n",
    "                best_l = [l[li]]\n",
    "                best_score = scores_exclusion[gi][li]\n",
    "    print(\"Finalizado en %.3fs\" % (time() - t0))\n",
    "    return scores_exclusion, best_g, best_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de una función que dibuja en un mapa de calor las puntuaciones dadas por** `GridSearchExclusion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_scores(scores):\n",
    "    im = plt.imshow(scores, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "    plt.title(\"scores\")\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"gamma\")\n",
    "    cax = plt.axes([0.83, 0.12, 0.05, 0.76])\n",
    "    plt.colorbar(cax=cax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de una función que imprime las componentes y la varianza acumulada de cada una (ver Evaluación de Isolet con ACP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cumvar(autoval, n_datos, start, end):\n",
    "    # Primero se calcula la varianza que proporciona cada componente\n",
    "    var_autoval = (autoval ** 2) / (X_train.shape[0] - 1)\n",
    "    # Se calcula el ratio en funcion del total que la varianza de cada componente proporciona \n",
    "    var_ratio = var_autoval / np.sum(var_autoval)\n",
    "    # Se obtienen las varianzas acumuladas por cada componente\n",
    "    cum_var = np.cumsum(var_ratio)\n",
    "    # Visualizar las varianzas cumulativas correspondientes a las componentes principales del intervalo [start, end]\n",
    "    index=0\n",
    "    for e in range(start-1, end):\n",
    "        print(\"\\t\", \"%3d\" % (e+1), \": \", \"%.6f\" % cum_var[e], sep='', end='')\n",
    "        index = index + 1\n",
    "        if index % 9 == 0:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores_copy_paste(scores):\n",
    "    print('[', end='')\n",
    "    for q1 in scores:\n",
    "        print('[', end='')\n",
    "        for q2 in q1:\n",
    "            print(\"%.6f, \" % q2, end='')\n",
    "        print('],')\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "# **Entrenamiento, predicción y evaluación de iris, wine y cancer**\n",
    "A continuación se realizan las pruebas correspondientes con las bases de datos iris, wine y cancer con el clasificador estadístico y el clasificador de la distancia euclídea. Al final se incluye una tabla resumen con los resultados. Por cada clasificador y base de datos se imprime el resultado obtenido por el clasificador equivalente de sklearn, con el fin de verificar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: datos: (150, 4) n_clases: 3\n",
      "\tclase 0:\t50 datos\n",
      "\tclase 1:\t50 datos\n",
      "\tclase 2:\t50 datos\n",
      "wine: datos: (178, 13) n_clases: 3\n",
      "\tclase 0:\t59 datos\n",
      "\tclase 1:\t71 datos\n",
      "\tclase 2:\t48 datos\n",
      "cancer: datos: (569, 30) n_clases: 2\n",
      "\tclase 0:\t212 datos\n",
      "\tclase 1:\t357 datos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Load data\n",
    "dataset_iris = load_iris()\n",
    "X_iris = dataset_iris.data\n",
    "y_iris = dataset_iris.target\n",
    "dataset_wine = load_wine()\n",
    "X_wine = dataset_wine.data\n",
    "y_wine = dataset_wine.target\n",
    "dataset_cancer = load_breast_cancer()\n",
    "X_cancer = dataset_cancer.data\n",
    "y_cancer = dataset_cancer.target\n",
    "print(\"iris: datos:\", X_iris.shape, \"n_clases:\", len(np.unique(y_iris)))\n",
    "for e in np.unique(y_iris):\n",
    "    print(\"\\tclase %d:\\t%d datos\" % (e, X_iris[y_iris==e].shape[0]))\n",
    "print(\"wine: datos:\", X_wine.shape, \"n_clases:\", len(np.unique(y_wine)))\n",
    "for e in np.unique(y_wine):\n",
    "    print(\"\\tclase %d:\\t%d datos\" % (e, X_wine[y_wine==e].shape[0]))\n",
    "print(\"cancer: datos:\", X_cancer.shape, \"n_clases:\", len(np.unique(y_cancer)))\n",
    "for e in np.unique(y_cancer):\n",
    "    print(\"\\tclase %d:\\t%d datos\" % (e, X_cancer[y_cancer==e].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 139/150 (92.67%)\n",
      "\t\tEvaluación por resustitución: 0.9267\n",
      "\t\tEvaluación por validación cruzada: 0.9133, std: 0.0499\n",
      "\t\tClasificador sklearn: 139 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_iris.target_names)\n",
    "clsf_euc.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 129/178 (72.47%)\n",
      "\t\tEvaluación por resustitución: 0.7247\n",
      "\t\tEvaluación por validación cruzada: 0.7187, std: 0.0804\n",
      "\t\tClasificador sklearn: 129 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_wine.target_names)\n",
    "clsf_euc.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_euc, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 507/569 (89.10%)\n",
      "\t\tEvaluación por resustitución: 0.8910\n",
      "\t\tEvaluación por validación cruzada: 0.8841, std: 0.0840\n",
      "\t\tClasificador sklearn: 507 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_cancer.target_names)\n",
    "clsf_euc.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_euc, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 147/150 (98.00%)\n",
      "\t\tEvaluación por resustitución: 0.9800\n",
      "\t\tEvaluación por validación cruzada: 0.9600, std: 0.0646\n",
      "\t\tClasificador sklearn: 147 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_iris.target_names)\n",
    "clsf_est.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_est.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_est, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 177/178 (99.44%)\n",
      "\t\tEvaluación por resustitución: 0.9944\n",
      "\t\tEvaluación por validación cruzada: 0.7108, std: 0.3660\n",
      "\t\tClasificador sklearn: 177 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_wine.target_names)\n",
    "clsf_est.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_est.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_est, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 554/569 (97.36%)\n",
      "\t\tEvaluación por resustitución: 0.9736\n",
      "\t\tEvaluación por validación cruzada: 0.9613, std: 0.0090\n",
      "\t\tClasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_cancer.target_names)\n",
    "clsf_est.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_est.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_est, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resultados de los tres experimentos (**clasificador distancia euclídea**):\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 0.9267 | 0.9133 |\n",
    "| Wine   | 0.7247 | 0.7187 |\n",
    "| Cancer | 0.8910 | 0.8841 |\n",
    "\n",
    "Resultados de los tres experimentos (**clasificador estadístico**):\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 0.9800 | 0.9600 |\n",
    "| Wine   | 0.9944 | 0.7108 |\n",
    "| Cancer | 0.9736 | 0.9613 |\n",
    "\n",
    "Dimensiones de las bases de datos:\n",
    "\n",
    "| Base de datos | Número de clases | Número de datos | Dimension de cada dato |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 3 | 150 | 4 |\n",
    "| Wine   | 3 | 178 | 13 |\n",
    "| Cancer | 2 | 569 | 30 |\n",
    "\n",
    "Como se puede observar, el clasificador estadístico tiene mejor tasa de aciertos con iris y cancer, comparado con el de la distancia euclídea. Esto se debe a que las clases no están muy separadas y la dispersión dentro de cada clase es alta. Es decir, el Ratio de Fisher es bajo. El clasificador estadístico funciona mejor en estas situaciones porque la frontera de indecisión del clasificador estadístico entre dos clases se puede adaptar más que la del clasificador de la distancia euclídea. En el clasificador de la distancia euclídea, las fronteras de indecisión siempre son puntos (en una dimensión), rectas (en dos dimensiones), planos (en tres dimensiones), hiperplanos (en cuatro dimensiones), etc. En el caso del clasificador estadístico, si las clases tienen la misma matriz de covarianzas, las fronteras de indecisión son iguales que en el de la distancia euclídea. Pero si las clases tienen distintas matrices de covarianzas, entonces las fronteras de indecisión pueden tomar formas curvadas que se adaptan mejor a la distribución de las clases.\n",
    "\n",
    "En el caso de la base de datos iris, vemos que el clasificador de la distancia euclídea funciona relativamente bien. Esto se debe a que las clases son muy separables, el Ratio de Fisher es muy alto (cuando este clasificador da mejores resultados). Tanto wine como cancer no tienen las clases lo suficientemente separadas como para que el clasificador de la distancia euclídea de muy buenos resultados. La separabilidad entre las clases se puede compensar con el clasificador estadístico, que da mejores tasas de aciertos en las bases de datos iris y cancer.\n",
    "\n",
    "La base de datos wine presenta 178 datos con 13 características. El motivo por el que da peores resultados es porque se da el fenómeno de *underfitting*. Se proporcionan pocos datos comparados con el número de dimensiones, por lo que el sesgo es muy alto.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento y evaluación de Isolet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_train = np.array(X[:6238])\n",
    "y_train = pd.factorize(y)[0][:6238]\n",
    "X_test = np.array(X[6238:])\n",
    "y_test = pd.factorize(y)[0][6238:]\n",
    "\n",
    "X = np.array(X)\n",
    "y = pd.factorize(y)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolet: datos: (7797, 617) n_clases: 26\n",
      "\tClasificador distancia euclídea:\n",
      "\t\tEvaluación por resustitución:\t 0.8809\n",
      "\t\tEvaluación por exclusión:\t 0.8743\n",
      "\tClasificador estadístico regularizado con el método de clase:\n",
      "\t\tEvaluación por resustitución:\t 0.0384738698\n",
      "\t\tEvaluación por exclusión:\t 0.0384862091\n",
      "\tClasificador estadístico regularizado con el método de sklearn:\n",
      "\t\tEvaluación por resustitución:\t 1.0000\n",
      "\t\tEvaluación por exclusión:\t 0.0648\n",
      "\tClasificador estadístico de sklearn:\n",
      "\t\tEvaluación por resustitución:\t 1.0000\n",
      "\t\tEvaluación por exclusión:\t 0.0648\n"
     ]
    }
   ],
   "source": [
    "# Clasificador distancia euclidea\n",
    "clss_euc = ClassifEuclid(np.unique(y_train))\n",
    "clss_euc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de clase\n",
    "clss_est_mc = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "clss_est_mc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de sklearn\n",
    "clss_est_msk = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est_msk.fit(X_train, y_train)\n",
    "# Clasificador estadístico de sklearn\n",
    "clss_est_sk = QuadraticDiscriminantAnalysis()\n",
    "clss_est_sk.fit(X_train, y_train)\n",
    "\n",
    "print(\"isolet: datos:\", X.shape, \"n_clases:\", len(np.unique(y)))\n",
    "\n",
    "print(\"\\tClasificador distancia euclídea:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_euc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_euc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de clase:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.10f\" % clss_est_mc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.10f\" % clss_est_mc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_msk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_msk.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_sk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_sk.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**\n",
    "\n",
    "| Clasificador | Acierto resustitucion | Acierto exclusion |\n",
    "| --- | --- | --- |\n",
    "| distancia euclídea   | 0.8809 | 0.8743 |\n",
    "| estadístico regularizado (metodo_clase)   | 0.038473 | 0.038486 |\n",
    "| estadístico regularizado (metodo_sklearn) | 1.0000 | 0.0648 |\n",
    "| estadístico de sklearn |  1.0000 | 0.0648 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comentarios sobre los resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando la tabla vemos que los resultados obtenidos por el clasificador de la distancia euclídea son decentes, mientras que los resultados obtenidos por los clasificadores estadísticos son pésimos., excepto en la evaluación por resustitución. Esto se debe a que el clasificador memoriza todos los datos. Los resultados de las pruebas por exclusión se deben a que la mayoría de las dimensiones de los datos no proporcionan información adicional (son variables colineares). Es por esto por lo que es imposible hallar la inversa de la matriz de covarianzas, que provoca que estos datos sean \"memorizados\" por el clasificador, causando un alto grado de *overfitting* como se puede ver por su alta tasa de aciertos en el conjunto de entrenamiento y su pésimo desempeño en el conjunto de test. Sin embargo esto no sucede con el euclideo puesto que no tiene en cuenta el factor de la dispersion de los datos y por tanto tampoco la independencia lineal de los vectores de la matriz de covarianza.\n",
    "\n",
    "El motivo por el que nuestra implementación da malos resultados en ambos tipos de evaluación es por lo que se explicó en la introducción. No se tienen en cuenta las clases cuyas matrices de covarianza sean singulares. Nuestra implementación sólo da buenos resultados con la combinación idónea de hiperparámetros, que en este caso son los valores por defecto ($\\lambda=0.0$ y $\\gamma=0.0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet con hiperparámetros**\n",
    "\n",
    "Ahora vamos a entrenar y evaluar el clasificador estadístico regularizado de sklearn con la base de datos Isolet. El motivo por el que empleamos el de sklearn y no nuestra implementación es porque el nuestro no está adaptado para ejecutar GridSearchCV. Más adelante se evalúa nuestra implementación con los hiperparámetros correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Funcion que evalua el clasificador con cada uno de los hiperparametros\n",
    "def find_best_parameters_quad(X, y, k, shrinkages):\n",
    "    # Creamos una instancia del clasificador\n",
    "    cbp = QuadraticDiscriminantAnalysis()\n",
    "    # definimos la rejilla en la que vamos a buscar\n",
    "    params = {'reg_param': shrinkages}\n",
    "    # Creamos una clase GridSearchCV que será una especie de supra-clasificador\n",
    "    # que se ajusta por validación cruzada.\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-1, scoring='accuracy', cv=k).fit(X, y)\n",
    "    # Como supra-clasificador que es, clf contiene todo tipo de datos sobre la evaluación\n",
    "    # por validación cruzada. Vamos a obtener en este caso el clasificador con mejor 'accuracy'\n",
    "    best_clf = clf.best_estimator_\n",
    "    # clf.cv_results_ contiene los resultados de la evaluación, obtengamos la media y\n",
    "    # desviación típica del score de validación\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "    # print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "\n",
    "    # Imprimamos los mejores parametro que hemos encontrado y el resultado de su validación\n",
    "    print(\"\\tSelected shrinkage = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.reg_param, result_score_mean, result_score_std))\n",
    "    return best_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar un hiperparámetro lo suficientemente bueno.\n",
    "Primero se prueba con 0.0, 0.1, 0.2, ..., 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelected shrinkage = 0.2\n",
      "\tAccuracy: 0.956 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# primero probar con 0.0, 0.1, 0.2, ..., 1.0\n",
    "h = [i/10 for i in range(11)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor de la lista anterior es 0.2, ahora se probarán los cercanos a 0.2: 0.10, 0.11, ..., 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelected shrinkage = 0.23\n",
      "\tAccuracy: 0.956 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# Probar con 0.10, 0.11, ..., 0.30\n",
    "h = [i/100 for i in range(10, 30)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor de la lista anterior es 0.23, ahora se probarán los cercanos a 0.23: 0.220, 0.221, 0.222, ..., 0.239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelected shrinkage = 0.23\n",
      "\tAccuracy: 0.956 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "# Probar con 0.220, 0.221, 0.222, ..., 0.239\n",
    "h = [i/1000 for i in range(220, 240)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor hiperparámetro que hemos encontrado (para el clasificador de sklearn) es 0.23, que proporciona una tasa de aciertos del 95,6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet** tras hacer un **Análisis de Componentes Principales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver sección de **Análisis de Componentes Principales** de la introducción. Se toma como base el hiperparámetro que indica número de componentes principales que seleccionamos. Este hiperparámetro indica el número de columnas que tendrá la matriz de proyección $A$. En el siguiente fragmento de código se toma como estimación base que $k=100$.\n",
    "\n",
    "En esta sección se prueba nuestra implementación del clasificador estadístico con todas las combinaciones de hiperparámetros $\\gamma$ y $\\lambda$ de la lista 0.0, 0.1, 0.2, ..., 1.0. No se prueba con listas más extensas porque tardaría demasiado en ejecutar. Tampoco se evalua con GridSearchCV por el mismo motivo. Se emplea la función `GridSearchExclusion`, definida en la parte de implementaciones, que evalúa por exclusión el clasificador estadístico regularizado (método de clase) con cada combinación de hiperparámetros $\\lambda$ y $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final: (6238, 100)\n",
      "X_test_final: (1559, 100)\n"
     ]
    }
   ],
   "source": [
    "# Paso 0: seleccionar el número de componentes principales\n",
    "n_componentes = 100 # hiperparámetro\n",
    "\n",
    "# Paso 1: calcular la media del conjunto de datos de entrenamiento\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "# Paso 2: estandarizar el conjunto de datos de entrenamiento\n",
    "X_norm = X_train - X_train_mean\n",
    "\n",
    "# Paso 3: calcular la nueva matriz de covarianzas del conjunto de datos estandarizados\n",
    "X_train_cov = np.cov(X_norm, rowvar=False)\n",
    "\n",
    "# Paso 4: calcular la descomposición espectral de la matriz de covarianzas\n",
    "u, autoval, autovec = np.linalg.svd(X_train_cov, full_matrices=False) # tarda 68.246s\n",
    "\n",
    "# Paso 5: construir la matriz de proyección A seleccionando las n_componentes componentes principales\n",
    "A = autovec[:n_componentes]\n",
    "\n",
    "# Paso 6: proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "\n",
    "# Paso 7: proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto tenemos `X_train_final` y `X_test_final` (ambos con 100 componentes), proyectado sobre el nuevo espacio. Ahora hay que entrenar el clasificador y evaluarlo con los nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.9660\n",
      "best hyperparams:\n",
      "\tgamma: 0.1 lambda: 0.1\n",
      "\tgamma: 0.5 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Paso 8: entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 38 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion\n",
    "#             por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.910199, 0.962155, 0.958307, 0.953175, 0.947402, 0.944836, 0.944195, 0.941629, 0.939064, 0.939064, 0.939064],\n",
    "                            [0.951251, 0.966004, 0.959589, 0.951892, 0.949326, 0.948685, 0.946119, 0.943554, 0.942912, 0.939705, 0.938422],\n",
    "                            [0.959589, 0.964721, 0.957024, 0.952534, 0.948685, 0.946761, 0.944195, 0.939705, 0.937139, 0.937139, 0.935856],\n",
    "                            [0.961514, 0.962155, 0.954458, 0.949326, 0.945478, 0.942271, 0.940346, 0.939064, 0.937139, 0.936498, 0.936498],\n",
    "                            [0.965362, 0.957665, 0.953175, 0.948044, 0.944836, 0.942271, 0.941629, 0.939064, 0.936498, 0.934573, 0.934573],\n",
    "                            [0.966004, 0.958307, 0.949326, 0.944195, 0.940988, 0.940988, 0.939064, 0.937781, 0.936498, 0.934573, 0.934573],\n",
    "                            [0.964721, 0.953175, 0.942271, 0.938422, 0.938422, 0.937781, 0.935215, 0.933932, 0.933932, 0.932649, 0.932649],\n",
    "                            [0.959589, 0.947402, 0.937781, 0.936498, 0.934573, 0.932649, 0.932649, 0.931366, 0.929442, 0.929442, 0.929442],\n",
    "                            [0.957024, 0.940346, 0.933932, 0.929442, 0.926876, 0.926235, 0.924952, 0.923028, 0.921745, 0.921103, 0.919820],\n",
    "                            [0.942912, 0.923028, 0.917896, 0.912123, 0.910840, 0.909557, 0.908275, 0.907633, 0.907633, 0.906992, 0.906992],\n",
    "                            [0.871071, 0.874278, 0.872996, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354]])\n",
    "\n",
    "best_g = [0.1, 0.5]\n",
    "best_l = [0.1, 0.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes gráficos se muestran las puntuaciones del clasificador estadístico regularizado (con el método de clase) para cada valor de los hiperparámetros $\\lambda$ y $\\gamma$. Se han empleado los datos `X_train_final` y `X_test_final`, que se han obtenido previamente seleccionando las 100 primeras componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, por lo general cuanto menor sea el valor del hiperparámetro $\\lambda$, mejores resultados se obtiene. Los mejores resultados se obtienen cuando $\\gamma$ = 0,5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del hiperparámetro $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado en la introducción, el Análisis de Componentes Principales selecciona las componentes de máxima varianza, es decir, selecciona las que aportan más información. El hiperparámetro $k$ indica el número de componentes que se seleccionan. Ahora, en vez de estimar el hiperparámetro $k$, vamos a seleccionarlo de otra forma más interesante. Vamos a calcular el valor de $k$ para que la varianza de las $k$ componentes principales sea superior al 99% de la varianza total del conjunto de datos. Vamos a seguir el procedimiento indicado en la sección de Análisis de Componentes Principales de la introducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  1: 0.749930\t  2: 0.845959\t  3: 0.893969\t  4: 0.919388\t  5: 0.939298\t  6: 0.952600\t  7: 0.962024\t  8: 0.968061\t  9: 0.972753\n",
      "\t 10: 0.976524\t 11: 0.979081\t 12: 0.981289\t 13: 0.983410\t 14: 0.985319\t 15: 0.986814\t 16: 0.988062\t 17: 0.989209\t 18: 0.990238\n",
      "\t 19: 0.991113\t 20: 0.991756\t 21: 0.992346\t 22: 0.992880\t 23: 0.993340\t 24: 0.993776\t 25: 0.994184\t 26: 0.994546\t 27: 0.994870\n",
      "\t 28: 0.995189\t 29: 0.995434\t 30: 0.995661\t 31: 0.995884\t 32: 0.996088\t 33: 0.996269\t 34: 0.996447\t 35: 0.996620\t 36: 0.996777\n",
      "\t 37: 0.996923\t 38: 0.997062\t 39: 0.997196\t 40: 0.997319\t 41: 0.997432\t 42: 0.997539\t 43: 0.997640\t 44: 0.997736\t 45: 0.997828\n",
      "\t 46: 0.997909\t 47: 0.997987\t 48: 0.998062\t 49: 0.998132\t 50: 0.998198\t 51: 0.998261\t 52: 0.998324\t 53: 0.998381\t 54: 0.998438\n",
      "\t 55: 0.998490\t 56: 0.998541\t 57: 0.998590\t 58: 0.998637\t 59: 0.998682\t 60: 0.998726\t 61: 0.998767\t 62: 0.998807\t 63: 0.998845\n",
      "\t 64: 0.998882\t 65: 0.998917\t 66: 0.998952\t 67: 0.998985\t 68: 0.999015\t 69: 0.999044\t 70: 0.999072\t 71: 0.999099\t 72: 0.999124\n",
      "\t 73: 0.999148\t 74: 0.999172\t 75: 0.999195\t 76: 0.999217\t 77: 0.999238\t 78: 0.999258\t 79: 0.999278\t 80: 0.999297\t 81: 0.999315\n",
      "\t 82: 0.999333\t 83: 0.999351\t 84: 0.999368\t 85: 0.999384\t 86: 0.999399\t 87: 0.999414\t 88: 0.999428\t 89: 0.999442\t 90: 0.999456\n",
      "\t 91: 0.999469\t 92: 0.999482\t 93: 0.999495\t 94: 0.999507\t 95: 0.999518\t 96: 0.999530\t 97: 0.999541\t 98: 0.999552\t 99: 0.999562\n",
      "\t100: 0.999572"
     ]
    }
   ],
   "source": [
    "print_cumvar(autoval, X_train.shape[0], 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores mostrados muestran el índice de la componente, y la varianza acumulada de esa componente y las componentes previas. Como se puede observar, la primera componente proporciona el 74.99% de la varianza del conjunto de datos. Si queremos escoger las $k$ primeras componentes para conservar el 99% de la varianza del conjunto de datos, nos vale con seleccionar 18 componentes. Vamos a confirmar ahora que los resultados con 18 componentes no varían mucho comparados con los de 100 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final: (6238, 18)\n",
      "X_test_final: (1559, 18)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 18 primeras componentes\n",
    "A = autovec[:18]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado en 1.674s\n",
      "max_score exclusion:\t\t0.9140\n",
      "best hyperparams:\n",
      "\tgamma: 0.1 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos y evaluamos el clasificador con los hiperparámetros\n",
    "scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, este código se ha ejecutado en unos 2 segundos, mientras que el anterior ha tardado más de 30 (en mi ordenador). Obviamente se debe a la reducción en la dimensionalidad: se ha pasado de manejar matrices de 6238x100 a matrices de 6238x18. La puntuación con 100 componentes es 0.9660, mientras que con 18 componentes es 0.9140. Se ha reducido el tiempo de cómputo en un 97%, sacrificando sólo un 5,2% de precisión. Vamos a probar ahora cuánta precisión se obtiene tomando las $k$ primeras componentes, de forma que se conserva un 99,9% de la varianza total. Viendo los valores de varianzas acumuladas impresos anteriormente, nos basta con seleccionar las 68 primeras, conservando un 99,9015% de la varianza total. Una de las ventajas del método de Análisis de Componentes Principales es que no es necesario recalcular la matriz de proyección $A$ si se quiere probar con un $k$ distinto. Repetimos los pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final: (6238, 68)\n",
      "X_test_final: (1559, 68)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 68 primeras componentes\n",
    "A = autovec[:68]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.9666\n",
      "best hyperparams:\n",
      "\tgamma: 0.4 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos y evaluamos el clasificador con los hiperparámetros\n",
    "\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 15 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.930725, 0.958948, 0.949968, 0.948044, 0.943554, 0.942271, 0.940346, 0.938422, 0.937139, 0.935215, 0.935215],\n",
    "                            [0.950609, 0.959589, 0.951892, 0.946761, 0.944836, 0.944836, 0.940988, 0.937781, 0.937139, 0.935856, 0.935215],\n",
    "                            [0.957665, 0.958948, 0.949326, 0.946119, 0.943554, 0.942271, 0.940988, 0.939064, 0.937139, 0.936498, 0.935856],\n",
    "                            [0.964080, 0.955741, 0.948044, 0.943554, 0.942271, 0.939705, 0.939064, 0.938422, 0.937781, 0.937139, 0.934573],\n",
    "                            [0.966645, 0.954458, 0.944836, 0.942271, 0.940988, 0.940346, 0.937781, 0.937781, 0.936498, 0.934573, 0.932649],\n",
    "                            [0.961514, 0.952534, 0.942271, 0.939064, 0.937139, 0.934573, 0.933932, 0.933291, 0.932008, 0.932008, 0.932008],\n",
    "                            [0.957665, 0.944836, 0.936498, 0.934573, 0.932649, 0.931366, 0.930725, 0.930083, 0.930083, 0.929442, 0.928801],\n",
    "                            [0.955099, 0.940346, 0.934573, 0.930725, 0.929442, 0.928159, 0.927518, 0.926235, 0.925593, 0.923669, 0.922386],\n",
    "                            [0.949968, 0.932008, 0.926235, 0.923028, 0.920462, 0.919179, 0.917896, 0.915972, 0.914047, 0.914047, 0.914047],\n",
    "                            [0.933932, 0.914689, 0.909557, 0.906992, 0.904426, 0.903143, 0.903143, 0.901860, 0.901219, 0.901219, 0.899936],\n",
    "                            [0.869147, 0.872996, 0.872354, 0.872354, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713]])\n",
    "\n",
    "best_g = [0.4]\n",
    "best_l = [0.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando las 68 primeras componentes, el porcentaje de la varianza del conjunto de datos que se conserva es 99,9015%. Esta vez se ha ejecutado en 66 segundos, pero la precisión ha sido de 0.9666. Esta precisión es incluso mayor que la que se obtiene con 100 componentes, 0.9660. Esto se debe al fenómeno conocido como *overfitting*. Si se seleccionan todas las componentes (caso estudiado arriba), el clasificador \"aprende\" de todas y cada una de ellas, el problema es que de las 617 componentes que tiene, la mayoría no proporciona información útil, por tanto influye negativamente en la clasificación de datos. Como se ha visto, con tan solo 18 de las 671 componentes se conserva un 99% de la varianza total, mientras que con 68 se conserva un 99,9%. En este caso, con 68 componentes, se ha obtenido una puntuación mayor que con 100 componentes, lo que indica que el \"número ideal de componentes\" se sitúa entre 68 y 100. Este valor de $k$ consigue un balance entre conservar la máxima varianza entre clases, pero sin que se produzca *overfitting*.\n",
    "\n",
    "Cabe destacar que sólamente se han probado los nuevos datos con las combinaciones de los hiperparámetros $\\lambda$ y $\\gamma$ de la lista `[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]`. La máxima puntuación que se obtenía antes de aplicar el Análisis de Componentes Principales (equivalente a seleccionar todas las componentes) es 0.956. Ahora se ha conseguido una puntuación incluso mayor: 0.9666. Este método no sólo elimina los datos menos importantes que empeoran los resultados, también simplifica el problema, por lo que se ejecuta el algoritmo de clasificación mucho más rápido. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet** tras hacer un **Análisis Discriminante Lineal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma como base el hiperparámetro que indica número de componentes principales que seleccionamos. Este hiperparámetro indica el número de columnas que tendrá la matriz de proyección $A$ (ver Análisis de Componentes Principales en la introducción).\n",
    "\n",
    "En esta sección se prueba el clasificador estadístico con todas las combinaciones de hiperparámetros $\\gamma$ y $\\lambda$ de la lista 0.0, 0.1, 0.2, ..., 1.0. No se prueba con listas más extensas porque tardaría demasiado en ejecutar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del hiperparámetro $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado en la introducción, el Análisis Discriminante Lineal selecciona las componentes que minimizan la varianza dentro de cada clase y maximizan la varianza entre clases, es decir maximiza el Ratio de Fisher. El hiperparámetro $c$ indica el número de componentes que se seleccionan. Vamos a seleccionar este hiperparámetro con el mismo método que en la evaluación de Isolet con Análisis de Componentes Principales. Vamos a calcular el valor de $c$ para que la varianza de (Sw^-1)Sb sea superior al 99% de la varianza total del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las matrices Sb y Sw (ver apartado de Análisis Discriminante Lineal de la introducción).\n",
    "n_caracteristicas = X_train.shape[1]\n",
    "Sw = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "Sb = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "n_clases = len(np.unique(y_train))\n",
    "mu_clases = np.mean(X_train, axis=0)\n",
    "for i in range(n_clases):\n",
    "    X_clase = X_train[y_train==i]\n",
    "    Sw = Sw + np.cov(X_clase, rowvar=False)\n",
    "    Sb = Sb + (len(X_clase) * ((X_clase - mu_clases).T @ (X_clase - mu_clases)))\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz Sw^-1 Sb\n",
    "u, autoval, autovec = np.linalg.svd((np.linalg.inv(Sw)@Sb), full_matrices=False) # tarda 68.246s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular las varianzas acumuladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  1: 0.729799\t  2: 0.866850\t  3: 0.903938\t  4: 0.937865\t  5: 0.952736\t  6: 0.964360\t  7: 0.972365\t  8: 0.977805\t  9: 0.982307\n",
      "\t 10: 0.985554\t 11: 0.987190\t 12: 0.988345\t 13: 0.989287\t 14: 0.989833\t 15: 0.990363\t 16: 0.990624\t 17: 0.990849\t 18: 0.991064\n",
      "\t 19: 0.991236\t 20: 0.991383\t 21: 0.991489\t 22: 0.991582\t 23: 0.991656\t 24: 0.991728\t 25: 0.991777\t 26: 0.991792\t 27: 0.991807\n",
      "\t 28: 0.991822\t 29: 0.991836\t 30: 0.991851\t 31: 0.991866\t 32: 0.991880\t 33: 0.991895\t 34: 0.991910\t 35: 0.991924\t 36: 0.991939\n",
      "\t 37: 0.991953\t 38: 0.991968\t 39: 0.991982\t 40: 0.991997\t 41: 0.992011\t 42: 0.992026\t 43: 0.992040\t 44: 0.992055\t 45: 0.992069\n",
      "\t 46: 0.992084\t 47: 0.992098\t 48: 0.992113\t 49: 0.992127\t 50: 0.992142\t 51: 0.992156\t 52: 0.992171\t 53: 0.992185\t 54: 0.992200\n",
      "\t 55: 0.992214\t 56: 0.992228\t 57: 0.992243\t 58: 0.992257\t 59: 0.992272\t 60: 0.992286\t 61: 0.992301\t 62: 0.992315\t 63: 0.992330\n",
      "\t 64: 0.992344\t 65: 0.992358\t 66: 0.992373\t 67: 0.992387\t 68: 0.992402\t 69: 0.992416\t 70: 0.992431\t 71: 0.992445\t 72: 0.992459\n",
      "\t 73: 0.992474\t 74: 0.992488\t 75: 0.992503\t 76: 0.992517\t 77: 0.992531\t 78: 0.992546\t 79: 0.992560\t 80: 0.992575\t 81: 0.992589\n",
      "\t 82: 0.992604\t 83: 0.992618\t 84: 0.992632\t 85: 0.992647\t 86: 0.992661\t 87: 0.992676\t 88: 0.992690\t 89: 0.992704\t 90: 0.992719\n",
      "\t 91: 0.992733\t 92: 0.992748\t 93: 0.992762\t 94: 0.992777\t 95: 0.992791\t 96: 0.992805\t 97: 0.992820\t 98: 0.992834\t 99: 0.992849\n",
      "\t100: 0.992863\t101: 0.992877\t102: 0.992892\t103: 0.992906\t104: 0.992921\t105: 0.992935\t106: 0.992949\t107: 0.992964\t108: 0.992978\n",
      "\t109: 0.992993\t110: 0.993007\t111: 0.993021\t112: 0.993036\t113: 0.993050\t114: 0.993065\t115: 0.993079\t116: 0.993093\t117: 0.993108\n",
      "\t118: 0.993122\t119: 0.993137\t120: 0.993151\t121: 0.993165\t122: 0.993180\t123: 0.993194\t124: 0.993209\t125: 0.993223\t126: 0.993237\n",
      "\t127: 0.993252\t128: 0.993266\t129: 0.993281\t130: 0.993295\t131: 0.993309\t132: 0.993324\t133: 0.993338\t134: 0.993353\t135: 0.993367\n",
      "\t136: 0.993381\t137: 0.993396\t138: 0.993410\t139: 0.993425\t140: 0.993439\t141: 0.993453\t142: 0.993468\t143: 0.993482\t144: 0.993497\n",
      "\t145: 0.993511\t146: 0.993525\t147: 0.993540\t148: 0.993554\t149: 0.993568\t150: 0.993583\t151: 0.993597\t152: 0.993612\t153: 0.993626\n",
      "\t154: 0.993640\t155: 0.993655\t156: 0.993669\t157: 0.993684\t158: 0.993698\t159: 0.993712\t160: 0.993727\t161: 0.993741\t162: 0.993756\n",
      "\t163: 0.993770\t164: 0.993784\t165: 0.993799\t166: 0.993813\t167: 0.993828\t168: 0.993842\t169: 0.993856\t170: 0.993871\t171: 0.993885\n",
      "\t172: 0.993900\t173: 0.993914\t174: 0.993928\t175: 0.993943\t176: 0.993957\t177: 0.993971\t178: 0.993986\t179: 0.994000\t180: 0.994015\n",
      "\t181: 0.994029\t182: 0.994043\t183: 0.994058\t184: 0.994072\t185: 0.994087\t186: 0.994101\t187: 0.994115\t188: 0.994130\t189: 0.994144\n",
      "\t190: 0.994159\t191: 0.994173\t192: 0.994187\t193: 0.994202\t194: 0.994216\t195: 0.994231\t196: 0.994245\t197: 0.994259\t198: 0.994274\n",
      "\t199: 0.994288\t200: 0.994302\t201: 0.994317\t202: 0.994331\t203: 0.994346\t204: 0.994360\t205: 0.994374\t206: 0.994389\t207: 0.994403\n",
      "\t208: 0.994418\t209: 0.994432\t210: 0.994446\t211: 0.994461\t212: 0.994475\t213: 0.994490\t214: 0.994504\t215: 0.994518\t216: 0.994533\n",
      "\t217: 0.994547\t218: 0.994561\t219: 0.994576\t220: 0.994590\t221: 0.994605\t222: 0.994619\t223: 0.994633\t224: 0.994648\t225: 0.994662\n",
      "\t226: 0.994677\t227: 0.994691\t228: 0.994705\t229: 0.994720\t230: 0.994734\t231: 0.994749\t232: 0.994763\t233: 0.994777\t234: 0.994792\n",
      "\t235: 0.994806\t236: 0.994821\t237: 0.994835\t238: 0.994849\t239: 0.994864\t240: 0.994878\t241: 0.994892\t242: 0.994907\t243: 0.994921\n",
      "\t244: 0.994936\t245: 0.994950\t246: 0.994964\t247: 0.994979\t248: 0.994993\t249: 0.995008\t250: 0.995022\t251: 0.995036\t252: 0.995051\n",
      "\t253: 0.995065\t254: 0.995080\t255: 0.995094\t256: 0.995108\t257: 0.995123\t258: 0.995137\t259: 0.995151\t260: 0.995166\t261: 0.995180\n",
      "\t262: 0.995195\t263: 0.995209\t264: 0.995223\t265: 0.995238\t266: 0.995252\t267: 0.995267\t268: 0.995281\t269: 0.995295\t270: 0.995310\n",
      "\t271: 0.995324\t272: 0.995339\t273: 0.995353\t274: 0.995367\t275: 0.995382\t276: 0.995396\t277: 0.995410\t278: 0.995425\t279: 0.995439\n",
      "\t280: 0.995454\t281: 0.995468\t282: 0.995482\t283: 0.995497\t284: 0.995511\t285: 0.995526\t286: 0.995540\t287: 0.995554\t288: 0.995569\n",
      "\t289: 0.995583\t290: 0.995598\t291: 0.995612\t292: 0.995626\t293: 0.995641\t294: 0.995655\t295: 0.995669\t296: 0.995684\t297: 0.995698\n",
      "\t298: 0.995713\t299: 0.995727\t300: 0.995741\t301: 0.995756\t302: 0.995770\t303: 0.995785\t304: 0.995799\t305: 0.995813\t306: 0.995828\n",
      "\t307: 0.995842\t308: 0.995857\t309: 0.995871\t310: 0.995885\t311: 0.995900\t312: 0.995914\t313: 0.995928\t314: 0.995943\t315: 0.995957\n",
      "\t316: 0.995972\t317: 0.995986\t318: 0.996000\t319: 0.996015\t320: 0.996029\t321: 0.996044\t322: 0.996058\t323: 0.996072\t324: 0.996087\n",
      "\t325: 0.996101\t326: 0.996116\t327: 0.996130\t328: 0.996144\t329: 0.996159\t330: 0.996173\t331: 0.996187\t332: 0.996202\t333: 0.996216\n",
      "\t334: 0.996231\t335: 0.996245\t336: 0.996259\t337: 0.996274\t338: 0.996288\t339: 0.996303\t340: 0.996317\t341: 0.996331\t342: 0.996346\n",
      "\t343: 0.996360\t344: 0.996374\t345: 0.996389\t346: 0.996403\t347: 0.996418\t348: 0.996432\t349: 0.996446\t350: 0.996461\t351: 0.996475\n",
      "\t352: 0.996490\t353: 0.996504\t354: 0.996518\t355: 0.996533\t356: 0.996547\t357: 0.996562\t358: 0.996576\t359: 0.996590\t360: 0.996605\n",
      "\t361: 0.996619\t362: 0.996633\t363: 0.996648\t364: 0.996662\t365: 0.996677\t366: 0.996691\t367: 0.996705\t368: 0.996720\t369: 0.996734\n",
      "\t370: 0.996749\t371: 0.996763\t372: 0.996777\t373: 0.996792\t374: 0.996806\t375: 0.996820\t376: 0.996835\t377: 0.996849\t378: 0.996864\n",
      "\t379: 0.996878\t380: 0.996892\t381: 0.996907\t382: 0.996921\t383: 0.996936\t384: 0.996950\t385: 0.996964\t386: 0.996979\t387: 0.996993\n",
      "\t388: 0.997007\t389: 0.997022\t390: 0.997036\t391: 0.997051\t392: 0.997065\t393: 0.997079\t394: 0.997094\t395: 0.997108\t396: 0.997122\n",
      "\t397: 0.997137\t398: 0.997151\t399: 0.997166\t400: 0.997180\t401: 0.997194\t402: 0.997209\t403: 0.997223\t404: 0.997237\t405: 0.997252\n",
      "\t406: 0.997266\t407: 0.997281\t408: 0.997295\t409: 0.997309\t410: 0.997324\t411: 0.997338\t412: 0.997352\t413: 0.997367\t414: 0.997381\n",
      "\t415: 0.997396\t416: 0.997410\t417: 0.997424\t418: 0.997439\t419: 0.997453\t420: 0.997467\t421: 0.997482\t422: 0.997496\t423: 0.997511\n",
      "\t424: 0.997525\t425: 0.997539\t426: 0.997554\t427: 0.997568\t428: 0.997582\t429: 0.997597\t430: 0.997611\t431: 0.997626\t432: 0.997640\n",
      "\t433: 0.997654\t434: 0.997669\t435: 0.997683\t436: 0.997697\t437: 0.997712\t438: 0.997726\t439: 0.997740\t440: 0.997755\t441: 0.997769\n",
      "\t442: 0.997784\t443: 0.997798\t444: 0.997812\t445: 0.997827\t446: 0.997841\t447: 0.997855\t448: 0.997870\t449: 0.997884\t450: 0.997898\n",
      "\t451: 0.997913\t452: 0.997927\t453: 0.997942\t454: 0.997956\t455: 0.997970\t456: 0.997985\t457: 0.997999\t458: 0.998013\t459: 0.998028\n",
      "\t460: 0.998042\t461: 0.998056\t462: 0.998071\t463: 0.998085\t464: 0.998099\t465: 0.998114\t466: 0.998128\t467: 0.998143\t468: 0.998157\n",
      "\t469: 0.998171\t470: 0.998186\t471: 0.998200\t472: 0.998214\t473: 0.998229\t474: 0.998243\t475: 0.998257\t476: 0.998272\t477: 0.998286\n",
      "\t478: 0.998300\t479: 0.998315\t480: 0.998329\t481: 0.998343\t482: 0.998358\t483: 0.998372\t484: 0.998386\t485: 0.998401\t486: 0.998415\n",
      "\t487: 0.998430\t488: 0.998444\t489: 0.998458\t490: 0.998473\t491: 0.998487\t492: 0.998501\t493: 0.998516\t494: 0.998530\t495: 0.998544\n",
      "\t496: 0.998559\t497: 0.998573\t498: 0.998587\t499: 0.998602\t500: 0.998616\t501: 0.998630\t502: 0.998645\t503: 0.998659\t504: 0.998673\n",
      "\t505: 0.998688\t506: 0.998702\t507: 0.998716\t508: 0.998731\t509: 0.998745\t510: 0.998759\t511: 0.998774\t512: 0.998788\t513: 0.998802\n",
      "\t514: 0.998817\t515: 0.998831\t516: 0.998845\t517: 0.998859\t518: 0.998874\t519: 0.998888\t520: 0.998902\t521: 0.998917\t522: 0.998931\n",
      "\t523: 0.998945\t524: 0.998960\t525: 0.998974\t526: 0.998988\t527: 0.999003\t528: 0.999017\t529: 0.999031\t530: 0.999046\t531: 0.999060\n",
      "\t532: 0.999074\t533: 0.999088\t534: 0.999103\t535: 0.999117\t536: 0.999131\t537: 0.999146\t538: 0.999160\t539: 0.999174\t540: 0.999189\n",
      "\t541: 0.999203\t542: 0.999217\t543: 0.999231\t544: 0.999246\t545: 0.999260\t546: 0.999274\t547: 0.999289\t548: 0.999303\t549: 0.999317\n",
      "\t550: 0.999331\t551: 0.999346\t552: 0.999360\t553: 0.999374\t554: 0.999388\t555: 0.999403\t556: 0.999417\t557: 0.999431\t558: 0.999446\n",
      "\t559: 0.999460\t560: 0.999474\t561: 0.999488\t562: 0.999503\t563: 0.999517\t564: 0.999531\t565: 0.999545\t566: 0.999559\t567: 0.999574\n",
      "\t568: 0.999588\t569: 0.999602\t570: 0.999616\t571: 0.999631\t572: 0.999645\t573: 0.999659\t574: 0.999673\t575: 0.999687\t576: 0.999701\n",
      "\t577: 0.999716\t578: 0.999730\t579: 0.999744\t580: 0.999758\t581: 0.999772\t582: 0.999786\t583: 0.999800\t584: 0.999814\t585: 0.999828\n",
      "\t586: 0.999842\t587: 0.999856\t588: 0.999870\t589: 0.999884\t590: 0.999898\t591: 0.999912\t592: 0.999925\t593: 0.999933\t594: 0.999941\n",
      "\t595: 0.999947\t596: 0.999953\t597: 0.999959\t598: 0.999964\t599: 0.999968\t600: 0.999973\t601: 0.999976\t602: 0.999980\t603: 0.999983\n",
      "\t604: 0.999986\t605: 0.999988\t606: 0.999990\t607: 0.999992\t608: 0.999993\t609: 0.999995\t610: 0.999996\t611: 0.999997\t612: 0.999998\n",
      "\t613: 0.999998\t614: 0.999999\t615: 0.999999\t616: 1.000000\t617: 1.000000"
     ]
    }
   ],
   "source": [
    "print_cumvar(autoval, X_train.shape[0], 1, 617)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta vez es necesario imprimir todos los valores. Si queremos escoger las $c$ primeras componentes para conservar el 99% de la varianza del conjunto de datos, nos vale con seleccionar 15 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final: (6238, 15)\n",
      "X_test_final: (1559, 15)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 15 primeras componentes\n",
    "A = autovec[:15]\n",
    "# Proyectar el conjunto de datos de entrenamiento sobre el nuevo espacio\n",
    "X_train_final = (A @ X_train.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ X_test.T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado en 1.256s\n",
      "max_score exclusion:\t\t0.9307\n",
      "best hyperparams:\n",
      "\tgamma: 0.2 lambda: 0.0\n",
      "\tgamma: 0.3 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con el ACP, que obtuvo una tasa de aciertos del 91,4% (seleccionando las componentes correspondientes al 99% de la varianza), con el método de ADL obtenemos una tasa de aciertos de 93,07%.\n",
    "\n",
    "Vamos a probar ahora a escoger las $c$ primeras componentes que conserven el 99,9% de la varianza. Mirando en los valores impresos arriba, el número de componentes que hay que seleccionar es 527. Notese la diferencia con el Análisis de Componentes Principales, el 99% estaba en 18 componentes y el 99,9% en 68; mientras que en el Análisis Discriminante Lineal el 99% está en 15 y el 99,9% está en 527."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final: (6238, 527)\n",
      "X_test_final: (1559, 527)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 527 primeras componentes\n",
    "A = autovec[:527]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_train.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ X_test.T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.0385\n",
      "best hyperparams:\n",
      "\ttodos\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 38 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486],\n",
    "                            [0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486, 0.038486]])\n",
    "\n",
    "best_g = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
    "          0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
    "          0.4, 0.4, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7,\n",
    "          0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
    "          0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "best_l = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3,\n",
    "          0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,\n",
    "          0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0,\n",
    "          0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4,\n",
    "          0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final, y_train, X_test_final, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "\"\"\"\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n",
    "\"\"\"\n",
    "print(\"\\ttodos\") # son demasiados para imprimir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, los resultados son pésimos. Estamos otra vez en el caso de *overfitting*, en el que se suministran demasiadas dimensiones que no proporcionan información adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet** con mezcla de **ACP** y **ADL**\n",
    "\n",
    "En esta sección se analizará primero con APC y ADL, y posteriormente con ADL y ACP. Se tomarán las componentes que contienen el 99,9% de la varianza para la primera fase y de estos se analizará cuántas componentes elegir para conservar el 99% y el 99,9% de la varianza para la segunda fase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ACP** -> **ADL**\n",
    "\n",
    "Para ACP habíamos seleccionado 68 componentes, que mantienen el 99,9% de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ACP: (6238, 68)\n",
      "X_test_final_ACP: (1559, 68)\n"
     ]
    }
   ],
   "source": [
    "# Calcular la matriz A\n",
    "# Calcular la media del conjunto de datos de entrenamiento\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "# Estandarizar el conjunto de datos de entrenamiento\n",
    "X_norm = X_train - X_train_mean\n",
    "\n",
    "# Calcular la nueva matriz de covarianzas del conjunto de datos estandarizados\n",
    "X_train_cov = np.cov(X_norm, rowvar=False)\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz de covarianzas\n",
    "u, autoval, autovec = np.linalg.svd(X_train_cov, full_matrices=False) # tarda 68.246s\n",
    "\n",
    "# Construir la matriz de proyección A seleccionando las 68 componentes principales\n",
    "n_componentes = 68 # hiperparámetro\n",
    "A = autovec[:n_componentes]\n",
    "\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final_ACP = (A @ X_norm.T).T\n",
    "\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ACP = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final_ACP:\", X_train_final_ACP.shape)\n",
    "print(\"X_test_final_ACP:\", X_test_final_ACP.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se calculan y visualizan las varianzas acumuladas para estimar el hiperparámetro $c$ de ADL, pero primero hay que calcular las matrices $S_{w}$ y $S_{b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las matrices Sb y Sw (ver apartado de Análisis Discriminante Lineal de la introducción).\n",
    "n_caracteristicas = X_train_final_ACP.shape[1]\n",
    "Sw = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "Sb = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "n_clases = len(np.unique(y_train))\n",
    "mu_clases = np.mean(X_train_final_ACP, axis=0)\n",
    "for i in range(n_clases):\n",
    "    X_clase = X_train_final_ACP[y_train==i]\n",
    "    Sw = Sw + np.cov(X_clase, rowvar=False)\n",
    "    Sb = Sb + (len(X_clase) * ((X_clase - mu_clases).T @ (X_clase - mu_clases)))\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz Sw^-1 Sb\n",
    "u, autoval, autovec = np.linalg.svd((np.linalg.inv(Sw)@Sb), full_matrices=False) # tarda 68.246s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se pueden visualizar las varianzas acumuladas para el conjunto de datos obtenido de hacer ACP con $k=68$ componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  1: 0.638590\t  2: 0.818469\t  3: 0.865391\t  4: 0.893118\t  5: 0.913279\t  6: 0.929994\t  7: 0.941599\t  8: 0.952724\t  9: 0.960716\n",
      "\t 10: 0.965241\t 11: 0.967882\t 12: 0.970030\t 13: 0.971660\t 14: 0.973022\t 15: 0.974177\t 16: 0.975133\t 17: 0.976004\t 18: 0.976779\n",
      "\t 19: 0.977474\t 20: 0.978121\t 21: 0.978760\t 22: 0.979386\t 23: 0.979963\t 24: 0.980517\t 25: 0.981032\t 26: 0.981507\t 27: 0.981982\n",
      "\t 28: 0.982457\t 29: 0.982932\t 30: 0.983407\t 31: 0.983882\t 32: 0.984357\t 33: 0.984831\t 34: 0.985306\t 35: 0.985781\t 36: 0.986256\n",
      "\t 37: 0.986730\t 38: 0.987205\t 39: 0.987679\t 40: 0.988154\t 41: 0.988628\t 42: 0.989102\t 43: 0.989576\t 44: 0.990050\t 45: 0.990523\n",
      "\t 46: 0.990995\t 47: 0.991466\t 48: 0.991936\t 49: 0.992405\t 50: 0.992873\t 51: 0.993340\t 52: 0.993803\t 53: 0.994265\t 54: 0.994721\n",
      "\t 55: 0.995175\t 56: 0.995628\t 57: 0.996078\t 58: 0.996512\t 59: 0.996939\t 60: 0.997364\t 61: 0.997776\t 62: 0.998177\t 63: 0.998561\n",
      "\t 64: 0.998938\t 65: 0.999270\t 66: 0.999577\t 67: 0.999809\t 68: 1.000000"
     ]
    }
   ],
   "source": [
    "print_cumvar(autoval, X_train.shape[0], 1, 68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conservar el 99% de la varianza, hay que seleccionar 44 componentes de la nueva matriz $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ACP_ADL: (6238, 44)\n",
      "X_test_final_ACP_ADL: (1559, 44)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 44 primeras componentes\n",
    "A = autovec[:44]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final_ACP_ADL = (A @ X_train_final_ACP.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ACP_ADL = (A @ X_test_final_ACP.T).T\n",
    "\n",
    "print(\"X_train_final_ACP_ADL:\", X_train_final_ACP_ADL.shape)\n",
    "print(\"X_test_final_ACP_ADL:\", X_test_final_ACP_ADL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.9545\n",
      "best hyperparams:\n",
      "\tgamma: 0.3 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 7 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.933932, 0.953175, 0.940988, 0.937139, 0.934573, 0.933291, 0.932649, 0.932008, 0.931366, 0.930725, 0.929442],\n",
    "                            [0.950609, 0.950609, 0.940346, 0.935215, 0.933291, 0.932008, 0.932649, 0.931366, 0.931366, 0.930725, 0.926876],\n",
    "                            [0.953817, 0.946119, 0.940988, 0.936498, 0.933291, 0.932649, 0.931366, 0.928801, 0.927518, 0.924952, 0.924952],\n",
    "                            [0.954458, 0.944836, 0.938422, 0.934573, 0.932008, 0.930725, 0.930083, 0.926876, 0.926235, 0.924952, 0.924310],\n",
    "                            [0.953817, 0.944195, 0.935856, 0.933932, 0.929442, 0.927518, 0.924952, 0.924310, 0.924310, 0.924310, 0.924310],\n",
    "                            [0.953175, 0.939705, 0.932008, 0.929442, 0.928159, 0.926235, 0.924952, 0.924310, 0.924310, 0.924310, 0.923669],\n",
    "                            [0.950609, 0.932008, 0.930083, 0.926235, 0.924310, 0.923669, 0.923669, 0.922386, 0.921745, 0.921745, 0.921103],\n",
    "                            [0.947402, 0.932008, 0.925593, 0.923669, 0.921745, 0.919179, 0.918538, 0.918538, 0.917896, 0.917896, 0.917255],\n",
    "                            [0.940988, 0.921103, 0.917896, 0.916613, 0.915972, 0.914689, 0.913406, 0.913406, 0.911482, 0.911482, 0.910840],\n",
    "                            [0.922386, 0.908916, 0.903784, 0.903143, 0.903143, 0.900577, 0.900577, 0.900577, 0.900577, 0.900577, 0.899294],\n",
    "                            [0.881976, 0.881334, 0.883258, 0.883900, 0.883258, 0.883258, 0.883258, 0.883258, 0.883258, 0.883258, 0.883258]])\n",
    "\n",
    "best_g = [0.3]\n",
    "best_l = [0.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final_ACP_ADL, y_train, X_test_final_ACP_ADL, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han empleado los datos `X_train_final_ACP_ADL` y `X_test_final_ACP_ADL`, que se han obtenido previamente seleccionando las 44 primeras componentes principales seleccionadas por ADL, de las 68 primeras componentes principales seleccionadas por ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, por lo general cuanto menor sean los valores de los hiperparámetros $\\lambda$ y $\\gamma$, mejores resultados se obtiene (sobre todo en el parámetro $\\lambda$), excepto en el caso de $\\lambda = \\gamma = 0$. La máxima puntuación es de 95,45%. Ahora seleccionaremos las componentes correspondientes al 99,9% de la varianza de las 68 componentes seleccionadas con ACP (igual que en el caso de 44 componentes para un 99%, pero esta vez para 99,9%). El número correspondiente es 65 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ACP_ADL: (6238, 65)\n",
      "X_test_final_ACP_ADL: (1559, 65)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 65 primeras componentes\n",
    "A = autovec[:65]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final_ACP_ADL = (A @ X_train_final_ACP.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ACP_ADL = (A @ X_test_final_ACP.T).T\n",
    "\n",
    "print(\"X_train_final_ACP_ADL:\", X_train_final_ACP_ADL.shape)\n",
    "print(\"X_test_final_ACP_ADL:\", X_test_final_ACP_ADL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.9622\n",
      "best hyperparams:\n",
      "\tgamma: 0.4 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 14 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.933932, 0.954458, 0.948044, 0.940988, 0.936498, 0.936498, 0.935856, 0.934573, 0.935215, 0.933291, 0.932008],\n",
    "                            [0.949326, 0.956382, 0.948044, 0.942271, 0.939064, 0.937781, 0.935215, 0.935215, 0.934573, 0.933291, 0.931366],\n",
    "                            [0.955099, 0.957024, 0.949326, 0.944836, 0.940988, 0.937781, 0.935215, 0.933291, 0.933291, 0.932649, 0.932008],\n",
    "                            [0.960231, 0.954458, 0.945478, 0.941629, 0.938422, 0.935856, 0.933932, 0.933291, 0.932008, 0.931366, 0.930725],\n",
    "                            [0.962155, 0.953175, 0.944836, 0.938422, 0.936498, 0.934573, 0.934573, 0.933932, 0.932008, 0.931366, 0.930083],\n",
    "                            [0.958948, 0.948685, 0.940346, 0.935856, 0.935215, 0.934573, 0.932649, 0.931366, 0.930083, 0.929442, 0.928159],\n",
    "                            [0.958948, 0.944195, 0.935856, 0.933291, 0.931366, 0.929442, 0.928801, 0.926876, 0.925593, 0.924952, 0.924310],\n",
    "                            [0.955741, 0.937781, 0.933291, 0.930725, 0.927518, 0.924952, 0.923669, 0.921103, 0.919820, 0.919820, 0.919820],\n",
    "                            [0.951251, 0.930725, 0.923669, 0.921103, 0.918538, 0.917896, 0.915972, 0.915330, 0.914047, 0.913406, 0.912765],\n",
    "                            [0.929442, 0.912123, 0.905709, 0.905067, 0.902502, 0.901860, 0.901860, 0.901219, 0.899936, 0.899936, 0.900577],\n",
    "                            [0.870430, 0.874278, 0.873637, 0.872996, 0.872996, 0.872996, 0.873637, 0.873637, 0.873637, 0.873637, 0.873637]])\n",
    "\n",
    "best_g = [0.4]\n",
    "best_l = [0.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final_ACP_ADL, y_train, X_test_final_ACP_ADL, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han empleado los datos `X_train_final_ACP_ADL` y `X_test_final_ACP_ADL`, que se han obtenido previamente seleccionando las 65 primeras componentes principales seleccionadas por ADL, de las 68 primeras componentes principales seleccionadas por ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos en un caso similar al anterior, sólo que la major tasa de aciertos obtenida es 96,22%. En el caso anterior (seleccionando las correspondientes al 99% de la varianza de las 68 seleccionadas por ACP) se obtenía una tasa de aciertos del 95,45%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ADL** -> **ACP**\n",
    "\n",
    "Para ADL habíamos seleccionado 527 componentes, que mantienen el 99,9% de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ADL: (6238, 527)\n",
      "X_test_final_ADL: (1559, 527)\n"
     ]
    }
   ],
   "source": [
    "# Calcular la matriz A\n",
    "# Calcular las matrices Sb y Sw (ver apartado de Análisis Discriminante Lineal de la introducción).\n",
    "n_caracteristicas = X_train.shape[1]\n",
    "Sw = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "Sb = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "n_clases = len(np.unique(y_train))\n",
    "mu_clases = np.mean(X_train, axis=0)\n",
    "for i in range(n_clases):\n",
    "    X_clase = X_train[y_train==i]\n",
    "    Sw = Sw + np.cov(X_clase, rowvar=False)\n",
    "    Sb = Sb + (len(X_clase) * ((X_clase - mu_clases).T @ (X_clase - mu_clases)))\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz Sw^-1 Sb\n",
    "u, autoval, autovec = np.linalg.svd((np.linalg.inv(Sw)@Sb), full_matrices=False) # tarda 68.246s\n",
    "\n",
    "# Calcular la matriz A, seleccionando 527 componentes\n",
    "A = autovec[:527]\n",
    "# Proyectar el conjunto de datos de entrenamiento sobre el nuevo espacio\n",
    "X_train_final_ADL = (A @ X_train.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ADL = (A @ X_test.T).T\n",
    "\n",
    "print(\"X_train_final_ADL:\", X_train_final_ADL.shape)\n",
    "print(\"X_test_final_ADL:\", X_test_final_ADL.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se calculan y visualizan las varianzas acumuladas para estimar el hiperparámetro $k$ de ACP, pero primero hay que calcular la descomposición espectral de la matriz de covarianzas de `X_train_final_ADL`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media del conjunto de datos de entrenamiento\n",
    "X_train_mean = np.mean(X_train_final_ADL, axis=0)\n",
    "\n",
    "# Estandarizar el conjunto de datos de entrenamiento\n",
    "X_norm = X_train_final_ADL - X_train_mean\n",
    "\n",
    "# Calcular la nueva matriz de covarianzas del conjunto de datos estandarizados\n",
    "X_train_cov = np.cov(X_norm, rowvar=False)\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz de covarianzas\n",
    "u, autoval, autovec = np.linalg.svd(X_train_cov, full_matrices=False) # tarda 68.246s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se pueden visualizar las varianzas acumuladas para el conjunto de datos obtenido de hacer ADL con $k=527$ componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  1: 0.772973\t  2: 0.870120\t  3: 0.911416\t  4: 0.933808\t  5: 0.953047\t  6: 0.965424\t  7: 0.973532\t  8: 0.978324\t  9: 0.981497\n",
      "\t 10: 0.984010\t 11: 0.985972\t 12: 0.987566\t 13: 0.988882\t 14: 0.990072\t 15: 0.991160\t 16: 0.992032\t 17: 0.992810\t 18: 0.993523\n",
      "\t 19: 0.994127\t 20: 0.994585\t 21: 0.994982\t 22: 0.995317\t 23: 0.995619\t 24: 0.995896\t 25: 0.996157\t 26: 0.996395\t 27: 0.996608\n",
      "\t 28: 0.996799\t 29: 0.996961\t 30: 0.997109\t 31: 0.997244\t 32: 0.997365\t 33: 0.997484\t 34: 0.997593\t 35: 0.997697\t 36: 0.997798\n",
      "\t 37: 0.997891\t 38: 0.997975\t 39: 0.998056\t 40: 0.998131\t 41: 0.998201\t 42: 0.998265\t 43: 0.998327\t 44: 0.998387\t 45: 0.998443\n",
      "\t 46: 0.998496\t 47: 0.998548\t 48: 0.998596\t 49: 0.998644\t 50: 0.998689\t 51: 0.998732\t 52: 0.998773\t 53: 0.998814\t 54: 0.998850\n",
      "\t 55: 0.998886\t 56: 0.998921\t 57: 0.998955\t 58: 0.998988\t 59: 0.999020\t 60: 0.999049\t 61: 0.999077\t 62: 0.999105\t 63: 0.999130\n",
      "\t 64: 0.999156\t 65: 0.999180\t 66: 0.999204\t 67: 0.999227\t 68: 0.999249\t 69: 0.999270\t 70: 0.999290\t 71: 0.999310\t 72: 0.999329\n",
      "\t 73: 0.999347\t 74: 0.999363\t 75: 0.999380\t 76: 0.999396\t 77: 0.999411\t 78: 0.999426\t 79: 0.999440\t 80: 0.999454\t 81: 0.999468\n",
      "\t 82: 0.999481\t 83: 0.999494\t 84: 0.999506\t 85: 0.999518\t 86: 0.999529\t 87: 0.999540\t 88: 0.999551\t 89: 0.999562\t 90: 0.999572\n",
      "\t 91: 0.999582\t 92: 0.999592\t 93: 0.999602\t 94: 0.999611\t 95: 0.999619\t 96: 0.999628\t 97: 0.999636\t 98: 0.999644\t 99: 0.999651\n",
      "\t100: 0.999659"
     ]
    }
   ],
   "source": [
    "print_cumvar(autoval, X_train.shape[0], 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conservar el 99% de la varianza, hay que seleccionar 14 componentes para la nueva matriz $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ADL_ACP: (6238, 14)\n",
      "X_test_final_ADL_ACP: (1559, 14)\n"
     ]
    }
   ],
   "source": [
    "# Construir la matriz de proyección A seleccionando las n_componentes componentes principales\n",
    "A = autovec[:14]\n",
    "\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final_ADL_ACP = (A @ X_norm.T).T\n",
    "\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ADL_ACP = (A @ (X_test_final_ADL - np.mean(X_test_final_ADL, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final_ADL_ACP:\", X_train_final_ADL_ACP.shape)\n",
    "print(\"X_test_final_ADL_ACP:\", X_test_final_ADL_ACP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado en 1.159s\n",
      "max_score exclusion:\t\t0.8820\n",
      "best hyperparams:\n",
      "\tgamma: 0.3 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final_ADL_ACP, y_train, X_test_final_ADL_ACP, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han empleado los datos `X_train_final_ADL_ACP` y `X_test_final_ADL_ACP`, que se han obtenido previamente seleccionando las 14 primeras componentes principales seleccionadas por ADL, de las 527 primeras componentes principales seleccionadas por ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, por lo general cuanto menor sean los valores de los hiperparámetros $\\lambda$ y $\\gamma$, mejores resultados se obtiene (sobre todo en el parámetro $\\lambda$). La máxima puntuación es de 88,2%.\n",
    "\n",
    "Ahora seleccionaremos las componentes correspondientes al 99,9% de la varianza de las 527 componentes seleccionadas con ADL (igual que en el caso de 14 componentes para un 99%, pero esta vez para 99,9%). El número correspondiente es 59 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final_ADL_ACP: (6238, 59)\n",
      "X_test_final_ADL_ACP: (1559, 59)\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 65 primeras componentes\n",
    "A = autovec[:59]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final_ADL_ACP = (A @ X_train_final_ADL.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final_ADL_ACP = (A @ X_test_final_ADL.T).T\n",
    "\n",
    "print(\"X_train_final_ADL_ACP:\", X_train_final_ADL_ACP.shape)\n",
    "print(\"X_test_final_ADL_ACP:\", X_test_final_ADL_ACP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_score exclusion:\t\t0.9654\n",
      "best hyperparams:\n",
      "\tgamma: 0.4 lambda: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 12 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "\n",
    "scores_exclusion = np.array([[0.932649, 0.954458, 0.948685, 0.944836, 0.942271, 0.940346, 0.940346, 0.937781, 0.937139, 0.936498, 0.935215],\n",
    "                            [0.953175, 0.955099, 0.951251, 0.946119, 0.944195, 0.940988, 0.939064, 0.937139, 0.935856, 0.935215, 0.934573],\n",
    "                            [0.960872, 0.954458, 0.949968, 0.946119, 0.940988, 0.939705, 0.937781, 0.937139, 0.936498, 0.935856, 0.935215],\n",
    "                            [0.962797, 0.954458, 0.948044, 0.942271, 0.939705, 0.937139, 0.936498, 0.935215, 0.934573, 0.934573, 0.933932],\n",
    "                            [0.965362, 0.953817, 0.942912, 0.939064, 0.937781, 0.937139, 0.936498, 0.935215, 0.934573, 0.933291, 0.932649],\n",
    "                            [0.960231, 0.951892, 0.941629, 0.937139, 0.936498, 0.935856, 0.934573, 0.933932, 0.933291, 0.933291, 0.931366],\n",
    "                            [0.957024, 0.946119, 0.937139, 0.935215, 0.933291, 0.932008, 0.930725, 0.928801, 0.928801, 0.926876, 0.926235],\n",
    "                            [0.952534, 0.939064, 0.931366, 0.930083, 0.927518, 0.926876, 0.926876, 0.925593, 0.924952, 0.924952, 0.924952],\n",
    "                            [0.942912, 0.929442, 0.923669, 0.920462, 0.919820, 0.919179, 0.917896, 0.916613, 0.915972, 0.915330, 0.914689],\n",
    "                            [0.926235, 0.911482, 0.908916, 0.906350, 0.905067, 0.904426, 0.903784, 0.903784, 0.903784, 0.903143, 0.902502],\n",
    "                            [0.867864, 0.867864, 0.867864, 0.868505, 0.868505, 0.868505, 0.868505, 0.868505, 0.868505, 0.868505, 0.868505]])\n",
    "\n",
    "best_g = [0.4]\n",
    "best_l = [0.0]\n",
    "\n",
    "#scores_exclusion, best_g, best_l = GridSearchExclusion(X_train_final_ADL_ACP, y_train, X_test_final_ADL_ACP, y_test)\n",
    "\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "print(\"best hyperparams:\")\n",
    "for e in range(len(best_g)):\n",
    "    print(\"\\tgamma: %1.1f lambda: %1.1f\" % (best_g[e], best_l[e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se han empleado los datos `X_train_final_ADL_ACP` y `X_test_final_ADL_ACP`, que se han obtenido previamente seleccionando las 59 primeras componentes principales seleccionadas por ACP, de las 527 primeras componentes principales seleccionadas por ADL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(scores_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos en una situación mejor que la anterior. La tasa de aciertos obtenida es 96,54%, mientras que en el caso anterior (seleccionando las correspondientes al 99% de la varianza de las 527 seleccionadas por ADL) se obtenía una tasa de aciertos del 88,20%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Resultados de los experimentos con la base de datos Isolet:**\n",
    "\n",
    "En los casos en los que se prueba primero ACP y luego ADL (y viceversa), de la \"primera fase\" se seleccionan las componentes correspondientes que conservan el 99,9% de la varianza. En la \"segunda fase\" se seleccionan las componentes correspondientes al 99% y 99,9% de la varianza acumulada. También se indican (cuando corresponde) los hiperparámetros $\\lambda$ y $\\gamma$ que mejores resultados dan. Tanto en ACP como en ADL, se emplea el clasificador estadístico regularizado (nuestra implementación).\n",
    "\n",
    "| Técnica empleada | nº de componentes seleccionadas | nº de componentes totales| proporción de varianza conservado | Tasa de aciertos (por exclusion) | gamma | lambda |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "| Clasificador distancia euclídea | - | 617 | 1.00 | 0.8743 | - | - |\n",
    "||||||||\n",
    "| Estadístico regularizado de sklearn   | - | - | 1.0 | 0.956 | 0.23 | - |\n",
    "||||||||\n",
    "| Estadístico regularizado con ACP          | 100 | 617 | 0.999572 | 0.9660 | 0.4 | 0 |\n",
    "| Estadístico regularizado con ACP (99%)   | 18 | 617 | 0.990238 | 0.9140 | 0.2 | 0 |\n",
    "| Estadístico regularizado con ACP (99,9%)  | 68 | 617 | 0.999015 | 0.9666 | 0.4 | 0 |\n",
    "||||||||\n",
    "| Estadístico regularizado con ADL (99%)   | 15 | 617 | 0.990363 | 0.9307 | 0.3 | 0 |\n",
    "| Estadístico regularizado con ADL (99,9%) | 527 | 617 | 0.999003 | 0.0385 | 0 | 0 |\n",
    "||||||||\n",
    "| Est. reg. con ACP y ADL (99%)  | 44 | 68 | 0.990050 | 0.9545 | 0.3 | 0 |\n",
    "| Est. reg. con ACP y ADL (99,9%)| 65 | 68 | 0.999270 | 0.9622 | 0.4 | 0 |\n",
    "||||||||\n",
    "| Est. reg. con ADL y ACP (99%)  | 14 | 527 | 0.990072 | 0.8820 | 0.3 | 0 |\n",
    "| Est. reg. con ADL y ACP (99,9%)| 59 | 527 | 0.999020 | 0.9654 | 0.4 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, la mejor tasa de aciertos que hemos conseguido en la base de datos Isolet, es de 96,66%. Este resultado se obtiene seleccionando las 68 componentes principales más importantes, que conservan un 99,9015% de la varianza total de los datos, y con hiperparámetros $\\gamma=0.4$ y $\\lambda=0$.\n",
    "\n",
    "El motivo por el que no conseguimos que la tasa de aciertos aumente más es porque la base de datos presenta muchos datos atípicos. Vamos a visualizar los diagramas de cajas de los datos de las clases 5 y 6 (por ejemplo). Se muestran las 15 primeras componentes porque las 617 totales son demasiadas para visualizar en una gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1368x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizar las [start:end] componentes de las clases clase1 y clase2\n",
    "start = 15\n",
    "end = 50\n",
    "clase1 = 5\n",
    "clase2 = 6\n",
    "\n",
    "fig = plt.figure(figsize=(19, 5))\n",
    "ax = fig.add_subplot(121)\n",
    "bp = ax.boxplot(X[y==clase1][:,start:end])\n",
    "labels = ax.set_xticklabels(list(range(start, end)))\n",
    "title = ax.set_title('clase %d' % clase1)\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "bp = ax.boxplot(X[y==clase2][:,start:end])\n",
    "labels = ax.set_xticklabels(list(range(start, end)))\n",
    "title = ax.set_title('clase %d' % clase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, algunas de las componentes (dimensiones del vector X, sin reducción de dimensiones) presentan una gran cantidad de datos atípicos. También se puede visualizar la similitud entre algunas de las componentes, por ejemplo la 18. Estas componentes muy parecidas son las que causaban el *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconocedor de Caras**\n",
    "\n",
    "\n",
    "A continuación se muestra el código necesario para implementar un reconocedor de caras. Como nuestro Dataset tenemos el \"Labeled Faces in the Wild\" o LFW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #as LDA\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=73, resize=0.5)\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Tamaño total del dataset:\")\n",
    "print(f\"n_samples: {n_samples}, hxw: {h} x {w}\")\n",
    "print(f\"Numero de caracteristicas: {n_features}, actually {h} x {w} = {h*w}\")\n",
    "print(f\"Numero de clases: {n_classes}, nombres: {target_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se imprimen algunos de los datos de nuestro dataset. Es posible cambiar la dimensión de la matriz de fotos que se muestran editando los valores n_row (número de filas) y n_col (número de columnas) dentro de la función plot_gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "plot_gallery(X, list(y), h, w, n_row=3, n_col=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos el conjunto de entrenamiento (X_train), el conjunto de test (X_train) y sus respectivas etiquetas (y_train, y_test) de nuestro dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Estadisticas de los datos:\")\n",
    "print(f\"Numero de datos de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Numero de datos de test: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si miramos la dimensión de los componentes del dataset de enternamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_train.shape: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar que los vectores del dataset tienen 2914 componentes. Independientemente de que pueda haber variables colíneares, es necesario reducir el número de componentes de nuestro dataset simplemente por el gasto computacional que supone tratar con vectores tan grandes. Para ello hemos implementado la combinación de análisis de componentes principales y análisis discriminante lineal.\n",
    "\n",
    "\n",
    "Realizamos el análisis de componentes principales (PCA) de la misma forma que lo hemos hecho para el dataset Isolet.\n",
    "En este caso hemos elegido X componentes, que nos proporcionan un Y% de la varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# Paso 1: hacer la media del conjunto de datos de entrenamiento\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "\n",
    "# Paso 2: estandarizar el conjunto de datos de entrenamiento\n",
    "X_norm = X_train - X_train_mean\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "\n",
    "# Paso 3: calcular la nueva matriz de covarianzas del conjunto de datos estandarizados\n",
    "X_train_cov = np.cov(X_norm, rowvar=False)\n",
    "\n",
    "\n",
    "\n",
    "# Paso 4: calcular la descomposición espectral de la matriz de covarianzas\n",
    "u, autoval, autovec = np.linalg.svd(X_train_cov, full_matrices=False) # tarda 68.246s\n",
    "\n",
    "print(\"SVD done in %0.3fs\" % (time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecha la descomposición espectral de la matriz, usando la funcion print_cumvar podemos imprimir las varianzas acumuladas por cada componente para así poder elegir un número adecuado de características a reducir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_cumvar(autoval, X_train.shape[0], 1, 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras hacer el PCA, podemos ver en la matriz de varianzas acumuladas lo siguiente:\n",
    "\n",
    "-Las 5 componentes más óptimas nos garantizan mas de un 90% de la varianza\n",
    "\n",
    "-7 componentes nos garantizan un 95% de la varianza\n",
    "\n",
    "-19 componentes nos garantizan un 99% de la varianza\n",
    "\n",
    "-29 componentes nos garantizan un 99,5% de la varianza\n",
    "\n",
    "-68 componentes nos garantizan un 99,9% de la varianza\n",
    "\n",
    "-168 componentes nos garantizan un 99,99% de la varianza\n",
    "\n",
    "\n",
    "Una vez seleccionado el número de componentes a las que queremos reducir los vectores del dataset, seguimos con el PCA. Cabe destacar que se puede modificar el numero de componentes a las que reducir mediante el parámetro n_component, que por defecto tenemos en 168."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_components = 168\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "\n",
    "# Paso 5: construir la matriz de proyección A seleccionando las n_componentes componentes principales\n",
    "A = autovec[:n_components]\n",
    "\n",
    "\n",
    "# Paso 6: proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_pca = (A @ (X_train - np.mean(X_train, axis=0)).T).T\n",
    "\n",
    "\n",
    "# Paso 7: proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_pca = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"PCA done in %0.3fs\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos las fotos tras la eliminación de las componentes menos discriminates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eigenfaces2 = A.reshape((n_components,h,w))\n",
    "eigenface_titles2 = [\"eigenfaces %d\" % i for i in range(eigenfaces2.shape[0])]\n",
    "plot_gallery(eigenfaces2, eigenface_titles2, h, w, n_row=3, n_col=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas caras, conocidas como eigenfaces, son nuestras fotos iniciales una vez eliminadas sus componentes menos discriminantes.\n",
    "\n",
    "A continuación prodecemos a realizar el análisis discriminante lineal (LDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#LDA\n",
    "t0 = time()\n",
    "\n",
    "#Inicializamos las matrices Sw y Sb\n",
    "#Sw = np.zeros((X_train_pca.shape[1], X_train_pca.shape[1]))\n",
    "#Sb = np.zeros((X_train_pca.shape[1], X_train_pca.shape[1]))\n",
    "\n",
    "Sw = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "Sb = np.zeros((X_train.shape[1], X_train.shape[1]))\n",
    "\n",
    "\n",
    "n_clases = len(np.unique(y_train))\n",
    "\n",
    "#mu_clases = np.mean(X_train_pca, axis=0)\n",
    "mu_clases = np.mean(X_train, axis=0)\n",
    "\n",
    "for i in range(n_clases):\n",
    "    X_clase = X_train[y_train==i]\n",
    "   # X_clase = X_train_pca[y_train==i]\n",
    "    Sw = Sw + np.cov(X_clase, rowvar=False)\n",
    "    Sb = Sb + (len(X_clase) * ((X_clase - mu_clases).T @ (X_clase - mu_clases)))\n",
    "\n",
    "# Calcular la descomposición espectral de la matriz Sw^-1 Sb\n",
    "u, autoval, autovec = np.linalg.svd((np.linalg.inv(Sw)@Sb), full_matrices=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos las varianzas acumuladas de cada componente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print_cumvar(autoval, X_train.shape[0], 1, 314)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "n_components = 168\n",
    "A = autovec[:n_components]\n",
    "\n",
    "print(\"A_lda.shape:\", A.shape)\n",
    "\n",
    "X_train_lda = (A @ X_train_pca.T).T\n",
    "\n",
    "print(\"X_train_lda: \", X_train_lda.shape)\n",
    "\n",
    "# Paso 7: proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_lda = (A @ X_test_pca.T).T\n",
    "\n",
    "#eigenfaces2 = A.reshape((n_components,h,w))\n",
    "print(\"LDA done in %0.3fs\" % (time() - t0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "#clf = ClassifEuclid(np.unique(y_train))\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(\"y_test:\", y_test.shape)\n",
    "print(\"y_pred:\", y_pred.shape)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(\" \", 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(\" \", 1)[-1]\n",
    "    return \"predicted: %s\\ntrue:      %s\" % (pred_name, true_name)\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\n",
    "plot_gallery(X_test, prediction_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
