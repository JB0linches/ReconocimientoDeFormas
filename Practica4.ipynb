{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 1 Reconocimiento de Formas: Clasificador de la distancia euclídea \n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cercadillo Muñoz, Daniel\n",
    "* **Alumno 3**: Cerezo Pomykol, Jan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook de Jupyter contiene las soluciones propuestas a los apartados del enunciado de la práctica 1. Incluye tanto la implementación de los clasificadores como las pruebas realizadas con estos. A continuación se explica el procedimiento seguido para implementar cada clasificador:\n",
    "\n",
    "**Clasificador distancia euclídea:**\n",
    "El entrenamiento de este clasificador consiste en calcular los centroides $z_{i}$ de cada clase:\n",
    "\n",
    "$$z_{i} = \\frac{1}{card(\\alpha_{i})}\\sum\\limits _{∀x\\in\\alpha_{i}}x $$\n",
    "\n",
    "La predicción consiste en calcular la distancia euclídea de cada vector de entrada a los centroides de cada clase y elegir la clase que se corresponde con la menor distancia euclídea asociada. La función de pertenencia es la siguiente:\n",
    "\n",
    "$$ de_{i}(x) ≡ D_{E}(x, z_{i}) = \\sqrt{\\sum\\limits_{j=0}^{n}(x_{j}-z_{i})^{2}}$$\n",
    "\n",
    "Donde $D_{E}(x, z_{i})$ es la distancia eculídea de $x$ al centroide $z_{i}$ y $j$ es la dimensión de cada dato. Dado que esta función proporciona la distancia a una clase, se selecciona el valor mínimo. Se asigna el elemento $x$ a la clase $α_{i}$ si:\n",
    "\n",
    "$$ i = \\arg_{\\min_{j}}\\{de_{i}(x)\\} $$\n",
    "\n",
    "**Clasificador estadístico bayesiano:** Este clasificador parte de la hipótesis de distribución gaussiana. La función de pertenencia del clasificador es la siguiente:\n",
    "\n",
    "$$ db_{i}(x) = -\\frac{1}{2}ln(|\\Sigma_{i}|)-\\frac{1}{2}(x-\\mu_{i})^{T}\\Sigma_{i}^{-1}(x-\\mu_{i})+\\ln P(\\alpha_{i})$$\n",
    "\n",
    "Donde $\\Sigma_{i}$ es la matriz de covarianza de la clase $\\alpha_{i}$, $P(\\alpha_{i})$ es la probabilidad a priori de la clase $\\alpha_{i}$, y $\\mu_{i}$ es la media de la clase $\\alpha_{i}$. Dado que esta función proporciona una probabilidad de pertenencia a una clase, se selecciona el valor máximo. Se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg_{\\max_{j}}\\{db_{i}(x)\\} $$\n",
    "\n",
    "En la implementación se emplea $dbq_{i} = \\ln(db_{i}(x))$, que tiene forma cuadrática:\n",
    "\n",
    "$$ dbq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{-1}] + [\\mu_{i}^{T}\\Sigma_{i}^{-1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "En la implementación, los términos $a$, $b$ y $c$ de la expresión cuadrática $ax^{2}+bx+c$ se corresponden con:\n",
    "\n",
    "$$a = -\\frac{1}{2}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$b = \\mu_{i}^{T}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$c = -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "Estos términos se calculan en el entrenamiento del clasificador, dado que son independientes del vector $x$ de entrada. En la función clasificadora, se calcula $dbq_{i}(x)$.\n",
    "\n",
    "El clasificador regularizado añade dos hiperparámetros en el cálculo de $db_{i}(x)$: $\\lambda$ y $\\gamma$. El primero indica una medida de similitud entre clases, mientras que el segundo sirve para regularizar la matrix de covarianzas. Primero se calcula la matrix $\\Sigma_{i}^{\\lambda}$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda} = \\frac{(1-\\lambda)n_{i}\\Sigma_{i} + \\lambda nS_{w}}{(1-\\lambda)n_{i} + \\lambda n}$$\n",
    "\n",
    "Donde $n_{i}$ es el número de representantes de la clase $i$, $n$ es el número total de representantes, y $S_{w}$ es la matriz\n",
    "\n",
    "$$S_{w} = \\sum\\limits_{i=0}^{n_{c}}\\frac{n_{i}}{n}\\Sigma_{i}$$\n",
    "\n",
    "donde $n_{c}$ es el número de clases.\n",
    "\n",
    "A continuación se calcula la matriz $\\Sigma_{i}^{\\lambda, \\gamma}$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda, \\gamma} = (1-\\lambda)\\Sigma_{i}^{\\lambda} + \\gamma c_{i} I_{d}$$\n",
    "\n",
    "Donde $I_{d}$ es la matriz identidad $d x d$, $d$ la dimensión de cada representante y $c_{i}$ es:\n",
    "\n",
    "$$c_{i} = \\frac{Tr\\{\\Sigma_{i}^{\\lambda}\\}}{d}$$\n",
    "\n",
    "Con la nueva matrix de covarianzas $\\Sigma_{i}^{\\lambda, \\gamma}$ se calcula $dbrq_{i}(x)$: \n",
    "\n",
    "$$ dbrq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{\\lambda, \\gamma -1}] + [\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}^{\\lambda, \\gamma}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "**NOTA**: Se incluyen las implemetanciones de los siguientes clasificadores:\n",
    "* **Clasificador de la distancia euclídea**: implementado con la función $de_{i}(x)$. Está disponible en la clase *ClassifEuclid.*\n",
    "* **Clasificador estadístico sin regularizar:** implementado con la función $dbq_{i}(x)$. Está disponible en la clase *ClassifEstadistico*\n",
    "* **Clasificador estadístico regularizado:** implementado con la función $dbrq_{i}(x)$. Está disponible en la clase *ClassifEstadisticoRegularizado_metodo_clase*\n",
    "* **Clasificador estadístico regularizado (método de sklearn):** implementado con regularización por autovectores. Está disponible en la clase *ClassifEstadisticoRegularizado_metodo_sklearn*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementación de clasificadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y) / len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEuclid(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n = np.zeros(len(self.labels)) # Contador de ocurrencias de cada clase\n",
    "        self.Z = np.zeros((len(self.labels), X.shape[1]))\n",
    "        # Calcular la media: \n",
    "        # Sumar las ocurrencias de cada clase en self.Z\n",
    "        for yi, Xi in zip(y, X):\n",
    "            n[yi] = n[yi] + 1\n",
    "            self.Z[yi] = self.Z[yi] + Xi\n",
    "        # Dividir cada sumatorio entre el númeo de ocurrencias\n",
    "        self.Z = self.Z / n[:, None]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadistico(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            self.cov[c] = np.cov(X[y==c], rowvar=False)\n",
    "            self.mu[c] = np.mean(X[y==c], axis=0)\n",
    "            self.cov_inv[c] = np.linalg.inv(self.cov[c])\n",
    "            self.det[c] = np.linalg.det(self.cov[c])\n",
    "            self.a[c] = -.5 * self.cov_inv[c]\n",
    "            self.b[c] = self.mu[c].T @ self.cov_inv[c]\n",
    "            self.c[c] = -.5 * (self.mu[c].T @ self.cov_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(np.sum(y==c)/X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado (método visto en clase, explicado en la introducción)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_clase(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_reg = None # Array de matrices de covarianza regularizadas\n",
    "        self.cov_reg_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "        self.dont_ignore = [] # dimensiones a NO ignorar si cov se puede invertir\n",
    "        self.priori = None\n",
    "\n",
    "    def fit(self, X, y, l=0, g=0):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        l: hiperparámetro de similitud entre matrices de covarianza\n",
    "        g: hiperparámetro de regularización\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_lg = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_lg_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        self.priori = np.empty(n_labels)\n",
    "        cov_pooled = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            self.cov[c] = np.cov(X_clase, rowvar=False)\n",
    "            cov_pooled = cov_pooled + ((X_clase.shape[0] / X.shape[0]) * self.cov[c])  # Matriz Sw en el libro de Webb (formula 2.15, pagina 42)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            cov_l = (((1 - l) * X_clase.shape[0] * self.cov[c]) + (l * X.shape[0] * cov_pooled)) / ((1 - l) * X_clase.shape[0] + l * X.shape[0])\n",
    "            self.cov_lg[c] = (1 - g) * cov_l + g * (np.trace(cov_l) / n_caracteristicas) * np.eye(n_caracteristicas)\n",
    "            self.det[c] = np.linalg.det(self.cov_lg[c])\n",
    "            if self.det[c] != 0:\n",
    "                self.cov_lg_inv[c] = np.linalg.inv(self.cov_lg[c])\n",
    "                self.det[c] = np.linalg.det(self.cov_lg[c])\n",
    "                self.a[c] = -.5 * self.cov_lg_inv[c]\n",
    "                self.b[c] = self.mu[c].T @ self.cov_lg_inv[c]\n",
    "                self.priori = X_clase.shape[0] / X.shape[0]\n",
    "                self.c[c] = -.5 * (self.mu[c].T @ self.cov_lg_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(self.priori)\n",
    "                self.dont_ignore.append(c)\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.zeros((X.shape[0], len(self.labels)))\n",
    "        for c in self.dont_ignore:\n",
    "            res[:,c] = -.5 * np.log(self.det[c]) - .5 * np.diagonal((X - self.mu[c]) @ self.cov_lg_inv[c] @ (X - self.mu[c]).T) + np.log(self.priori)\n",
    "        return res\n",
    "        #return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado por autovectores (método de sklearn)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_sklearn(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[], reg_param=0):\n",
    "        self.labels = labels\n",
    "        self.reg_param = 0 # hiperparametro\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.prob_clases = None\n",
    "        self.ajustes = []\n",
    "        self.autovectores = []\n",
    "\n",
    "    def fit(self, X, y, reg_param=0):\n",
    "        if self.reg_param == 0:\n",
    "            self.reg_param = reg_param\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.prob_clases = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c, :]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            X_new = X_clase - self.mu[c]\n",
    "            # descomposicion espectral\n",
    "            _, autovalores, autovectores = np.linalg.svd(X_new, full_matrices=False)\n",
    "            ajuste = (autovalores ** 2) / (X_new.shape[0] - 1)\n",
    "            ajuste = ((1 - self.reg_param) * ajuste) + self.reg_param\n",
    "            self.cov[c] = (ajuste * autovectores.T) @ autovectores # np.dot(ajuste * autovectores.T, autovectores)\n",
    "            self.ajustes.append(np.copy(ajuste))\n",
    "            self.autovectores.append(np.copy(autovectores))\n",
    "            self.prob_clases[c] = X_clase.shape[0] / X.shape[0]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.empty((X.shape[0], len(self.labels)))\n",
    "        for c in range(len(self.labels)):\n",
    "            res[:,c] = np.sum(((X - self.mu[c]) @ (self.autovectores[c] * (self.ajustes[c] ** -.5)[:, None]).T) ** 2, axis=1)\n",
    "        aux = np.asarray([np.sum(np.log(x)) for x in self.ajustes])\n",
    "        return (-.5 * (res.T + aux[:, None]) + np.log(self.prob_clases)[:, None]).T\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clase Splitter para GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusionSplitter:\n",
    "    \"\"\"Esta clase nos permite usar GridSearchCV con la valuación por exclusion.\"\"\"\n",
    "    def __init__(self, train_indices, test_indices):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return [(self.train_indices, self.test_indices)]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de Cross Validation con KFolds**\n",
    "Esta implementación funciona, pero no debe usarse. No siempre ofrece los mismos resultados porque el array de entrada se baraja de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clsf, X, y, cv):\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X_chunks = np.array_split(X[permutation], cv)\n",
    "    y_chunks = np.array_split(y[permutation], cv)\n",
    "    scores = np.empty(cv)\n",
    "    for i in range(cv):\n",
    "        X_test = X_chunks[i]\n",
    "        y_test = y_chunks[i]\n",
    "        X_train_chunks = X_chunks[:i] + X_chunks[i+1:]\n",
    "        y_train_chunks = y_chunks[:i] + y_chunks[i+1:]\n",
    "        X_train = np.vstack(X_train_chunks)\n",
    "        y_train = np.hstack(y_train_chunks)\n",
    "        clsf.fit(X_train, y_train)\n",
    "        scores[i] = clsf.score(X_test, y_test)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de Cross Validation con Stratified KFolds**\n",
    "Esta implementación funciona, pero no debe usarse. No es una implementación eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def cv_score_skf(clsf, X, y, cv, reg_param=0):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    i = 0\n",
    "    for train_i, test_i in skf.split(X, y):\n",
    "        X_train = X[train_i]\n",
    "        y_train = y[train_i]\n",
    "        X_test = X[test_i]\n",
    "        y_test = y[test_i]\n",
    "        clsf.fit(X_train, y_train, reg_param)\n",
    "        scores[i] = clsf.score(X_test, y_test)\n",
    "        i = i + 1\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "# **Entrenamiento, predicción y evaluación de iris, wine y cancer**\n",
    "A continuación se realizan las pruebas correspondientes con las bases de datos iris, wine y cancer con el clasificador estadístico y el clasificador de la distancia euclídea. Al final se incluye una tabla resumen con los resultados. Por cada clasificador y base de datos se imprime el resultado obtenido por el clasificador equivalente de sklearn, con el fin de verificar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: datos: (150, 4) n_clases: 3\n",
      "wine: datos: (178, 13) n_clases: 3\n",
      "cancer: datos: (569, 30) n_clases: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Load data\n",
    "dataset_iris = load_iris()\n",
    "X_iris = dataset_iris.data\n",
    "y_iris = dataset_iris.target\n",
    "dataset_wine = load_wine()\n",
    "X_wine = dataset_wine.data\n",
    "y_wine = dataset_wine.target\n",
    "dataset_cancer = load_breast_cancer()\n",
    "X_cancer = dataset_cancer.data\n",
    "y_cancer = dataset_cancer.target\n",
    "print(\"iris: datos:\", X_iris.shape, \"n_clases:\", len(np.unique(y_iris)))\n",
    "print(\"wine: datos:\", X_wine.shape, \"n_clases:\", len(np.unique(y_wine)))\n",
    "print(\"cancer: datos:\", X_cancer.shape, \"n_clases:\", len(np.unique(y_cancer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 139/150 (92.67%)\n",
      "\t\tEvaluación por resustitución: 0.9267\n",
      "\t\tEvaluación por validación cruzada: 0.9133, std: 0.0499\n",
      "\t\tClasificador sklearn: 139 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_iris.target_names)\n",
    "clsf_euc.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "#scores = cv_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 129/178 (72.47%)\n",
      "\t\tEvaluación por resustitución: 0.7247\n",
      "\t\tEvaluación por validación cruzada: 0.7187, std: 0.0804\n",
      "\t\tClasificador sklearn: 129 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_wine.target_names)\n",
    "clsf_euc.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_euc, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 507/569 (89.10%)\n",
      "\t\tEvaluación por resustitución: 0.8910\n",
      "\t\tEvaluación por validación cruzada: 0.8841, std: 0.0840\n",
      "\t\tClasificador sklearn: 507 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_cancer.target_names)\n",
    "clsf_euc.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_euc, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 147/150 (98.00%)\n",
      "\t\tEvaluación por resustitución: 0.9800\n",
      "\t\tEvaluación por validación cruzada: 0.9600, std: 0.0646\n",
      "\t\tClasificador sklearn: 147 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_iris.target_names)\n",
    "clsf_est.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_est.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_est, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 177/178 (99.44%)\n",
      "\t\tEvaluación por resustitución: 0.9944\n",
      "\t\tEvaluación por validación cruzada: 0.7108, std: 0.3660\n",
      "\t\tClasificador sklearn: 177 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_wine.target_names)\n",
    "clsf_est.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_est.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_est, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 554/569 (97.36%)\n",
      "\t\tEvaluación por resustitución: 0.9736\n",
      "\t\tEvaluación por validación cruzada: 0.9613, std: 0.0090\n",
      "\t\tClasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_cancer.target_names)\n",
    "clsf_est.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_est.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_est, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resultados de los tres experimentos (clasificador distancia euclídea):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 139| 92.67|\n",
    "| Wine   | 129| 72.47|\n",
    "| Cancer | 507| 89.10|\n",
    "\n",
    "Resultados de los tres experimentos (clasificador estadístico):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147| 98.00|\n",
    "| Wine   | 177| 99.44|\n",
    "| Cancer | 554| 97.37|\n",
    "\n",
    "Dimensiones de las bases de datos:\n",
    "\n",
    "| Base de datos | Número de clases | Número de datos | Dimension de cada dato |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 3 | 150 | 4 |\n",
    "| Wine   | 3 | 178 | 13 |\n",
    "| Cancer | 2 | 569 | 30 |\n",
    "\n",
    "Como se puede observar, el clasificador estadístico tiene mejor tasa de aciertos con las tres bases de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento y evaluación de Isolet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolet: datos: (7797, 617) n_clases: 26\n",
      "\tClasificador distancia euclídea:\n",
      "\t\tEvaluación por resustitución:\t 0.8809\n",
      "\t\tEvaluación por exclusión:\t 0.8743\n",
      "\tClasificador estadístico regularizado con el método de clase:\n",
      "\t\tEvaluación por resustitución:\t 0.0384738698\n",
      "\t\tEvaluación por exclusión:\t 0.0384862091\n",
      "\tClasificador estadístico regularizado con el método de sklearn:\n",
      "\t\tEvaluación por resustitución:\t 1.0000\n",
      "\t\tEvaluación por exclusión:\t 0.0648\n",
      "\tClasificador estadístico de sklearn:\n",
      "\t\tEvaluación por resustitución:\t 1.0000\n",
      "\t\tEvaluación por exclusión:\t 0.0648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_train = np.array(X[:6238])\n",
    "y_train = pd.factorize(y)[0][:6238]\n",
    "X_test = np.array(X[6238:])\n",
    "y_test = pd.factorize(y)[0][6238:]\n",
    "\n",
    "X = np.array(X)\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Clasificador distancia euclidea\n",
    "clss_euc = ClassifEuclid(np.unique(y_train))\n",
    "clss_euc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de clase\n",
    "clss_est_mc = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "clss_est_mc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de sklearn\n",
    "clss_est_msk = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est_msk.fit(X_train, y_train)\n",
    "# Clasificador estadístico de sklearn\n",
    "clss_est_sk = QuadraticDiscriminantAnalysis()\n",
    "clss_est_sk.fit(X_train, y_train)\n",
    "\n",
    "print(\"isolet: datos:\", X.shape, \"n_clases:\", len(np.unique(y)))\n",
    "\n",
    "print(\"\\tClasificador distancia euclídea:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_euc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_euc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de clase:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.10f\" % clss_est_mc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.10f\" % clss_est_mc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_msk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_msk.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_sk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_sk.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tEvaluación por resustitución: 0.9535\n",
      "\t\tEvaluación por exclusión: 0.9519\n",
      "\t\tEvaluación por resustitución: 0.9186\n",
      "\t\tEvaluación por exclusión: 0.9557\n",
      "\t\tEvaluación por resustitución: 0.8955\n",
      "\t\tEvaluación por exclusión: 0.9532\n"
     ]
    }
   ],
   "source": [
    "clss_est = ClassifEstadisticoRegularizado(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.1)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n",
    "clss_est = ClassifEstadisticoRegularizado(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.2)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n",
    "clss_est = ClassifEstadisticoRegularizado(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.3)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador de la distancia euclídea:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9267 | 0.9133 | - |\n",
    "| Wine   | 0.7247 | 0.7187 | - |\n",
    "| Cancer | 0.8910 | 0.8841 | - |\n",
    "| Isolet |  0.8809 | - | 0.8743 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador estadístico bayesiano:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9800 | 0.9600 | - |\n",
    "| Wine   | 0.9944 | 0.7108 | - |\n",
    "| Cancer | 0.9736 | 0.9613 | - |\n",
    "| Isolet |  1.0000 | - | 0.0648 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comentarios sobre los resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijándonos en la columna de aciertos por sustitución, vemos que el estadístico comete menos errores en las 3 bases de datos,\n",
    "siendo mas destacable la diferencia en cuanto al porcentaje de aciertos en las de Wine y Cancer, puesto que pasa de un 72,47%\n",
    "a un 99,44% en Wine y de un 89,1% a un 97,36%. Sin embargo, este incremento de la tasa de aciertos no se corresponde con un\n",
    "aumento real de la precisión del clasificador, si no con un error en la forma de evaluar el rendimiento de los clasificadores.\n",
    "Al evaluar ambos por validación cruzada, comprobamos que el aumento no es tan grande como el obtenido evaluando solo por\n",
    "resusitución, siendo incluso menor la precisión del estadístico en Wine a pesar de que era donde a priori se producia el mayor\n",
    "aumento. A pesar del peor rendimiento obtenido por el bayesiano en Wine, no podemos obviar que ha desempeñado mejor su funcion\n",
    "en las otras dos bases de datos, mostrando incluso un aumento de la tasas de aciertos desde un 88,41% a un 96,13% en Cancer.\n",
    "\n",
    "En cuanto a los resultados obtenidos en Isolet, vemos que los resultados del euclideo concuerdan más con los resultados que se\n",
    "esperan de un clasificador que los del bayesiano. Como podemos ver, en el bayesiano se ha obtenido un 100% de precision por\n",
    "resustitución, sin embargo se ha obtenido un 6,48% por exclusion. Este fenómeno se debe a la existencia de variables linealmente\n",
    "dependientes en el conjunto de entrenamiento de isolet. Debido a las variables colineares, es imposible hallar la inversa de la\n",
    "matriz de covarianzas, por lo que estos datos no se tienen en cuenta afectando negativamente al rendimiento del bayesiano, sin\n",
    "embargo esto no sucede con el euclideo puesto que no tiene en cuenta el factor de la dispersion de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet con hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSelected shrinkage = 0.23\n",
      "\tAccuracy: 0.956 (+/- 0.000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhyperparams = [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\\nscores = find_best_hyperparam(X, y, 3, hyperparams)\\nprint(scores, scores==np.max(scores))\\nprint(\"max score:\", np.max(scores), \"scores:\", scores)\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_best_parameters_quad(X, y, k, shrinkages):\n",
    "    # Creamos una instancia del clasificador\n",
    "    cbp = QuadraticDiscriminantAnalysis()\n",
    "    # definimos la rejilla en la que vamos a buscar\n",
    "    params = {'reg_param': shrinkages}\n",
    "    # Creamos una clase GridSearchCV que será una especie de supra-clasificador\n",
    "    # que se ajusta por validación cruzada.\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-1, scoring='accuracy', cv=k).fit(X, y)\n",
    "    # Como supra-clasificador que es, clf contiene todo tipo de datos sobre la evaluación\n",
    "    # por validación cruzada. Vamos a obtener en este caso el clasificador con mejor 'accuracy'\n",
    "    best_clf = clf.best_estimator_\n",
    "    # clf.cv_results_ contiene los resultados de la evaluación, obtengamos la media y\n",
    "    # desviación típica del score de validación\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "    # print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "\n",
    "    # Imprimamos los mejores parametro que hemos encontrado y el resultado de su validación\n",
    "    print(\"\\tSelected shrinkage = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.reg_param,\n",
    "                                                   result_score_mean,\n",
    "                                                   result_score_std))\n",
    "    return best_clf\n",
    "\n",
    "def find_best_hyperparam(X, y, k, shrinkages):\n",
    "    scores = np.empty((len(shrinkages), k))\n",
    "    for h in range(len(shrinkages)):\n",
    "        skf = StratifiedKFold(n_splits=k)\n",
    "        i = 0\n",
    "        for train_i, test_i in skf.split(X, y):\n",
    "            X_train = X[train_i]\n",
    "            y_train = y[train_i]\n",
    "            X_test = X[test_i]\n",
    "            y_test = y[test_i]\n",
    "            cbp = ClassifEstadisticoRegularizado(np.unique(y))\n",
    "            cbp.fit(X_train, y_train, shrinkages[h])\n",
    "            scores[h][i] = cbp.score(X_test, y_test)\n",
    "            i = i + 1\n",
    "    return np.max(scores, axis=1)\n",
    "\n",
    "    \n",
    "#ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test)))\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))),\n",
    "                                [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3])\n",
    "#clf = find_best_parameters_quad2(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))),\n",
    "#                                [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3])\n",
    "\"\"\"\n",
    "clf = ClassifEstadisticoRegularizado(np.unique(y), [0.2, 0.21])\n",
    "clf.fit(X, y)\n",
    "#clf.decision_function(X)\n",
    "clf.num_aciertos(X, y)\n",
    "\"\"\"\n",
    "#clf = find_best_parameters_quad2(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))),\n",
    "#                                [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3])\n",
    "\"\"\"\n",
    "hyperparams = [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\n",
    "scores = find_best_hyperparam(X, y, 3, hyperparams)\n",
    "print(scores, scores==np.max(scores))\n",
    "print(\"max score:\", np.max(scores), \"scores:\", scores)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
      "[0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\n"
     ]
    }
   ],
   "source": [
    "# 0.23 -> 0.956\n",
    "\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 10\n",
    "for ffff in range(x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 30\n",
    "for ffff in range(20, x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "class prueba():\n",
    "    def __init__(self, labels, tremendo=0):\n",
    "        if tremendo == 0:\n",
    "            self.x = len(labels)\n",
    "        else:\n",
    "            self.x = tremendo\n",
    "    def print_X(self):\n",
    "        print(self.x)\n",
    "    \n",
    "p = prueba([1, 2, 3], tremendo=2)\n",
    "p.print_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
