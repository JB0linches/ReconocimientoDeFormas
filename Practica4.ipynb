{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# **Práctica Final Reconocimiento de Formas**\n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cerezo Pomykol, Jan\n",
    "\n",
    "**Nota**: El alumno *Cercadillo Muñoz, Daniel*, que figura en las anteriores entregas, sin haber participado en la elaboración de ninguna de ellas, nos ha confirmado oficialmente que ha abandonado la asignatura, por tanto no consta como autor en esta práctica. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook de Jupyter contiene las soluciones propuestas a los apartados del enunciado de la práctica correspondiente a la primera parte de la asignatura. Incluye tanto la implementación de los clasificadores como las pruebas realizadas con estos. A continuación se explica el procedimiento seguido para implementar cada clasificador, así como los métodos de reducción de la dimensionalidad vistos en clase:\n",
    "\n",
    "***\n",
    "\n",
    "**Clasificador distancia euclídea:**\n",
    "El entrenamiento de este clasificador consiste en calcular los centroides $z_{i}$ de cada clase. Esto es lo que hace la función `fit` del clasificador.\n",
    "\n",
    "$$z_{i} = \\frac{1}{card(\\alpha_{i})}\\sum\\limits _{\\forall x\\in\\alpha_{i}}x$$\n",
    "\n",
    "La predicción consiste en calcular la distancia euclídea de cada vector de entrada a los centroides de cada clase y elegir la clase que se corresponde con la menor distancia euclídea asociada. El cálculo de pertenencia se hace con `decision_function`. La función de pertenencia es la siguiente:\n",
    "\n",
    "$$ de_{i}(x) \\equiv D_{E}(x, z_{i}) = \\sqrt{\\sum\\limits_{j=0}^{n}(x_{j}-z_{i})^{2}}$$\n",
    "\n",
    "Donde $D_{E}(x, z_{i})$ es la distancia eculídea de $x$ al centroide $z_{i}$ y $j$ es la dimensión de cada dato. Dado que esta función proporciona la distancia a una clase, se selecciona el valor mínimo. Se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg_{\\min_{j}}\\{de_{i}(x)\\} $$\n",
    "\n",
    "Esta operación se ejecuta en la función `predict`.\n",
    "\n",
    "***\n",
    "\n",
    "**Clasificador estadístico bayesiano:** Este clasificador parte de la hipótesis de distribución gaussiana. La función de pertenencia del clasificador es la siguiente:\n",
    "\n",
    "$$ db_{i}(x) = -\\frac{1}{2}ln(|\\Sigma_{i}|)-\\frac{1}{2}(x-\\mu_{i})^{T}\\Sigma_{i}^{-1}(x-\\mu_{i})+\\ln P(\\alpha_{i})$$\n",
    "\n",
    "Donde $\\Sigma_{i}$ es la matriz de covarianza de la clase $\\alpha_{i}$, $P(\\alpha_{i})$ es la probabilidad a priori de la clase $\\alpha_{i}$, y $\\mu_{i}$ es la media de la clase $\\alpha_{i}$. Dado que esta función proporciona una probabilidad de pertenencia a una clase, se selecciona el valor máximo. Se asigna el elemento $x$ a la clase $\\alpha_{i}$ si:\n",
    "\n",
    "$$ i = \\arg_{\\max_{j}}\\{db_{i}(x)\\} $$\n",
    "\n",
    "En la implementación se emplea $dbq_{i} = \\ln(db_{i}(x))$, que tiene forma cuadrática:\n",
    "\n",
    "$$ dbq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{-1}]x + [\\mu_{i}^{T}\\Sigma_{i}^{-1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "En la implementación, los términos $a$, $b$ y $c$ de la expresión cuadrática $ax^{2}+bx+c$ se corresponden con:\n",
    "\n",
    "$$a = -\\frac{1}{2}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$b = \\mu_{i}^{T}\\Sigma_{i}^{-1}$$\n",
    "\n",
    "$$c = -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{-1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "Estos términos se calculan en el entrenamiento del clasificador, dado que son independientes del vector $x$ de entrada. En la función clasificadora, se calcula $dbq_{i}(x)$. (?)\n",
    "\n",
    "El clasificador regularizado añade dos hiperparámetros en el cálculo de $db_{i}(x)$: $\\lambda$ y $\\gamma$. El primero indica una medida de similitud entre clases, mientras que el segundo sirve para regularizar la matriz de covarianzas. Primero se calcula la matriz $\\Sigma_{i}^{\\lambda}$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda} = \\frac{(1-\\lambda)n_{i}\\Sigma_{i} + \\lambda nS_{w}}{(1-\\lambda)n_{i} + \\lambda n}$$\n",
    "\n",
    "Donde $n_{i}$ es el número de representantes de la clase $i$, $n$ es el número total de representantes, y $S_{w}$ es la matriz\n",
    "\n",
    "$$S_{w} = \\sum\\limits_{i=0}^{n_{c}}\\frac{n_{i}}{n}\\Sigma_{i}$$\n",
    "\n",
    "donde $n_{c}$ es el número de clases.\n",
    "\n",
    "A continuación se calcula la matriz $\\Sigma_{i}^{\\lambda, \\gamma}$:\n",
    "\n",
    "$$\\Sigma_{i}^{\\lambda, \\gamma} = (1-\\lambda)\\Sigma_{i}^{\\lambda} + \\gamma c_{i} I_{d}$$\n",
    "\n",
    "Donde $I_{d}$ es la matriz identidad $d x d$, $d$ la dimensión de cada representante y $c_{i}$ es:\n",
    "\n",
    "$$c_{i} = \\frac{Tr\\{\\Sigma_{i}^{\\lambda}\\}}{d}$$\n",
    "\n",
    "Con la nueva matriz de covarianzas $\\Sigma_{i}^{\\lambda, \\gamma}$ se calcula $dbrq_{i}(x)$: \n",
    "\n",
    "$$ dbrq_{i}(x) = x^{T}[-\\frac{1}{2}\\Sigma_{i}^{\\lambda, \\gamma -1}]x + [\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}]x -\\frac{1}{2}\\mu_{i}^{T}\\Sigma_{i}^{\\lambda, \\gamma -1}\\mu_{i} -\\frac{1}{2}\\ln|\\Sigma_{i}^{\\lambda, \\gamma}| + \\ln P(\\alpha_{i})$$\n",
    "\n",
    "**NOTA**: Se incluyen las implemetanciones de los siguientes clasificadores:\n",
    "* **Clasificador de la distancia euclídea**: implementado con la función $de_{i}(x)$. Está disponible en la clase *ClassifEuclid.*\n",
    "* **Clasificador estadístico sin regularizar:** implementado con la función $dbq_{i}(x)$. Está disponible en la clase *ClassifEstadistico*\n",
    "* **Clasificador estadístico regularizado:** implementado con la función $dbrq_{i}(x)$. Está disponible en la clase *ClassifEstadisticoRegularizado_metodo_clase*\n",
    "* **Clasificador estadístico regularizado (método de sklearn):** implementado con regularización por autovectores. Está disponible en la clase *ClassifEstadisticoRegularizado_metodo_sklearn*\n",
    "\n",
    "***\n",
    "\n",
    "**Análisis de Componentes Principales:** Este método tiene como objetivo eliminar características no discriminantes de un conjunto de datos, de forma que se conserva la mayoría de la información necesaria para la decisión, eliminando un número considerable de información poco relevante. Esta técnica se puede emplear en múltiples campos, pero detallaremos el procedimiento para esta práctica.\n",
    "\n",
    "Partiendo de un conjunto de datos $X$ que contiene dimensiones que no aportan información dado que la varianza de esa dimensión es muy pequeña, el Análisis de Componentes Principales consiste en escoger las componentes asociadas a las varianzas más altas de cada una de las dimensiones. Dicho de otra forma, es un método de selección de componentes que maximiza la varianza dentro de cada clase.\n",
    "\n",
    "1. El primer paso consiste en calcular la media del vector $X$ de datos.\n",
    "\n",
    "$$\\bar X = \\frac{1}{m}\\sum\\limits_{i=1}^{m}X_{i}$$\n",
    "\n",
    "2. El segundo paso consiste en estandarizar el conjunto de datos. Para ello se resta al vector $X$ su media $\\bar X$.\n",
    "\n",
    "$$\\hat X = X - \\bar X$$\n",
    "\n",
    "3. Se calcula la matriz de covarianzas $\\Sigma_{\\hat X}$ de $\\hat X$.\n",
    "\n",
    "4. Se calcula la descomposición espectral de la matriz $\\Sigma_{\\hat X}$. Los autovalores ordenados de mayor a menor, proporcionan los autovectores correspondientes a las direcciones de máxima varianza del conjunto de datos. En este punto es posible entender por qué es importante estandarizar los datos (paso 2), veamos un ejemplo. Supongamos que queremos clasificar personas según lo que cobran cada día. Para este problema, en una variable medimos el salario anual, y en otra el número de días que se trabaja al año. En este caso el salario estará en el rango de las decenas de miles, mientras que el número de días nunca será superior a 365. Si los sueldos de nuestro conjunto de datos varían entre 9.000€ hasta 40.000€ (por ejemplo), y los días varían entre 100 y 300 días, se ve claramente que el autovector asociado al autovalor mayor es el de los salarios. El objetivo del Análisis de Componentes Principales es reducir el conjunto de datos sin perder demasiada información. En este ejemplo, el salario es la variable que tiene mayor varianza. Pero podría darse el caso de que no es la variable más importante para el problema que queremos resolver, por tanto sería incorrecto seleccionar el autovector asociado. Es por esto por lo que es necesario estandarizar los datos.\n",
    "\n",
    "$$\\Sigma_{\\hat X} = P\\Lambda P^{T}$$\n",
    "\n",
    "5. Se construye la matriz de proyección $A$, compuesta por los $k$ autovectores de mayor autovalor asociado ($P_{1-k}$). El valor de $k$ es un hiperparámetro, indica el número de componentes que se conservarán.\n",
    "\n",
    "$$A = P_{1-k}$$\n",
    "\n",
    "6. Se proyectan los datos estandarizados sobre el nuevo espacio:\n",
    "\n",
    "$$X_{pr} = A^{T}\\hat X$$\n",
    "\n",
    "Con el conjunto de datos $X_{pr}$ se entrena el clasificador. Cuando se quiere evaluar, es necesario estandarizar los datos del test y proyectarlos sobre el mismo espacio:\n",
    "\n",
    "$$X_{pr} = A^{T}(X-\\bar X)$$\n",
    "\n",
    "***\n",
    "\n",
    "**Análisis Discriminante Lineal:** Este método, al igual que el Análisis de Componentes Principales, consiste en reducir la dimensionalidad de un conjunto de datos. Tiene como objetivo maximizar la separabilidad entre las clases, pero minimizando la varianza dentro de cada clase, es decir, maximiza el Ratio de Fisher. Esta técnica también se puede emplear en múltiples campos, pero detallaremos el procedimiento seguido en esta práctica.\n",
    "\n",
    "1. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Este método asigna el dato $x$ a la clase que minimize la distancia de Mahalanobis, teniendo en cuenta además la probabilidad a priori de cada clase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementación de clasificadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "from time import time\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y) / len(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEuclid(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n = np.zeros(len(self.labels)) # Contador de ocurrencias de cada clase\n",
    "        self.Z = np.zeros((len(self.labels), X.shape[1]))\n",
    "        # Calcular la media: \n",
    "        # Sumar las ocurrencias de cada clase en self.Z\n",
    "        for yi, Xi in zip(y, X):\n",
    "            n[yi] = n[yi] + 1\n",
    "            self.Z[yi] = self.Z[yi] + Xi\n",
    "        # Dividir cada sumatorio entre el númeo de ocurrencias\n",
    "        self.Z = self.Z / n[:, None]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadistico(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            self.cov[c] = np.cov(X_clase, rowvar=False)\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            self.cov_inv[c] = np.linalg.inv(self.cov[c])\n",
    "            self.det[c] = np.linalg.det(self.cov[c])\n",
    "            self.a[c] = -.5 * self.cov_inv[c]\n",
    "            self.b[c] = self.mu[c].T @ self.cov_inv[c]\n",
    "            self.c[c] = -.5 * (self.mu[c].T @ self.cov_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(X_clase.shape[0] / X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado (método visto en clase, explicado en la introducción)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_clase(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_reg = None # Array de matrices de covarianza regularizadas\n",
    "        self.cov_reg_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        self.dont_ignore = [] # dimensiones a NO ignorar si cov se puede invertir\n",
    "        self.priori = None\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self, X, y, l=0, g=0):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        l: (lambda) hiperparámetro de similitud entre matrices de covarianza (ver introduccion)\n",
    "        g: (gamma) hiperparámetro de regularización (ver introduccion)\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_lg = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_lg_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.priori = np.empty(n_labels)\n",
    "        cov_pooled = np.zeros((n_caracteristicas, n_caracteristicas))\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            self.cov[c] = np.cov(X_clase, rowvar=False)\n",
    "            cov_pooled = cov_pooled + ((X_clase.shape[0] / X.shape[0]) * self.cov[c])  # Matriz Sw en el libro de Webb (formula 2.15, pagina 42)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            cov_l = (((1 - l) * X_clase.shape[0] * self.cov[c]) + (l * X.shape[0] * cov_pooled)) / ((1 - l) * X_clase.shape[0] + l * X.shape[0])\n",
    "            self.cov_lg[c] = (1 - g) * cov_l + g * (np.trace(cov_l) / n_caracteristicas) * np.eye(n_caracteristicas)\n",
    "            self.det[c] = np.linalg.det(self.cov_lg[c])\n",
    "            if self.det[c] != 0:\n",
    "                self.cov_lg_inv[c] = np.linalg.inv(self.cov_lg[c])\n",
    "                self.det[c] = np.linalg.det(self.cov_lg[c])\n",
    "                self.priori = X_clase.shape[0] / X.shape[0]\n",
    "                self.dont_ignore.append(c)\n",
    "                self.a[c] = -.5 * self.cov_lg_inv[c]\n",
    "                self.b[c] = self.mu[c].T @ self.cov_lg_inv[c]\n",
    "                self.c[c] = -.5 * (self.mu[c].T @ self.cov_lg_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(X_clase.shape[0] / X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.zeros((X.shape[0], len(self.labels)))\n",
    "        for c in self.dont_ignore:\n",
    "            #res[:,c] = -.5 * np.log(self.det[c]) - .5 * np.diagonal((X - self.mu[c]) @ self.cov_lg_inv[c] @ (X - self.mu[c]).T) + np.log(self.priori)\n",
    "            res[:,c] = np.einsum('ab,db,ad->a', X, self.a[c], X) + np.einsum('b,cb->c', self.b[c], X) + self.c[c]\n",
    "        return res\n",
    "        #return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado por autovectores (método de sklearn)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado_metodo_sklearn(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        self.labels = labels\n",
    "        self.reg_param = 0 # hiperparametro\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.prob_clases = None\n",
    "        self.ajustes = []\n",
    "        self.autovectores = []\n",
    "    \n",
    "    def fit(self, X, y, reg_param=0):\n",
    "        self.reg_param = reg_param\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.prob_clases = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c, :]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            X_new = X_clase - self.mu[c]\n",
    "            # descomposicion espectral\n",
    "            _, autovalores, autovectores = np.linalg.svd(X_new, full_matrices=False)\n",
    "            ajuste = (autovalores ** 2) / (X_new.shape[0] - 1)\n",
    "            ajuste = ((1 - self.reg_param) * ajuste) + self.reg_param\n",
    "            self.cov[c] = (ajuste * autovectores.T) @ autovectores # np.dot(ajuste * autovectores.T, autovectores)\n",
    "            self.ajustes.append(np.copy(ajuste))\n",
    "            self.autovectores.append(np.copy(autovectores))\n",
    "            self.prob_clases[c] = X_clase.shape[0] / X.shape[0]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.empty((X.shape[0], len(self.labels)))\n",
    "        for c in range(len(self.labels)):\n",
    "            res[:,c] = np.sum(((X - self.mu[c]) @ (self.autovectores[c] * (self.ajustes[c] ** -.5)[:, None]).T) ** 2, axis=1)\n",
    "        aux = np.asarray([np.sum(np.log(x)) for x in self.ajustes])\n",
    "        return (-.5 * (res.T + aux[:, None]) + np.log(self.prob_clases)[:, None]).T\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clase Splitter para GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusionSplitter:\n",
    "    \"\"\"Esta clase nos permite usar GridSearchCV con la valuación por exclusion.\"\"\"\n",
    "    def __init__(self, train_indices, test_indices):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return [(self.train_indices, self.test_indices)]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de Cross Validation con KFolds**\n",
    "Esta implementación funciona, pero no debe usarse. No siempre ofrece los mismos resultados porque el array de entrada se baraja de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score(clsf, X, y, cv):\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X_chunks = np.array_split(X[permutation], cv)\n",
    "    y_chunks = np.array_split(y[permutation], cv)\n",
    "    scores = np.empty(cv)\n",
    "    for i in range(cv):\n",
    "        X_test = X_chunks[i]\n",
    "        y_test = y_chunks[i]\n",
    "        X_train_chunks = X_chunks[:i] + X_chunks[i+1:]\n",
    "        y_train_chunks = y_chunks[:i] + y_chunks[i+1:]\n",
    "        X_train = np.vstack(X_train_chunks)\n",
    "        y_train = np.hstack(y_train_chunks)\n",
    "        clsf.fit(X_train, y_train)\n",
    "        scores[i] = clsf.score(X_test, y_test)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implemetación de Cross Validation con Stratified KFolds**\n",
    "Esta implementación funciona, pero no debe usarse. No es una implementación eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def cv_score_skf(clsf, X, y, cv, reg_param=0):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    i = 0\n",
    "    for train_i, test_i in skf.split(X, y):\n",
    "        X_train = X[train_i]\n",
    "        y_train = y[train_i]\n",
    "        X_test = X[test_i]\n",
    "        y_test = y[test_i]\n",
    "        clsf.fit(X_train, y_train, reg_param)\n",
    "        scores[i] = clsf.score(X_test, y_test)\n",
    "        i = i + 1\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "# **Entrenamiento, predicción y evaluación de iris, wine y cancer**\n",
    "A continuación se realizan las pruebas correspondientes con las bases de datos iris, wine y cancer con el clasificador estadístico y el clasificador de la distancia euclídea. Al final se incluye una tabla resumen con los resultados. Por cada clasificador y base de datos se imprime el resultado obtenido por el clasificador equivalente de sklearn, con el fin de verificar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: datos: (150, 4) n_clases: 3\n",
      "wine: datos: (178, 13) n_clases: 3\n",
      "cancer: datos: (569, 30) n_clases: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Load data\n",
    "dataset_iris = load_iris()\n",
    "X_iris = dataset_iris.data\n",
    "y_iris = dataset_iris.target\n",
    "dataset_wine = load_wine()\n",
    "X_wine = dataset_wine.data\n",
    "y_wine = dataset_wine.target\n",
    "dataset_cancer = load_breast_cancer()\n",
    "X_cancer = dataset_cancer.data\n",
    "y_cancer = dataset_cancer.target\n",
    "print(\"iris: datos:\", X_iris.shape, \"n_clases:\", len(np.unique(y_iris)))\n",
    "print(\"wine: datos:\", X_wine.shape, \"n_clases:\", len(np.unique(y_wine)))\n",
    "print(\"cancer: datos:\", X_cancer.shape, \"n_clases:\", len(np.unique(y_cancer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 139/150 (92.67%)\n",
      "\t\tEvaluación por resustitución: 0.9267\n",
      "\t\tEvaluación por validación cruzada: 0.9133, std: 0.0499\n",
      "\t\tClasificador sklearn: 139 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_iris.target_names)\n",
    "clsf_euc.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "#scores = cv_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 129/178 (72.47%)\n",
      "\t\tEvaluación por resustitución: 0.7247\n",
      "\t\tEvaluación por validación cruzada: 0.7187, std: 0.0804\n",
      "\t\tClasificador sklearn: 129 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_wine.target_names)\n",
    "clsf_euc.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_euc, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 507/569 (89.10%)\n",
      "\t\tEvaluación por resustitución: 0.8910\n",
      "\t\tEvaluación por validación cruzada: 0.8841, std: 0.0840\n",
      "\t\tClasificador sklearn: 507 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_cancer.target_names)\n",
    "clsf_euc.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_euc, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 147/150 (98.00%)\n",
      "\t\tEvaluación por resustitución: 0.9800\n",
      "\t\tEvaluación por validación cruzada: 0.9600, std: 0.0646\n",
      "\t\tClasificador sklearn: 147 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_iris.target_names)\n",
    "clsf_est.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_est.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_est, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 177/178 (99.44%)\n",
      "\t\tEvaluación por resustitución: 0.9944\n",
      "\t\tEvaluación por validación cruzada: 0.7108, std: 0.3660\n",
      "\t\tClasificador sklearn: 177 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_wine.target_names)\n",
    "clsf_est.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_est.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_est, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 554/569 (97.36%)\n",
      "\t\tEvaluación por resustitución: 0.9736\n",
      "\t\tEvaluación por validación cruzada: 0.9613, std: 0.0090\n",
      "\t\tClasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_cancer.target_names)\n",
    "clsf_est.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_est.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_est, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resultados de los tres experimentos (clasificador distancia euclídea):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 139| 92.67|\n",
    "| Wine   | 129| 72.47|\n",
    "| Cancer | 507| 89.10|\n",
    "\n",
    "Resultados de los tres experimentos (clasificador estadístico):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147| 98.00|\n",
    "| Wine   | 177| 99.44|\n",
    "| Cancer | 554| 97.37|\n",
    "\n",
    "Dimensiones de las bases de datos:\n",
    "\n",
    "| Base de datos | Número de clases | Número de datos | Dimension de cada dato |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 3 | 150 | 4 |\n",
    "| Wine   | 3 | 178 | 13 |\n",
    "| Cancer | 2 | 569 | 30 |\n",
    "\n",
    "Como se puede observar, el clasificador estadístico tiene mejor tasa de aciertos con las tres bases de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento y evaluación de Isolet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/980745747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Si existe la base de datos, cargo las variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_train = np.array(X[:6238])\n",
    "y_train = pd.factorize(y)[0][:6238]\n",
    "X_test = np.array(X[6238:])\n",
    "y_test = pd.factorize(y)[0][6238:]\n",
    "\n",
    "X = np.array(X)\n",
    "y = pd.factorize(y)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificador distancia euclidea\n",
    "clss_euc = ClassifEuclid(np.unique(y_train))\n",
    "clss_euc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de clase\n",
    "clss_est_mc = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "clss_est_mc.fit(X_train, y_train)\n",
    "# Clasificador estadístico regularizado con el metodo de sklearn\n",
    "clss_est_msk = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est_msk.fit(X_train, y_train)\n",
    "# Clasificador estadístico de sklearn\n",
    "clss_est_sk = QuadraticDiscriminantAnalysis()\n",
    "clss_est_sk.fit(X_train, y_train)\n",
    "\n",
    "print(\"isolet: datos:\", X.shape, \"n_clases:\", len(np.unique(y)))\n",
    "\n",
    "print(\"\\tClasificador distancia euclídea:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_euc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_euc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de clase:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.10f\" % clss_est_mc.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.10f\" % clss_est_mc.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico regularizado con el método de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_msk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_msk.score(X_test, y_test))\n",
    "print(\"\\tClasificador estadístico de sklearn:\")\n",
    "print(\"\\t\\tEvaluación por resustitución:\\t\", \"%.4f\" % clss_est_sk.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\\t\", \"%.4f\" % clss_est_sk.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador de la distancia euclídea:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9267 | 0.9133 | - |\n",
    "| Wine   | 0.7247 | 0.7187 | - |\n",
    "| Cancer | 0.8910 | 0.8841 | - |\n",
    "| Isolet |  0.8809 | - | 0.8743 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador estadístico bayesiano:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9800 | 0.9600 | - |\n",
    "| Wine   | 0.9944 | 0.7108 | - |\n",
    "| Cancer | 0.9736 | 0.9613 | - |\n",
    "| Isolet |  1.0000 | - | 0.0648 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comentarios sobre los resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijándonos en la columna de aciertos por sustitución, vemos que el estadístico comete menos errores en las 3 bases de datos,\n",
    "siendo mas destacable la diferencia en cuanto al porcentaje de aciertos en las de Wine y Cancer, puesto que pasa de un 72,47%\n",
    "a un 99,44% en Wine y de un 89,1% a un 97,36%. Sin embargo, este incremento de la tasa de aciertos no se corresponde con un\n",
    "aumento real de la precisión del clasificador, si no con un error en la forma de evaluar el rendimiento de los clasificadores.\n",
    "Al evaluar ambos por validación cruzada, comprobamos que el aumento no es tan grande como el obtenido evaluando solo por\n",
    "resusitución, siendo incluso menor la precisión del estadístico en Wine a pesar de que era donde a priori se producia el mayor\n",
    "aumento. A pesar del peor rendimiento obtenido por el bayesiano en Wine, no podemos obviar que ha desempeñado mejor su funcion\n",
    "en las otras dos bases de datos, mostrando incluso un aumento de la tasas de aciertos desde un 88,41% a un 96,13% en Cancer.\n",
    "\n",
    "En cuanto a los resultados obtenidos en Isolet, vemos que los resultados del euclideo concuerdan más con los resultados que se\n",
    "esperan de un clasificador que los del bayesiano. Como podemos ver, en el bayesiano se ha obtenido un 100% de precision por\n",
    "resustitución, sin embargo se ha obtenido un 6,48% por exclusion. Este fenómeno se debe a la existencia de variables linealmente dependientes en el conjunto de entrenamiento de isolet. Debido a las variables colineares, es imposible hallar la inversa de la\n",
    "matriz de covarianzas, por lo que estos datos son \"memorizados\" por el clasificador, causando un alto grado de overfitting como se puede ver por su alta tasa de aciertos en el conjunto de entrenamiento y su pésimo desempeño en el conjunto de test. Sin\n",
    "embargo esto no sucede con el euclideo puesto que no tiene en cuenta el factor de la dispersion de los datos y por tanto tampoco la independencia lineal de los vectores de la matriz de covarianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet con hiperparámetros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Funcion que evalua el clasificador con cada uno de los hiperparametros\n",
    "def find_best_parameters_quad(X, y, k, shrinkages):\n",
    "    # Creamos una instancia del clasificador\n",
    "    cbp = QuadraticDiscriminantAnalysis()\n",
    "    # definimos la rejilla en la que vamos a buscar\n",
    "    params = {'reg_param': shrinkages}\n",
    "    # Creamos una clase GridSearchCV que será una especie de supra-clasificador\n",
    "    # que se ajusta por validación cruzada.\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-1, scoring='accuracy', cv=k).fit(X, y)\n",
    "    # Como supra-clasificador que es, clf contiene todo tipo de datos sobre la evaluación\n",
    "    # por validación cruzada. Vamos a obtener en este caso el clasificador con mejor 'accuracy'\n",
    "    best_clf = clf.best_estimator_\n",
    "    # clf.cv_results_ contiene los resultados de la evaluación, obtengamos la media y\n",
    "    # desviación típica del score de validación\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "    # print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "\n",
    "    # Imprimamos los mejores parametro que hemos encontrado y el resultado de su validación\n",
    "    print(\"\\tSelected shrinkage = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.reg_param, result_score_mean, result_score_std))\n",
    "    return best_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscar un hiperparámetro lo suficientemente bueno.\n",
    "Primero se prueba con 0.0, 0.1, 0.2, ..., 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero probar con 0.0, 0.1, 0.2, ..., 1.0\n",
    "h = [i/10 for i in range(11)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor de la lista anterior es 0.2, ahora se probarán los cercanos a 0.2: 0.10, 0.11, ..., 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con 0.10, 0.11, ..., 0.30\n",
    "h = [i/100 for i in range(10, 30)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "El mejor de la lista anterior es 0.23, ahora se probarán los cercanos a 0.23: 0.220, 0.221, 0.222, ..., 0.239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con 0.220, 0.221, 0.222, ..., 0.239\n",
    "h = [i/1000 for i in range(220, 240)]\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))), h)\n",
    "# El mejor hiperparámetro es 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor de la lista anterior es 0.23. Al parecer ya no se mejora la precisión, por tanto nos quedamos con 0.23.\n",
    "\n",
    "Comprobamos el funcionamiento correcto de nuestra implementación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y))\n",
    "clf.fit(X, y, reg_param=0.23)\n",
    "print(clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparam(X, y, k, shrinkages):\n",
    "    scores = np.empty((len(shrinkages), k))\n",
    "    for h in range(len(shrinkages)):\n",
    "        skf = StratifiedKFold(n_splits=k)\n",
    "        i = 0\n",
    "        for train_i, test_i in skf.split(X, y):\n",
    "            X_train = X[train_i]\n",
    "            y_train = y[train_i]\n",
    "            X_test = X[test_i]\n",
    "            y_test = y[test_i]\n",
    "            cbp = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y))\n",
    "            cbp.fit(X_train, y_train, shrinkages[h])\n",
    "            scores[h][i] = cbp.score(X_test, y_test)\n",
    "            i = i + 1\n",
    "    return np.max(scores, axis=1)\n",
    "#hyperparams = [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3]\n",
    "#scores = find_best_hyperparam(X, y, 3, hyperparams)\n",
    "#print(scores)\n",
    "#print(\"max score:\", np.max(scores), \"scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [i/1000 for i in range(220, 240)]\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluación de Isolet** tras hacer un **Análisis de Componentes Principales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma como base el hiperparámetro que indica número de componentes principales que seleccionamos. Este hiperparámetro indica el número de columnas que tendrá la matriz de proyección $A$ (ver Análisis de Componentes Principales en la introducción). En el siguiente fragmento de código se toma $k=100$.\n",
    "\n",
    "En esta sección se prueba el clasificador estadístico con todas las combinaciones de hiperparámetros $\\gamma$ y $\\lambda$ de la lista 0.0, 0.1, 0.2, ..., 1.0. No se prueba con listas más extensas porque tardaría demasiado en ejecutar.\n",
    "\n",
    "**IMPORTANTE:** HAY QUE EJECUTAR TODAS LAS CELDAS EN ORDEN SECUENCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/1601729364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Paso 1: hacer la media del conjunto de datos de entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Paso 2: estandarizar el conjunto de datos de entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Paso 0: seleccionar el número de componentes principales\n",
    "n_componentes = 100 # hiperparámetro\n",
    "\n",
    "# Paso 1: hacer la media del conjunto de datos de entrenamiento\n",
    "X_train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "# Paso 2: estandarizar el conjunto de datos de entrenamiento\n",
    "X_norm = X_train - X_train_mean\n",
    "\n",
    "# Paso 3: calcular la nueva matriz de covarianzas del conjunto de datos estandarizados\n",
    "X_train_cov = np.cov(X_norm, rowvar=False)\n",
    "\n",
    "# Paso 4: calcular la descomposición espectral de la matriz de covarianzas\n",
    "u, autoval, autovec = np.linalg.svd(X_train_cov, full_matrices=False) # tarda 68.246s\n",
    "\n",
    "# Paso 5: construir la matriz de proyección A seleccionando las n_componentes componentes principales\n",
    "A = autovec[:n_componentes]\n",
    "\n",
    "# Paso 6: proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "\n",
    "# Paso 7: proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto tenemos `X_train_final` y `X_test_final` (ambos con 100 componentes), proyectado sobre el nuevo espacio. Ahora hay que entrenar el clasificador y evaluarlo con los nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 8: obtener combinaciones de los hiperparámetros lambda y gamma\n",
    "g = [i/10 for i in range(11)] # hiperparametro gamma (ver clasificador estadistico regularizado en la introduccion)\n",
    "l = [i/10 for i in range(11)] # hiperparametro lambda (ver clasificador estadistico regularizado en la introduccion)\n",
    "\n",
    "# Paso 9: entrenar el clasificador y evaluarlo para cada combinación de lambda y gamma\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar varios minutos. Prueba el clasificador\n",
    "#             con cada combinación de hiperparametros lambda y gamma 0.0, 0.1, 0.2, ..., 1.0.\n",
    "#             Los resultados se han precalculado y están guardados en scores_resustitucion y\n",
    "#             scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "#             La celda i,j de cada una de estas matrices se corresponde con el score del clasificador\n",
    "#             estadistico regualrizado con hiperparametros gamma = g[i] y lambda = l[j].\n",
    "scores_resustitucion = np.array([[1.000000, 0.989740, 0.979481, 0.969862, 0.964572, 0.960885, 0.956236, 0.951266, 0.947419, 0.944694, 0.941969],\n",
    "                                [0.999359, 0.986214, 0.973710, 0.967618, 0.962488, 0.957358, 0.953030, 0.949343, 0.945976, 0.943732, 0.941167],\n",
    "                                [0.997756, 0.981404, 0.971465, 0.963450, 0.956717, 0.953190, 0.949824, 0.947098, 0.943411, 0.940846, 0.938762],\n",
    "                                [0.994870, 0.978519, 0.967618, 0.958641, 0.952870, 0.950305, 0.946938, 0.944694, 0.941327, 0.939404, 0.937320],\n",
    "                                [0.991343, 0.973549, 0.962007, 0.954633, 0.950625, 0.947419, 0.944854, 0.941808, 0.938923, 0.936839, 0.935396],\n",
    "                                [0.987336, 0.968259, 0.957198, 0.950465, 0.945495, 0.942770, 0.939885, 0.936358, 0.934915, 0.933633, 0.932350],\n",
    "                                [0.982366, 0.961045, 0.949663, 0.944213, 0.940686, 0.936999, 0.934113, 0.932671, 0.930106, 0.929625, 0.928663],\n",
    "                                [0.973870, 0.952068, 0.940846, 0.936037, 0.932190, 0.930106, 0.927701, 0.926579, 0.925297, 0.924174, 0.923213],\n",
    "                                [0.964091, 0.940846, 0.933953, 0.927381, 0.923533, 0.921289, 0.919525, 0.918243, 0.917441, 0.916480, 0.915357],\n",
    "                                [0.946137, 0.925938, 0.917121, 0.913113, 0.911510, 0.910067, 0.908625, 0.907823, 0.906701, 0.906220, 0.905899],\n",
    "                                [0.874800, 0.876403, 0.876563, 0.876403, 0.876403, 0.876403, 0.876563, 0.876563, 0.876242, 0.876242, 0.876082]])\n",
    "scores_exclusion = np.array([[0.910199, 0.962155, 0.958307, 0.953175, 0.947402, 0.944836, 0.944195, 0.941629, 0.939064, 0.939064, 0.939064],\n",
    "                            [0.951251, 0.966004, 0.959589, 0.951892, 0.949326, 0.948685, 0.946119, 0.943554, 0.942912, 0.939705, 0.938422],\n",
    "                            [0.959589, 0.964721, 0.957024, 0.952534, 0.948685, 0.946761, 0.944195, 0.939705, 0.937139, 0.937139, 0.935856],\n",
    "                            [0.961514, 0.962155, 0.954458, 0.949326, 0.945478, 0.942271, 0.940346, 0.939064, 0.937139, 0.936498, 0.936498],\n",
    "                            [0.965362, 0.957665, 0.953175, 0.948044, 0.944836, 0.942271, 0.941629, 0.939064, 0.936498, 0.934573, 0.934573],\n",
    "                            [0.966004, 0.958307, 0.949326, 0.944195, 0.940988, 0.940988, 0.939064, 0.937781, 0.936498, 0.934573, 0.934573],\n",
    "                            [0.964721, 0.953175, 0.942271, 0.938422, 0.938422, 0.937781, 0.935215, 0.933932, 0.933932, 0.932649, 0.932649],\n",
    "                            [0.959589, 0.947402, 0.937781, 0.936498, 0.934573, 0.932649, 0.932649, 0.931366, 0.929442, 0.929442, 0.929442],\n",
    "                            [0.957024, 0.940346, 0.933932, 0.929442, 0.926876, 0.926235, 0.924952, 0.923028, 0.921745, 0.921103, 0.919820],\n",
    "                            [0.942912, 0.923028, 0.917896, 0.912123, 0.910840, 0.909557, 0.908275, 0.907633, 0.907633, 0.906992, 0.906992],\n",
    "                            [0.871071, 0.874278, 0.872996, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354, 0.872354]])\n",
    "\"\"\"\n",
    "scores_resustitucion = np.empty((len(g), len(l)))\n",
    "scores_exclusion = np.empty((len(g), len(l)))\n",
    "t0 = time()\n",
    "for gi in range(len(g)):\n",
    "    for li in range(len(l)):\n",
    "        clss_est = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "        clss_est.fit(X_train_final, y_train, l=l[li], g=g[gi])\n",
    "        scores_resustitucion[gi][li] = clss_est.score(X_train_final, y_train)\n",
    "        scores_exclusion[gi][li] = clss_est.score(X_test_final, y_test)\n",
    "print(\"Finalizado en %.3fs\" % (time() - t0))\n",
    "\"\"\"\n",
    "\n",
    "print(\"max_score resustitucion:\\t%.4f\" % np.max(scores_resustitucion))\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes gráficos se muestran las puntuaciones del clasificador estadístico regularizado (con el método de clase) para cada valor de los hiperparámetros $\\lambda$ y $\\gamma$. Se han empleado los datos `X_train_final` y `X_test_final`, que se han obtenido previamente seleccionando las 100 primeras componentes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/4207031703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_resustitucion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'viridis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'nearest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scores_resustitucion\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "im = plt.imshow(scores_resustitucion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_resustitucion\")\n",
    "plt.subplot(122)\n",
    "im = plt.imshow(scores_exclusion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_exclusion\")\n",
    "plt.subplots_adjust(right=0.9)\n",
    "cax = plt.axes([0.95, 0.235, 0.02, 0.53])\n",
    "plt.colorbar(cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, por lo general cuanto menor sean los valores de los hiperparámetros $\\lambda$ y $\\gamma$, mejores resultados se obtiene, excepto en el caso de $\\lambda = \\gamma = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimación del hiperparámetro $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado en la introducción, el Análisis de Componentes Principales selecciona las componentes de máxima varianza, es decir, selecciona las que aportan más información. El hiperparámetro $k$ indica el número de componentes que se seleccionan. Ahora, en vez de estimar el hiperparámetro $k$, vamos a seleccionarlo de otra forma más interesante. Vamos a calcular el valor de $k$ para que la varianza de las $k$ componentes principales sea superior al 99% de la varianza total del conjunto de datos. Vamos a seguir el procedimiento indicado en la sección de Análisis de Componentes Principales de la introducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/1656159051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Primero se calcula la varianza que proporciona cada componente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvar_autoval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mautoval\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Se calcula el ratio en funcion del total que la varianza de cada componente proporciona\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvar_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_autoval\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_autoval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Se obtienen las varianzas acumuladas por cada componente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'autoval' is not defined"
     ]
    }
   ],
   "source": [
    "# Primero se calcula la varianza que proporciona cada componente\n",
    "var_autoval = (autoval ** 2) / (X_train_final.shape[0] - 1)\n",
    "# Se calcula el ratio en funcion del total que la varianza de cada componente proporciona \n",
    "var_ratio = var_autoval / np.sum(var_autoval)\n",
    "# Se obtienen las varianzas acumuladas por cada componente\n",
    "cum_var = np.cumsum(var_ratio)\n",
    "# Visualizar las 200 primeras (no hace falta visualizar las menos importantes)\n",
    "index = 0\n",
    "for e in cum_var:\n",
    "    print(\"\\t\", \"%3d\" % (index+1), \": \", \"%.6f\" % e, sep='', end='')\n",
    "    index = index + 1\n",
    "    if index % 9 == 0:\n",
    "        print()\n",
    "    if index == 207:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores mostrados muestran el índice de la componente, y la varianza acumulada de esa componente y las componentes previas. Como se puede observar, la primera componente proporciona el 74.99% de la varianza del conjunto de datos. Si queremos escoger las $k$ primeras componentes para conservar el 99% de la varianza del conjunto de datos, nos vale con seleccionar 18 componentes. Vamos a confirmar ahora que los resultados con 18 componentes no varían mucho comparados con los de 100 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las 18 primeras componentes\n",
    "A = autovec[:18]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos y evaluamos el clasificador con los hiperparámetros\n",
    "\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 5 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_resustitucion y\n",
    "#             scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "scores_resustitucion = np.array([[0.930266, 0.899647, 0.888105, 0.880891, 0.877845, 0.874960, 0.872876, 0.870151, 0.869029, 0.867906, 0.867425],\n",
    "                                [0.923052, 0.895960, 0.883937, 0.879449, 0.876082, 0.872555, 0.870792, 0.868868, 0.867746, 0.866784, 0.866143],\n",
    "                                [0.915357, 0.889708, 0.880090, 0.873998, 0.871273, 0.869509, 0.867105, 0.865822, 0.864540, 0.863097, 0.862296],\n",
    "                                [0.906220, 0.884418, 0.874319, 0.869509, 0.866143, 0.863418, 0.862135, 0.861173, 0.860532, 0.859410, 0.858448],\n",
    "                                [0.897082, 0.877204, 0.867586, 0.862616, 0.860693, 0.859089, 0.858288, 0.857166, 0.856685, 0.855563, 0.855242],\n",
    "                                [0.889388, 0.868548, 0.861815, 0.857166, 0.855402, 0.853960, 0.853158, 0.852196, 0.851395, 0.850433, 0.850112],\n",
    "                                [0.880571, 0.862937, 0.855082, 0.852357, 0.849792, 0.848189, 0.847066, 0.846585, 0.845784, 0.844982, 0.845303],\n",
    "                                [0.868227, 0.852677, 0.846585, 0.844822, 0.842578, 0.841776, 0.840975, 0.840494, 0.840013, 0.840173, 0.840173],\n",
    "                                [0.856044, 0.840975, 0.835043, 0.833921, 0.831837, 0.831196, 0.830074, 0.829593, 0.829913, 0.829593, 0.829272],\n",
    "                                [0.834562, 0.824784, 0.822058, 0.820616, 0.819654, 0.819493, 0.819493, 0.819333, 0.819013, 0.818692, 0.818692],\n",
    "                                [0.798012, 0.803463, 0.803302, 0.802661, 0.802821, 0.802661, 0.802661, 0.802661, 0.802661, 0.802821, 0.802821]])\n",
    "scores_exclusion = np.array([[0.906350, 0.900577, 0.886466, 0.880051, 0.876203, 0.875561, 0.874278, 0.873637, 0.871713, 0.869788, 0.869788],\n",
    "                            [0.914047, 0.902502, 0.888390, 0.883258, 0.879410, 0.875561, 0.874278, 0.873637, 0.872996, 0.872996, 0.873637],\n",
    "                            [0.910199, 0.898653, 0.888390, 0.879410, 0.876844, 0.874278, 0.872996, 0.872354, 0.871713, 0.871713, 0.871071],\n",
    "                            [0.907633, 0.891597, 0.883258, 0.879410, 0.874920, 0.872354, 0.869147, 0.867864, 0.866581, 0.866581, 0.866581],\n",
    "                            [0.896729, 0.886466, 0.875561, 0.870430, 0.869147, 0.867864, 0.867864, 0.867864, 0.867864, 0.866581, 0.866581],\n",
    "                            [0.890956, 0.876844, 0.867864, 0.864015, 0.860167, 0.858884, 0.856960, 0.856960, 0.856960, 0.856318, 0.855677],\n",
    "                            [0.887749, 0.869147, 0.858242, 0.853752, 0.853111, 0.851828, 0.851187, 0.850545, 0.849904, 0.849262, 0.847979],\n",
    "                            [0.881334, 0.855677, 0.848621, 0.845414, 0.843489, 0.843489, 0.843489, 0.843489, 0.842848, 0.842848, 0.842848],\n",
    "                            [0.871071, 0.842207, 0.838358, 0.837716, 0.837075, 0.833868, 0.832585, 0.832585, 0.831302, 0.830661, 0.830661],\n",
    "                            [0.841565, 0.822963, 0.822322, 0.822963, 0.822322, 0.822322, 0.822322, 0.822322, 0.822322, 0.822963, 0.822963],\n",
    "                            [0.797306, 0.802437, 0.803079, 0.803720, 0.803720, 0.803079, 0.803079, 0.802437, 0.801796, 0.801796, 0.801796]])\n",
    "\"\"\"\n",
    "scores_resustitucion = np.empty((len(g), len(l)))\n",
    "scores_exclusion = np.empty((len(g), len(l)))\n",
    "t0 = time()\n",
    "for gi in range(len(g)):\n",
    "    for li in range(len(l)):\n",
    "        clss_est = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "        clss_est.fit(X_train_final, y_train, l=l[li], g=g[gi])\n",
    "        scores_resustitucion[gi][li] = clss_est.score(X_train_final, y_train)\n",
    "        scores_exclusion[gi][li] = clss_est.score(X_test_final, y_test)\n",
    "print(\"Finalizado en %.3fs\" % (time() - t0))\n",
    "\"\"\"\n",
    "\n",
    "print(\"max_score resustitucion:\\t%.4f\" % np.max(scores_resustitucion))\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, este código se ha ejecutado en unos 5 segundos, mientras que el anterior ha tardado más de 250 segundos (en mi ordenador). Obviamente se debe a la reducción en la dimensionalidad: se ha pasado de manejar matrices de 6238x100 a matrices de 6238x18. La puntuación con 100 componentes es 0.9660, mientras que con 18 componentes es 0.9140. Se ha reducido el tiempo de cómputo en un 97%, sacrificando sólo un 5,2% de precisión. Vamos a probar ahora cuánta precisión se obtiene tomando las $k$ primeras componentes, de forma que se conserva un 99,9% de la varianza total. Viendo los valores de varianzas acumuladas, nos basta con seleccionar las 68 primeras, conservando un 99,9015% de la varianza total. Una de las ventajas del método de Análisis de Componentes Principales es que no es necesario recalcular la matriz de proyección $A$ si se quiere probar con un $k$ distinto. Repetimos los pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "im = plt.imshow(scores_resustitucion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_resustitucion\")\n",
    "plt.subplot(122)\n",
    "im = plt.imshow(scores_exclusion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_exclusion\")\n",
    "plt.subplots_adjust(right=0.9)\n",
    "cax = plt.axes([0.95, 0.235, 0.02, 0.53])\n",
    "plt.colorbar(cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El eje horizontal muestra los valores de $\\lambda$, y el vertical los de $\\gamma$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las 68 primeras componentes\n",
    "A = autovec[:68]\n",
    "# Proyectar el conjunto de datos de entrenamiento estandarizado sobre el nuevo espacio\n",
    "X_train_final = (A @ X_norm.T).T\n",
    "# Proyectar el conjunto de datos de test sobre el nuevo espacio:\n",
    "X_test_final = (A @ (X_test - np.mean(X_test, axis=0)).T).T\n",
    "print(\"X_train_final:\", X_train_final.shape)\n",
    "print(\"X_test_final:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos y evaluamos el clasificador con los hiperparámetros\n",
    "\n",
    "# IMPORTANTE: el siguiente fragmento de codigo tarda en ejecutar unos 66 segundos.\n",
    "#             Los resultados se han precalculado y están guardados en scores_resustitucion y\n",
    "#             scores_exclusion por si no se quiere ejecutar esta parte.\n",
    "scores_resustitucion = np.array([[0.998557, 0.976274, 0.964572, 0.957679, 0.951908, 0.947419, 0.943732, 0.940205, 0.937480, 0.935396, 0.934274],\n",
    "                                [0.995030, 0.974190, 0.961366, 0.954793, 0.949663, 0.946297, 0.942610, 0.939724, 0.937159, 0.935556, 0.933793],\n",
    "                                [0.990542, 0.970664, 0.957679, 0.951266, 0.945175, 0.943091, 0.940366, 0.936999, 0.933633, 0.932190, 0.930907],\n",
    "                                [0.985572, 0.965053, 0.954312, 0.945656, 0.941808, 0.939083, 0.936197, 0.934274, 0.931869, 0.929304, 0.927701],\n",
    "                                [0.980763, 0.959282, 0.949022, 0.941167, 0.937320, 0.934113, 0.932350, 0.929945, 0.928342, 0.926258, 0.924495],\n",
    "                                [0.974832, 0.952709, 0.941488, 0.935556, 0.931869, 0.929304, 0.926579, 0.924976, 0.922571, 0.921129, 0.920327],\n",
    "                                [0.968900, 0.945816, 0.934915, 0.931068, 0.927220, 0.923693, 0.921449, 0.920487, 0.920327, 0.918884, 0.917602],\n",
    "                                [0.960244, 0.937961, 0.929465, 0.923533, 0.920327, 0.917762, 0.915678, 0.913434, 0.911831, 0.911350, 0.911831],\n",
    "                                [0.950786, 0.927220, 0.919045, 0.913594, 0.911510, 0.909266, 0.908464, 0.908144, 0.907663, 0.907021, 0.906861],\n",
    "                                [0.932991, 0.911029, 0.904777, 0.901571, 0.900128, 0.899327, 0.898525, 0.897563, 0.897243, 0.896601, 0.896601],\n",
    "                                [0.868868, 0.869830, 0.869990, 0.869990, 0.869990, 0.869990, 0.869830, 0.869990, 0.870151, 0.869830, 0.869830]])\n",
    "scores_exclusion = np.array([[0.930725, 0.958948, 0.949968, 0.948044, 0.943554, 0.942271, 0.940346, 0.938422, 0.937139, 0.935215, 0.935215],\n",
    "                            [0.950609, 0.959589, 0.951892, 0.946761, 0.944836, 0.944836, 0.940988, 0.937781, 0.937139, 0.935856, 0.935215],\n",
    "                            [0.957665, 0.958948, 0.949326, 0.946119, 0.943554, 0.942271, 0.940988, 0.939064, 0.937139, 0.936498, 0.935856],\n",
    "                            [0.964080, 0.955741, 0.948044, 0.943554, 0.942271, 0.939705, 0.939064, 0.938422, 0.937781, 0.937139, 0.934573],\n",
    "                            [0.966645, 0.954458, 0.944836, 0.942271, 0.940988, 0.940346, 0.937781, 0.937781, 0.936498, 0.934573, 0.932649],\n",
    "                            [0.961514, 0.952534, 0.942271, 0.939064, 0.937139, 0.934573, 0.933932, 0.933291, 0.932008, 0.932008, 0.932008],\n",
    "                            [0.957665, 0.944836, 0.936498, 0.934573, 0.932649, 0.931366, 0.930725, 0.930083, 0.930083, 0.929442, 0.928801],\n",
    "                            [0.955099, 0.940346, 0.934573, 0.930725, 0.929442, 0.928159, 0.927518, 0.926235, 0.925593, 0.923669, 0.922386],\n",
    "                            [0.949968, 0.932008, 0.926235, 0.923028, 0.920462, 0.919179, 0.917896, 0.915972, 0.914047, 0.914047, 0.914047],\n",
    "                            [0.933932, 0.914689, 0.909557, 0.906992, 0.904426, 0.903143, 0.903143, 0.901860, 0.901219, 0.901219, 0.899936],\n",
    "                            [0.869147, 0.872996, 0.872354, 0.872354, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713, 0.871713]])\n",
    "\"\"\"\n",
    "scores_resustitucion = np.empty((len(g), len(l)))\n",
    "scores_exclusion = np.empty((len(g), len(l)))\n",
    "t0 = time()\n",
    "for gi in range(len(g)):\n",
    "    for li in range(len(l)):\n",
    "        clss_est = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "        clss_est.fit(X_train_final, y_train, l=l[li], g=g[gi])\n",
    "        scores_resustitucion[gi][li] = clss_est.score(X_train_final, y_train)\n",
    "        scores_exclusion[gi][li] = clss_est.score(X_test_final, y_test)\n",
    "print(\"Finalizado en %.3fs\" % (time() - t0))\n",
    "\"\"\"\n",
    "\n",
    "print(\"max_score resustitucion:\\t%.4f\" % np.max(scores_resustitucion))\n",
    "print(\"max_score exclusion:\\t\\t%.4f\" % np.max(scores_exclusion))\n",
    "\n",
    "\"\"\"\n",
    "print('[', end='')\n",
    "for q1 in scores_resustitucion:\n",
    "    print('[', end='')\n",
    "    for q2 in q1:\n",
    "        print(\"%.6f, \" % q2, end='')\n",
    "    print('],')\n",
    "print(']')\n",
    "print()\n",
    "print('[', end='')\n",
    "for q1 in scores_exclusion:\n",
    "    print('[', end='')\n",
    "    for q2 in q1:\n",
    "        print(\"%.6f, \" % q2, end='')\n",
    "    print('],')\n",
    "print(']')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "im = plt.imshow(scores_resustitucion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_resustitucion\")\n",
    "plt.subplot(122)\n",
    "im = plt.imshow(scores_exclusion, cmap='viridis', interpolation='nearest', extent=[0, 1, 1, 0])\n",
    "plt.title(\"scores_exclusion\")\n",
    "plt.subplots_adjust(right=0.9)\n",
    "cax = plt.axes([0.95, 0.235, 0.02, 0.53])\n",
    "plt.colorbar(cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El eje horizontal muestra los valores de $\\lambda$, y el vertical los de $\\gamma$. Como se ve, los valores de $\\gamma$ y $\\lambda$ óptimos son $\\gamma=0.4$ y $\\lambda = 0.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss_est = ClassifEstadisticoRegularizado_metodo_clase(np.unique(y_train))\n",
    "clss_est.fit(X_train_final, y_train, g=0.41)\n",
    "score_resustitucion = clss_est.score(X_train_final, y_train)\n",
    "score_exclusion = clss_est.score(X_test_final, y_test)\n",
    "print(\"score_resustitucion:\", score_resustitucion)\n",
    "print(\"score_exclusion:\", score_exclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionando las 68 primeras componentes, el porcentaje de la varianza del conjunto de datos que se conserva es 99,9015%. Esta vez se ha ejecutado en 66 segundos, pero la precisión ha sido de 0.9666. Esta precisión es incluso mayor que la que se obtiene con 100 componentes, 0.9660. Esto se debe al fenómeno conocido como *overfitting*. Si se seleccionan todas las componentes (caso estudiado arriba), el clasificador \"aprende\" de todas y cada una de ellas, el problema es que de las 617 componentes que tiene, la mayoría no proporciona información útil, por tanto influye negativamente en la clasificación de datos. Como se ha visto, con tan solo 18 de las 671 componentes se conserva un 99% de la varianza total, mientras que con 68 se conserva un 99,9%. En este caso, con 68 componentes, se ha obtenido una puntuación mayor que con 100 componentes, lo que indica que el \"número ideal de componentes\" se sitúa entre 68 y 100. Este valor de $k$ consigue un balance entre conservar la máxima varianza entre clases, pero sin que se produzca *overfitting*.\n",
    "\n",
    "Cabe destacar que sólamente se han probado los nuevos datos con las combinaciones de los hiperparámetros $\\lambda$ y $\\gamma$ de la lista `[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]`. La máxima puntuación que se obtenía antes de aplicar el Análisis de Componentes Principales (equivalente a seleccionar todas las componentes) es 0.956. Ahora se ha conseguido una puntuación incluso mayor: 0.9666. Este método no sólo elimina los datos menos importantes que empeoran los resultados, también simplifica el problema, por lo que se ejecuta el algoritmo de clasificación mucho más rápido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss_est = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.1)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n",
    "clss_est = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.23)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n",
    "clss_est = ClassifEstadisticoRegularizado_metodo_sklearn(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train, 0.3)\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\t\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.23 -> 0.956\n",
    "\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 10\n",
    "for ffff in range(x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 30\n",
    "for ffff in range(20, x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prueba():\n",
    "    def __init__(self, labels, tremendo=0):\n",
    "        if tremendo == 0:\n",
    "            self.x = len(labels)\n",
    "        else:\n",
    "            self.x = tremendo\n",
    "    def print_X(self):\n",
    "        print(self.x)\n",
    "    \n",
    "p = prueba([1, 2, 3], tremendo=2)\n",
    "p.print_X()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Caras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total del dataset:\n",
      "n_samples: 1288, hxw: 62 x 47\n",
      "Numero de caracteristicas: 2914, actually 62 x 47 = 2914\n",
      "Numero de clases: 7, nombres: ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Tony Blair']\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.5)\n",
    "\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Tamaño total del dataset:\")\n",
    "print(f\"n_samples: {n_samples}, hxw: {h} x {w}\")\n",
    "print(f\"Numero de caracteristicas: {n_features}, actually {h} x {w} = {h*w}\")\n",
    "print(f\"Numero de clases: {n_classes}, nombres: {target_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/1815977670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplot_gallery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_row\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/1815977670.py\u001b[0m in \u001b[0;36mplot_gallery\u001b[1;34m(images, titles, h, w, n_row, n_col)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_gallery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_row\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Helper function to plot a gallery of portraits\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.90\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_row\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "plot_gallery(X, list(y), h, w, n_row=3, n_col=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Estadisticas de los datos:\")\n",
    "print(f\"Numero de datos de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Numero de datos de test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "n_components = 150\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(X_train)\n",
    "print(\"Finalizado en %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"Finalizado en %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w, n_row=3, n_col=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting people's names on the test set\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12424/1425222094.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicting people's names on the test set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassifEuclid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Predicting people's names on the test set\")\n",
    "t0 = time()\n",
    "clf = ClassifEuclid(np.unique(y_train))\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(\" \", 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(\" \", 1)[-1]\n",
    "    return \"predicted: %s\\ntrue:      %s\" % (pred_name, true_name)\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\n",
    "plot_gallery(X_test, prediction_titles, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
