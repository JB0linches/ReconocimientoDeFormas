{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "colab_type": "text",
    "id": "AfaNEPeRXCe8"
   },
   "source": [
    "# Práctica 1 Reconocimiento de Formas: Clasificador de la distancia euclídea \n",
    "\n",
    "* **Alumno 1**: Bolinches Segovia, Jorge\n",
    "* **Alumno 2**: Cercadillo Muñoz, Daniel\n",
    "* **Alumno 3**: Cerezo Pomykol, Jan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementación de clasificadores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def decision_function(self, X):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.num_aciertos(X, y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEuclid(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.Z = None # Array de centroides\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n = np.zeros(len(self.labels)) # Contador de ocurrencias de cada clase\n",
    "        self.Z = np.zeros((len(self.labels), X.shape[1]))\n",
    "        # Calcular la media: \n",
    "        # Sumar las ocurrencias de cada clase en self.Z\n",
    "        for yi, Xi in zip(y, X):\n",
    "            n[yi] = n[yi] + 1\n",
    "            self.Z[yi] = self.Z[yi] + Xi\n",
    "        # Dividir cada sumatorio entre el númeo de ocurrencias\n",
    "        self.Z = self.Z / n[:, None]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        # Calcular la distancia de cada fila a cada centroide\n",
    "        aux = X[:,None]-self.Z\n",
    "        return np.sqrt(np.einsum('abc,abc->ab', aux, aux))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        # Devuelve un array con el índice con valor mínimo de cada fila.\n",
    "        # Cada índice se corresponde con la clase a la que pertenece.\n",
    "        return np.argmin(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self, X, y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        # Contar el número de datos iguales en ambos vectores\n",
    "        return np.sum(self.predict(X)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifEstadistico(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[]):\n",
    "        \"\"\"Constructor de la clase\n",
    "        labels: lista de etiquetas de esta clase (argumento necesario)\"\"\"\n",
    "        self.labels = labels\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.cov_inv = None # Array de matrices de covarianza inversas\n",
    "        self.det = None # Array de determinantes de las matrices de covarianza\n",
    "        # Terminos de la expresión cuadrática del clasificador\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "        self.c = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        y: vector de etiquetas, tantos elementos como filas en X\n",
    "        retorna objeto clasificador\"\"\"\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.cov_inv = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.det = np.empty(n_labels)\n",
    "        self.a = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.b = np.empty((n_labels, n_caracteristicas))\n",
    "        self.c = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            self.cov[c] = np.cov(X[y==c], rowvar=False)\n",
    "            self.mu[c] = np.mean(X[y==c], axis=0)\n",
    "            self.cov_inv[c] = np.linalg.inv(self.cov[c])\n",
    "            self.det[c] = np.linalg.det(self.cov[c])\n",
    "            self.a[c] = -.5 * self.cov_inv[c]\n",
    "            self.b[c] = self.mu[c].T @ self.cov_inv[c]\n",
    "            self.c[c] = -.5 * (self.mu[c].T @ self.cov_inv[c] @ self.mu[c]) -.5 * np.log(self.det[c]) + np.log(np.sum(y==c)/X.shape[0])\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        return np.einsum('ab,cdb,ad->ac', X, self.a, X) + np.einsum('ab,cb->ca', self.b, X) + self.c[None,:]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano regularizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsWqPK6l2flD"
   },
   "outputs": [],
   "source": [
    "class ClassifEstadisticoRegularizado(Classifier, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, labels=[], reg_param=0):\n",
    "        self.labels = labels\n",
    "        self.reg_param = reg_param # hiperparametro\n",
    "        self.mu = None # Array de medias\n",
    "        self.cov = None # Array de matrices de covarianza de cada clase\n",
    "        self.prob_clases = None\n",
    "        self.ajustes = []\n",
    "        self.autovectores = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_labels = len(self.labels)\n",
    "        n_caracteristicas = X.shape[1]\n",
    "        self.mu = np.empty((n_labels, n_caracteristicas))\n",
    "        self.cov = np.empty((n_labels, n_caracteristicas, n_caracteristicas))\n",
    "        self.prob_clases = np.empty(n_labels)\n",
    "        for c in range(len(self.labels)):\n",
    "            X_clase = X[y==c, :]\n",
    "            self.mu[c] = np.mean(X_clase, axis=0)\n",
    "            X_new = X_clase - self.mu[c]\n",
    "            # descomposicion espectral\n",
    "            _, autovalores, autovectores = np.linalg.svd(X_new, full_matrices=False)\n",
    "            ajuste = (autovalores ** 2) / (X_new.shape[0] - 1)\n",
    "            ajuste = ((1 - self.reg_param) * ajuste) + self.reg_param\n",
    "            self.cov[c] = (ajuste * autovectores.T) @ autovectores # np.dot(ajuste * autovectores.T, autovectores)\n",
    "            self.ajustes.append(np.copy(ajuste))\n",
    "            self.autovectores.append(np.copy(autovectores))\n",
    "            self.prob_clases[c] = X_clase.shape[0] / X.shape[0]\n",
    "        return self\n",
    "\n",
    "    def decision_function(self,X):\n",
    "        \"\"\"Estima el grado de pertenencia de cada dato a todas las clases \n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\"\n",
    "        res = np.empty((X.shape[0], len(self.labels)))\n",
    "        for c in range(len(self.labels)):\n",
    "            res[:,c] = np.sum(((X - self.mu[c]) @ (self.autovectores[c] * (self.ajustes[c] ** -.5)[:, None]).T) ** 2, axis=1)\n",
    "        aux = np.asarray([np.sum(np.log(x)) for x in self.ajustes])\n",
    "        return (-.5 * (res.T + aux[:, None]) + np.log(self.prob_clases)[:, None]).T\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Estima la etiqueta de cada dato. La etiqueta puede ser un entero o bien un string.\n",
    "        X: matriz numpy cada fila es un dato, cada columna una medida\n",
    "        retorna un vector con las etiquetas de cada dato\"\"\"\n",
    "        return np.argmax(self.decision_function(X), axis=1)\n",
    "    \n",
    "    def num_aciertos(self,X,y):\n",
    "        \"\"\"Cuenta el numero de aciertos del clasificador para un conjunto de datos X.\n",
    "        X: matriz de datos a clasificar\n",
    "        y: vector de etiquetas correctas\"\"\"\n",
    "        return np.sum(self.predict(X)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclusionSplitter:\n",
    "    \"\"\"Esta clase nos permite usar GridSearchCV con la valuación por exclusion.\"\"\"\n",
    "    def __init__(self, train_indices, test_indices):\n",
    "        self.train_indices = train_indices\n",
    "        self.test_indices = test_indices\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return [(self.train_indices, self.test_indices)]\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0U0Awu0X01F"
   },
   "source": [
    "# **Entrenamiento, predicción y evaluación de iris, wine y cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load data\n",
    "dataset_iris = load_iris()\n",
    "X_iris = dataset_iris.data\n",
    "y_iris = dataset_iris.target\n",
    "dataset_wine = load_wine()\n",
    "X_wine = dataset_wine.data\n",
    "y_wine = dataset_wine.target\n",
    "dataset_cancer = load_breast_cancer()\n",
    "X_cancer = dataset_cancer.data\n",
    "y_cancer = dataset_cancer.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador de la distancia euclídea**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 139/150 (92.67%)\n",
      "\t\tEvaluación por resustitución: 0.9267\n",
      "\t\tEvaluación por validación cruzada: 0.9133, std: 0.0499\n",
      "\t\tClasificador sklearn: 139 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_iris.target_names)\n",
    "clsf_euc.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_euc, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 129/178 (72.47%)\n",
      "\t\tEvaluación por resustitución: 0.7247\n",
      "\t\tEvaluación por validación cruzada: 0.7187, std: 0.0804\n",
      "\t\tClasificador sklearn: 129 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_wine.target_names)\n",
    "clsf_euc.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_euc, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xasWFNlhX85L",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 507/569 (89.10%)\n",
      "\t\tEvaluación por resustitución: 0.8910\n",
      "\t\tEvaluación por validación cruzada: 0.8841, std: 0.0840\n",
      "\t\tClasificador sklearn: 507 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_euc = ClassifEuclid(dataset_cancer.target_names)\n",
    "clsf_euc.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_euc.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_euc.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_euc, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = NearestCentroid().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Clasificador estadístico bayesiano**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **iris**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tiris:   Aciertos: 147/150 (98.00%)\n",
      "\t\tEvaluación por resustitución: 0.9800\n",
      "\t\tEvaluación por validación cruzada: 0.9600, std: 0.0646\n",
      "\t\tClasificador sklearn: 147 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_iris.target_names)\n",
    "clsf_est.fit(np.array(X_iris), y_iris)\n",
    "n_aciertos = clsf_est.num_aciertos(X_iris, y_iris)\n",
    "print(\"\\tiris:   Aciertos: \", n_aciertos, \"/\", len(y_iris), \" (\", \"%.2f\" % ((n_aciertos / len(y_iris))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_iris, y_iris))\n",
    "scores = cross_val_score(clsf_est, X_iris, y_iris, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_iris, y_iris)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_iris)==y_iris), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **wine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twine:   Aciertos: 177/178 (99.44%)\n",
      "\t\tEvaluación por resustitución: 0.9944\n",
      "\t\tEvaluación por validación cruzada: 0.7108, std: 0.3660\n",
      "\t\tClasificador sklearn: 177 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_wine.target_names)\n",
    "clsf_est.fit(np.array(X_wine), y_wine)\n",
    "n_aciertos = clsf_est.num_aciertos(X_wine, y_wine)\n",
    "print(\"\\twine:   Aciertos: \", n_aciertos, \"/\", len(y_wine), \" (\", \"%.2f\" % ((n_aciertos / len(y_wine))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_wine, y_wine))\n",
    "scores = cross_val_score(clsf_est, X_wine, y_wine, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_wine, y_wine)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_wine)==y_wine), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base de datos **cancer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcancer: Aciertos: 554/569 (97.36%)\n",
      "\t\tEvaluación por resustitución: 0.9736\n",
      "\t\tEvaluación por validación cruzada: 0.9613, std: 0.0090\n",
      "\t\tClasificador sklearn: 554 aciertos\n"
     ]
    }
   ],
   "source": [
    "# Nuestro clasificador\n",
    "clsf_est = ClassifEstadistico(dataset_cancer.target_names)\n",
    "clsf_est.fit(np.array(X_cancer), y_cancer)\n",
    "n_aciertos = clsf_est.num_aciertos(X_cancer, y_cancer)\n",
    "print(\"\\tcancer: Aciertos: \", n_aciertos, \"/\", len(y_cancer), \" (\", \"%.2f\" % ((n_aciertos / len(y_cancer))*100), \"%)\", sep='')\n",
    "# Evaluación por resustitución y validación cruzada\n",
    "print(\"\\t\\tEvaluación por resustitución:\", \"%.4f\" % clsf_est.score(X_cancer, y_cancer))\n",
    "scores = cross_val_score(clsf_est, X_cancer, y_cancer, cv=5)\n",
    "print(\"\\t\\tEvaluación por validación cruzada: \", \"%.4f\" % np.mean(scores), \", std: \", \"%.4f\" % np.std(scores), sep='')\n",
    "# Comparación con el clasificador de sklearn\n",
    "nc = QuadraticDiscriminantAnalysis().fit(X_cancer, y_cancer)\n",
    "print(\"\\t\\t\", \"Clasificador sklearn: \", np.sum(nc.predict(X_cancer)==y_cancer), \" aciertos\", sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resultados de los tres experimentos (clasificador distancia euclídea):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 139| 92.67|\n",
    "| Wine   | 129| 72.47|\n",
    "| Cancer | 507| 89.10|\n",
    "\n",
    "Resultados de los tres experimentos (clasificador estadístico):\n",
    "\n",
    "| Base de datos | Número de aciertos | Porcentaje de aciertos |\n",
    "| --- | --- | --- |\n",
    "| Iris   | 147| 98.00|\n",
    "| Wine   | 177| 99.44|\n",
    "| Cancer | 554| 97.37|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrenamiento y evaluación de Isolet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jan\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\discriminant_analysis.py:873: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador distancia euclídea:\n",
      "\tEvaluación por resustitución: 0.8809\n",
      "\tEvaluación por exclusión: 0.8743\n",
      "Clasificador estadístico:\n",
      "\tEvaluación por resustitución: 1.0000\n",
      "\tEvaluación por exclusión: 0.0648\n",
      "Clasificador estadístico de sklearn:\n",
      "\tEvaluación por resustitución: 1.0000\n",
      "\tEvaluación por exclusión: 0.0648\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os.path\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Si existe la base de datos, cargo las variables\n",
    "if os.path.exists(\"isolet_X.pickle\"):\n",
    "    X = pd.read_pickle('isolet_X.pickle')\n",
    "    y = pd.read_pickle('isolet_y.pickle')\n",
    "else:\n",
    "    # Cargamos desde internet ( https://www.openml.org ) y la guardamos en el directorio local\n",
    "    X, y = fetch_openml('isolet', version=1, return_X_y=True, cache=False)\n",
    "    # Guardamos los datos para no volver a descargarlos\n",
    "    X.to_pickle(\"isolet_X.pickle\")\n",
    "    y.to_pickle(\"isolet_y.pickle\")\n",
    "\n",
    "X_train = np.array(X[:6238])\n",
    "y_train = pd.factorize(y)[0][:6238]\n",
    "X_test = np.array(X[6238:])\n",
    "y_test = pd.factorize(y)[0][6238:]\n",
    "\n",
    "X = np.array(X)\n",
    "y = pd.factorize(y)[0]\n",
    "\n",
    "# Clasificador distancia euclidea\n",
    "clss_euc = ClassifEuclid(np.unique(y_train))\n",
    "clss_euc.fit(X_train, y_train)\n",
    "# Clasificador estadístico\n",
    "clss_est = ClassifEstadisticoRegularizado(np.unique(y_train))\n",
    "clss_est.fit(X_train, y_train)\n",
    "# Clasificador estadístico de sklearn\n",
    "clss_est_sk = QuadraticDiscriminantAnalysis()\n",
    "clss_est_sk.fit(X_train, y_train)\n",
    "\n",
    "print(\"Clasificador distancia euclídea:\")\n",
    "print(\"\\tEvaluación por resustitución:\", \"%.4f\" % clss_euc.score(X_train, y_train))\n",
    "print(\"\\tEvaluación por exclusión:\", \"%.4f\" % clss_euc.score(X_test, y_test))\n",
    "print(\"Clasificador estadístico:\")\n",
    "print(\"\\tEvaluación por resustitución:\", \"%.4f\" % clss_est.score(X_train, y_train))\n",
    "print(\"\\tEvaluación por exclusión:\", \"%.4f\" % clss_est.score(X_test, y_test))\n",
    "print(\"Clasificador estadístico de sklearn:\")\n",
    "print(\"\\tEvaluación por resustitución:\", \"%.4f\" % clss_est_sk.score(X_train, y_train))\n",
    "print(\"\\tEvaluación por exclusión:\", \"%.4f\" % clss_est_sk.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Resumen de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador de la distancia euclídea:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9267 | 0.9133 | - |\n",
    "| Wine   | 0.7247 | 0.7187 | - |\n",
    "| Cancer | 0.8910 | 0.8841 | - |\n",
    "| Isolet |  0.8809 | - | 0.8743 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de los experimentos con el clasificador estadístico bayesiano:\n",
    "\n",
    "| Base de datos | Acierto resustitucion | Acierto validacion cruzada | Acierto exclusion |\n",
    "| --- | --- | --- | --- |\n",
    "| Iris   | 0.9800 | 0.9600 | - |\n",
    "| Wine   | 0.9944 | 0.7108 | - |\n",
    "| Cancer | 0.9736 | 0.9613 | - |\n",
    "| Isolet |  1.0000 | - | 0.0648 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Comentarios sobre los resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijándonos en la columna de aciertos por sustitución, vemos que el estadístico comete menos errores en las 3 bases de datos,\n",
    "siendo mas destacable la diferencia en cuanto al porcentaje de aciertos en las de Wine y Cancer, puesto que pasa de un 72,47%\n",
    "a un 99,44% en Wine y de un 89,1% a un 97,36%. Sin embargo, este incremento de la tasa de aciertos no se corresponde con un\n",
    "aumento real de la precisión del clasificador, si no con un error en la forma de evaluar el rendimiento de los clasificadores.\n",
    "Al evaluar ambos por validación cruzada, comprobamos que el aumento no es tan grande como el obtenido evaluando solo por\n",
    "resusitución, siendo incluso menor la precisión del estadístico en Wine a pesar de que era donde a priori se producia el mayor\n",
    "aumento. A pesar del peor rendimiento obtenido por el bayesiano en Wine, no podemos obviar que ha desempeñado mejor su funcion\n",
    "en las otras dos bases de datos, mostrando incluso un aumento de la tasas de aciertos desde un 88,41% a un 96,13% en Cancer.\n",
    "\n",
    "En cuanto a los resultados obtenidos en Isolet, vemos que los resultados del euclideo concuerdan más con los resultados que se\n",
    "esperan de un clasificador que los del bayesiano. Como podemos ver, en el bayesiano se ha obtenido un 100% de precision por\n",
    "resustitución, sin embargo se ha obtenido un 6,48% por exclusion. Este fenómeno se debe a la existencia de variables linealmente\n",
    "dependientes en el conjunto de entrenamiento de isolet. Debido a las variables colineares, es imposible hallar la inversa de la\n",
    "matriz de covarianzas, por lo que estos datos no se tienen en cuenta afectando negativamente al rendimiento del bayesiano, sin\n",
    "embargo esto no sucede con el euclideo puesto que no tiene en cuenta el factor de la dispersion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_best_parameters_quad(X, y, k, shrinkages):\n",
    "    \"\"\"\n",
    "    Busca el clasificador bayesiano regularizado con el mejores parámetros.\n",
    "    :param X: Ejemplos de la dase de datos\n",
    "    :param y: Etiquetas de los ejemplos\n",
    "    :param k: Número de divisiones en la validación cruzada (k-fold)\n",
    "    :param shrinkages: Lista de posibles valores del parametro de shrinkage que conforman la rejilla\n",
    "    \"\"\"\n",
    "\n",
    "    # Creamos una instancia del clasificador\n",
    "    cbp = QuadraticDiscriminantAnalysis()\n",
    "    # definimos la rejilla en la que vamos a buscar\n",
    "    params = {'reg_param': shrinkages}\n",
    "    # Creamos una clase GridSearchCV que será una especie de supra-clasificador\n",
    "    # que se ajusta por validación cruzada.\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-1, scoring='accuracy', cv=k).fit(X, y)\n",
    "    # Como supra-clasificador que es, clf contiene todo tipo de datos sobre la evaluación\n",
    "    # por validación cruzada. Vamos a obtener en este caso el clasificador con mejor 'accuracy'\n",
    "    best_clf = clf.best_estimator_\n",
    "    # clf.cv_results_ contiene los resultados de la evaluación, obtengamos la media y\n",
    "    # desviación típica del score de validación\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "    # print(\"Srinkage scores: \", clf.cv_results_['mean_test_score'])\n",
    "\n",
    "    # Imprimamos los mejores parametro que hemos encontrado y el resultado de su validación\n",
    "    print(\"\\tSelected shrinkage = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.reg_param,\n",
    "                                                   result_score_mean,\n",
    "                                                   result_score_std))\n",
    "    return best_clf\n",
    "\n",
    "def find_best_parameters_quad2(X, y, k, shrinkages):\n",
    "        \n",
    "    \n",
    "    cbp = ClassifEstadistico(np.unique(y))\n",
    "    params = {'reg_param': shrinkages}\n",
    "    clf = GridSearchCV(cbp, params, n_jobs=-1, scoring='accuracy', cv=k).fit(X, y)\n",
    "    best_clf = clf.best_estimator_\n",
    "    result_score_mean = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "    result_score_std = clf.cv_results_['std_test_score'][clf.best_index_]\n",
    "\n",
    "    print(\"\\tSelected shrinkage = {}\\n\" \\\n",
    "          \"\\tAccuracy: {:.3f} (+/- {:.3f})\".format(best_clf.reg_param,\n",
    "                                                   result_score_mean,\n",
    "                                                   result_score_std))\n",
    "    return best_clf\n",
    "\n",
    "\n",
    "#ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test)))\n",
    "clf = find_best_parameters_quad(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))),\n",
    "                                [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3])\n",
    "#clf = find_best_parameters_quad2(X, y, ExclusionSplitter(np.arange(0, len(X_train)), np.arange(len(X_train), len(X_train) + len(X_test))),\n",
    "#                                [0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3])\n",
    "\n",
    "clf = ClassifEstadisticoRegularizado(np.unique(y), [0.2, 0.21])\n",
    "clf.fit(X, y)\n",
    "#clf.decision_function(X)\n",
    "clf.num_aciertos(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.23 -> 0.956\n",
    "\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 10\n",
    "for ffff in range(x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n",
    "\n",
    "print(\"[\",end='')\n",
    "x = 30\n",
    "for ffff in range(20, x):\n",
    "    print(ffff/100, \", \", sep='', end='')\n",
    "print(x/100, end='')\n",
    "print(\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prueba():\n",
    "    def __init__(self, labels, tremendo=0):\n",
    "        if tremendo == 0:\n",
    "            self.x = len(labels)\n",
    "        else:\n",
    "            self.x = tremendo\n",
    "    def print_X(self):\n",
    "        print(self.x)\n",
    "    \n",
    "p = prueba([1, 2, 3], tremendo=2)\n",
    "p.print_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Esqueleto(2).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
